{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run0154\n",
    "\n",
    "\n",
    "-  Based on `Run0145-karel_edition-Mk2`.\n",
    "\n",
    "\n",
    ">  Replaced <br>\n",
    "```power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 1e-32, numpy.inf)) ** (K.clip(K.abs(x[1]), -1., 3.)))``` <br>\n",
    "with <br>\n",
    "```power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.00001, 1000)) ** (K.clip(K.abs(x[1]), -1., 3.)))```\n",
    "\n",
    "-  Disabled Karel's custom callback `NBatchLogger()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Due to the fact that the Wi-Fi went down over night here at the IPP office where I had my laptop running whilst being connected to Theropoda, Runs0154-0157 may have been corrupted. I am re-running these exact same notebooks just to make sure that this is not the case. They are all designated as -Mk2 and have their separate (but otherwise identical) Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Gets the current file name. Useful for procedurally generating output/log files.\n",
    "file_name =  os.path.basename(sys.argv[0][:-3])\n",
    "print(file_name)\n",
    "\n",
    "if file_name == \"ipykernel_launcher\":\n",
    "    print(\"This is the Jupyter version.\")\n",
    "    print(\"Now MANUALLY run the next two cells!\")\n",
    "    print(\"STOP! This should not be in your code!!\")\n",
    "    exit(0)\n",
    "    time.sleep(10)\n",
    "    print(\"Testing if script has really stopped.\")\n",
    "else:\n",
    "    print(\"This is the Atom version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IN JUPYTER!!\n",
    "# Start here (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-14_Run0154-Mk2.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-14_Run0154-Mk2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "file_name = file_name[:-6]\n",
    "print(file_name)\n",
    "\n",
    "is_Jupyter = True\n",
    "print(is_Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code for both ATOM & JUPYTER from now (Run all cells below now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Late Fusion Module (test) - Functional API\n",
    "'''\n",
    "\n",
    "# Multiple Inputs\n",
    "import keras\n",
    "from keras.optimizers import RMSprop, adam, Adam\n",
    "from keras.initializers import TruncatedNormal, glorot_normal, Constant\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "#from keras.backend import switch\n",
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "\n",
    "#keras.backend.clear_session()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new Metric: rmse = Root Mean Square Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( y_true-y_pred )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify for ATOM use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_Jupyter == True:\n",
    "    pass\n",
    "else:\n",
    "    # Gets the current file name. Useful for procedurally generating output/log files.\n",
    "    file_name =  os.path.basename(sys.argv[0][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters\n",
    "batch_size = 10\n",
    "#num_classes = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (which is in HDF5 or .h5 format)\n",
    "store = pandas.HDFStore(\"training_gen3_7D_nions0_flat_filter8.h5\")\n",
    "target_df = store['/output/efeETG_GB'].to_frame()  # This one is relatively easy to train\n",
    "input_df = store['input']\n",
    "\n",
    "# Puts inputs and outputs in the same pandas dataframe.\n",
    "# Also only keeps overlapping entries.\n",
    "joined_dataFrame = target_df.join(input_df)\n",
    "\n",
    "# Make a copy of joined_dataFrame for later use\n",
    "joined_dataFrame_original = deepcopy(joined_dataFrame)\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "# Standard configuration\n",
    "joined_dataFrame['efeETG_GB'] = (joined_dataFrame['efeETG_GB'] - joined_dataFrame['efeETG_GB'].mean()) / joined_dataFrame['efeETG_GB'].std()\n",
    "joined_dataFrame['Ati'] = (joined_dataFrame['Ati'] - joined_dataFrame['Ati'].mean()) / joined_dataFrame['Ati'].std()\n",
    "joined_dataFrame['Ate'] = (joined_dataFrame['Ate'] - joined_dataFrame['Ate'].mean()) / joined_dataFrame['Ate'].std()\n",
    "joined_dataFrame['An'] = (joined_dataFrame['An'] - joined_dataFrame['An'].mean()) / joined_dataFrame['An'].std()\n",
    "joined_dataFrame['q'] = (joined_dataFrame['q'] - joined_dataFrame['q'].mean()) / joined_dataFrame['q'].std()\n",
    "joined_dataFrame['smag'] = (joined_dataFrame['smag'] - joined_dataFrame['smag'].mean()) / joined_dataFrame['smag'].std()\n",
    "joined_dataFrame['x'] = (joined_dataFrame['x'] - joined_dataFrame['x'].mean()) / joined_dataFrame['x'].std()\n",
    "joined_dataFrame['Ti_Te'] = (joined_dataFrame['Ti_Te'] - joined_dataFrame['Ti_Te'].mean()) / joined_dataFrame['Ti_Te'].std()\n",
    "\n",
    "# Shuffles dataset\n",
    "shuffled_joined_dataFrame = joined_dataFrame.reindex(numpy.random.permutation(\n",
    "                                                joined_dataFrame.index))\n",
    "\n",
    "# Creates a pandas dataframe for the outputs\n",
    "shuffled_clean_output_df = shuffled_joined_dataFrame['efeETG_GB']\n",
    "\n",
    "# Make a copy of shuffled_joined_dataFrame for later use\n",
    "shuffled_joined_dataFrame_base = deepcopy(shuffled_joined_dataFrame)\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Creates a pandas dataframe for the inputs (7D)\n",
    "shuffled_clean_input_df_7D = shuffled_joined_dataFrame.drop('efeETG_GB', axis=1)\n",
    "\n",
    "# Creates training dataset (90% of total data) for outputs\n",
    "y_train = shuffled_clean_output_df.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9))]\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train = shuffled_clean_input_df_7D.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for outputs\n",
    "y_test = shuffled_clean_output_df.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9)):]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test = shuffled_clean_input_df_7D.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9)):]\n",
    "# *************************************************************************** #\n",
    "\n",
    "\n",
    "# Deletes pandas dataframes that are no longer needed\n",
    "del target_df, input_df\n",
    "\n",
    "# Closes the HDFStore. This is good practice.\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>Ate</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.410133e-16</td>\n",
       "      <td>2.628174e-16</td>\n",
       "      <td>2.265683e-16</td>\n",
       "      <td>8.717152e-17</td>\n",
       "      <td>-1.748519e-17</td>\n",
       "      <td>-1.076100e-18</td>\n",
       "      <td>5.216605e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632300e+00</td>\n",
       "      <td>-1.639065e+00</td>\n",
       "      <td>-1.901001e+00</td>\n",
       "      <td>-8.370116e-01</td>\n",
       "      <td>-1.574307e+00</td>\n",
       "      <td>-1.405340e+00</td>\n",
       "      <td>-1.235044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.928000e-01</td>\n",
       "      <td>-7.898708e-01</td>\n",
       "      <td>-5.438138e-01</td>\n",
       "      <td>-6.367600e-01</td>\n",
       "      <td>-8.011463e-01</td>\n",
       "      <td>-9.907529e-01</td>\n",
       "      <td>-8.817246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.059360e-01</td>\n",
       "      <td>-9.507533e-02</td>\n",
       "      <td>1.347799e-01</td>\n",
       "      <td>-3.983652e-01</td>\n",
       "      <td>-1.936629e-01</td>\n",
       "      <td>-1.615792e-01</td>\n",
       "      <td>-1.750863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.809279e-01</td>\n",
       "      <td>5.997202e-01</td>\n",
       "      <td>6.437252e-01</td>\n",
       "      <td>1.976217e-01</td>\n",
       "      <td>9.108525e-01</td>\n",
       "      <td>6.675945e-01</td>\n",
       "      <td>7.576761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.641520e+00</td>\n",
       "      <td>2.684107e+00</td>\n",
       "      <td>1.831264e+00</td>\n",
       "      <td>2.581570e+00</td>\n",
       "      <td>1.739239e+00</td>\n",
       "      <td>1.704062e+00</td>\n",
       "      <td>1.944828e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati           Ate            An             q          smag  \\\n",
       "count  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06   \n",
       "mean  -1.410133e-16  2.628174e-16  2.265683e-16  8.717152e-17 -1.748519e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.632300e+00 -1.639065e+00 -1.901001e+00 -8.370116e-01 -1.574307e+00   \n",
       "25%   -7.928000e-01 -7.898708e-01 -5.438138e-01 -6.367600e-01 -8.011463e-01   \n",
       "50%   -1.059360e-01 -9.507533e-02  1.347799e-01 -3.983652e-01 -1.936629e-01   \n",
       "75%    5.809279e-01  5.997202e-01  6.437252e-01  1.976217e-01  9.108525e-01   \n",
       "max    2.641520e+00  2.684107e+00  1.831264e+00  2.581570e+00  1.739239e+00   \n",
       "\n",
       "                  x         Ti_Te  \n",
       "count  6.479137e+06  6.479137e+06  \n",
       "mean  -1.076100e-18  5.216605e-17  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -1.405340e+00 -1.235044e+00  \n",
       "25%   -9.907529e-01 -8.817246e-01  \n",
       "50%   -1.615792e-01 -1.750863e-01  \n",
       "75%    6.675945e-01  7.576761e-01  \n",
       "max    1.704062e+00  1.944828e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_7D.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe for the inputs\n",
    "shuffled_clean_input_df_1 = shuffled_clean_input_df_7D.drop('Ate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.410133e-16</td>\n",
       "      <td>2.265683e-16</td>\n",
       "      <td>8.717152e-17</td>\n",
       "      <td>-1.748519e-17</td>\n",
       "      <td>-1.076100e-18</td>\n",
       "      <td>5.216605e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632300e+00</td>\n",
       "      <td>-1.901001e+00</td>\n",
       "      <td>-8.370116e-01</td>\n",
       "      <td>-1.574307e+00</td>\n",
       "      <td>-1.405340e+00</td>\n",
       "      <td>-1.235044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.928000e-01</td>\n",
       "      <td>-5.438138e-01</td>\n",
       "      <td>-6.367600e-01</td>\n",
       "      <td>-8.011463e-01</td>\n",
       "      <td>-9.907529e-01</td>\n",
       "      <td>-8.817246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.059360e-01</td>\n",
       "      <td>1.347799e-01</td>\n",
       "      <td>-3.983652e-01</td>\n",
       "      <td>-1.936629e-01</td>\n",
       "      <td>-1.615792e-01</td>\n",
       "      <td>-1.750863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.809279e-01</td>\n",
       "      <td>6.437252e-01</td>\n",
       "      <td>1.976217e-01</td>\n",
       "      <td>9.108525e-01</td>\n",
       "      <td>6.675945e-01</td>\n",
       "      <td>7.576761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.641520e+00</td>\n",
       "      <td>1.831264e+00</td>\n",
       "      <td>2.581570e+00</td>\n",
       "      <td>1.739239e+00</td>\n",
       "      <td>1.704062e+00</td>\n",
       "      <td>1.944828e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati            An             q          smag             x  \\\n",
       "count  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06   \n",
       "mean  -1.410133e-16  2.265683e-16  8.717152e-17 -1.748519e-17 -1.076100e-18   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.632300e+00 -1.901001e+00 -8.370116e-01 -1.574307e+00 -1.405340e+00   \n",
       "25%   -7.928000e-01 -5.438138e-01 -6.367600e-01 -8.011463e-01 -9.907529e-01   \n",
       "50%   -1.059360e-01  1.347799e-01 -3.983652e-01 -1.936629e-01 -1.615792e-01   \n",
       "75%    5.809279e-01  6.437252e-01  1.976217e-01  9.108525e-01  6.675945e-01   \n",
       "max    2.641520e+00  1.831264e+00  2.581570e+00  1.739239e+00  1.704062e+00   \n",
       "\n",
       "              Ti_Te  \n",
       "count  6.479137e+06  \n",
       "mean   5.216605e-17  \n",
       "std    1.000000e+00  \n",
       "min   -1.235044e+00  \n",
       "25%   -8.817246e-01  \n",
       "50%   -1.750863e-01  \n",
       "75%    7.576761e-01  \n",
       "max    1.944828e+00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 6)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_7D.drop('Ati', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('An', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('q', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('smag', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('x', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('Ti_Te', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.628174e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.639065e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.898708e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.507533e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.997202e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.684107e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ate\n",
       "count  6.479137e+06\n",
       "mean   2.628174e-16\n",
       "std    1.000000e+00\n",
       "min   -1.639065e+00\n",
       "25%   -7.898708e-01\n",
       "50%   -9.507533e-02\n",
       "75%    5.997202e-01\n",
       "max    2.684107e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 1)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 1\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_1 = shuffled_clean_input_df_1.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_1 = shuffled_clean_input_df_1.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 2\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_2 = shuffled_clean_input_df_2.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_2 = shuffled_clean_input_df_2.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "6D_INPUTS (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch1 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch1 (Dense)         (None, 30)           930         hidden1_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1 (Dense)           (None, 1)            31          hidden2_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Ate_INPUT (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch3 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1_feeder (Dense)    (None, 1)            2           theta_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "visible_branch2_feeder (Dense)  (None, 1)            2           Ate_INPUT[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch3 (Dense)         (None, 30)           930         hidden1_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Addition_Pooling (Add)          (None, 1)            0           theta_branch1_feeder[0][0]       \n",
      "                                                                 visible_branch2_feeder[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3 (Dense)             (None, 1)            31          hidden2_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "TR (Dense)                      (None, 1)            2           Addition_Pooling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3_feeder (Dense)      (None, 1)            2           c_3_branch3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           TR[0][0]                         \n",
      "                                                                 c_3_branch3_feeder[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer (Dense)            (None, 1)            2           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,352\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# branch1\n",
    "visible_branch1 = Input(shape=(6, ), name=\"6D_INPUTS\")\n",
    "hidden1_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch1\")(visible_branch1)\n",
    "hidden2_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch1\")(hidden1_branch1)\n",
    "theta_branch1 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"theta_branch1\")(hidden2_branch1)\n",
    "theta_branch1_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=-1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"theta_branch1_feeder\")(theta_branch1)\n",
    "\n",
    "# branch2 (Ate input)\n",
    "visible_branch2 = Input(shape=(1, ), name=\"Ate_INPUT\")\n",
    "visible_branch2_feeder = Dense(1,\n",
    "                activation='linear',\n",
    "                name=\"visible_branch2_feeder\")(visible_branch2)\n",
    "\n",
    "# addition_pooling (effectively subtraction though...)\n",
    "addition_pooling = keras.layers.Add(name=\"Addition_Pooling\")([theta_branch1_feeder, visible_branch2_feeder])\n",
    "\n",
    "TR = Dense(1, activation='relu',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=False,\n",
    "           name=\"TR\")(addition_pooling)\n",
    "\n",
    "# branch 3 (for c_3)\n",
    "hidden1_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch3\")(visible_branch1)\n",
    "hidden2_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch3\")(hidden1_branch3)\n",
    "c_3_branch3 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"c_3_branch3\")(hidden2_branch3)\n",
    "c_3_branch3_feeder = Dense(1,\n",
    "        kernel_initializer=Constant(value=+1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"c_3_branch3_feeder\")(c_3_branch3)\n",
    "\n",
    "# Power_Pooling\n",
    "#merge = concatenate([TR, c_3_branch3_feeder], name=\"merge\")\n",
    "#power_pooling = Lambda(power_function, name=\"Power_Pooling\")(merge)\n",
    "#power_pooling = Lambda(lambda x: 1 ** x)(c_3_branch3_feeder)\n",
    "\n",
    "'''\n",
    "def power_lambda(x):\n",
    "    if x[0] <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x[0] ** x[1]\n",
    "'''\n",
    "    \n",
    "power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.00001, 1000)) ** (K.clip(K.abs(x[1]), -1., 3.)))\n",
    "#power_layer = Lambda(lambda x: K.tf.where(K.tf.less_equal(x[0], 1e-6), K.tf.fill(tf.shape(x[0]), 0.), K.abs(x[0]) ** K.clip(K.abs(x[1]), 0.5, 3.)))\n",
    "#power_layer = Lambda(lambda x: K.tf.where(K.tf.greater(x[0], 1e-6), K.tf.fill(tf.shape(x[0]), 0.), K.tf.fill(tf.shape(x[0]), 1000000000.)))\n",
    "\n",
    "power_pooling = power_layer([TR, c_3_branch3_feeder])\n",
    "\n",
    "\n",
    "# branch 4 (for the gradient)\n",
    "hidden1_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch4\")(visible_branch1)\n",
    "hidden2_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch4\")(hidden1_branch4)\n",
    "m_branch4 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"m_branch4\")(hidden2_branch4)\n",
    "m_branch4_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=+1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"m_branch4_feeder\")(m_branch4)\n",
    "\n",
    "# multiplication pooling\n",
    "multiplication_pooling = keras.layers.Multiply(name=\"Multiplication_Pooling\")([m_branch4_feeder, power_pooling])\n",
    "\n",
    "# interpretation model\n",
    "output = Dense(1, activation='linear',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=True,\n",
    "           name=\"Output_Layer\")(power_pooling)\n",
    "\n",
    "model = Model(inputs=[visible_branch1, visible_branch2], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph\n",
    "plot_model(model, 'ModelPlots/' + str(file_name) + '_model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from IPython import embed\n",
    "class NBatchLogger(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Logger that log average performance per `display` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.step += 1\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display\n",
    "                if abs(val) > 1e-3:\n",
    "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            if self.params['steps'] is None:\n",
    "                steps_per_epoch = int(numpy.ceil(self.params['samples'] / self.params['batch_size']))\n",
    "            else:\n",
    "                steps = self.params['steps']\n",
    "            #embed()\n",
    "            epoch = int(numpy.floor((self.step - 1)/ steps_per_epoch))\n",
    "            step_in_epoch = self.step - epoch * steps_per_epoch\n",
    "            print('step: {}/{} epoch {}: ... {}'.format(step_in_epoch,\n",
    "                                          steps_per_epoch,\n",
    "                                          epoch,\n",
    "                                          metrics_log))\n",
    "            self.metric_cache.clear()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5831223 samples, validate on 647914 samples\n",
      "Epoch 1/100\n",
      " - 665s - loss: 0.1510 - mean_absolute_error: 0.1042 - mean_squared_error: 0.1427 - rmse: 0.2448 - val_loss: 0.1625 - val_mean_absolute_error: 0.0953 - val_mean_squared_error: 0.1480 - val_rmse: 0.2402\n",
      "Epoch 2/100\n",
      " - 742s - loss: 0.1516 - mean_absolute_error: 0.0926 - mean_squared_error: 0.1304 - rmse: 0.2302 - val_loss: 0.1446 - val_mean_absolute_error: 0.0978 - val_mean_squared_error: 0.1171 - val_rmse: 0.2284\n",
      "Epoch 3/100\n",
      " - 740s - loss: 0.1605 - mean_absolute_error: 0.0926 - mean_squared_error: 0.1309 - rmse: 0.2299 - val_loss: 0.1511 - val_mean_absolute_error: 0.0904 - val_mean_squared_error: 0.1183 - val_rmse: 0.2178\n",
      "Epoch 4/100\n",
      " - 736s - loss: 0.1653 - mean_absolute_error: 0.0917 - mean_squared_error: 0.1286 - rmse: 0.2282 - val_loss: 0.1547 - val_mean_absolute_error: 0.0816 - val_mean_squared_error: 0.1134 - val_rmse: 0.2100\n",
      "Epoch 5/100\n",
      " - 736s - loss: 0.1689 - mean_absolute_error: 0.0910 - mean_squared_error: 0.1261 - rmse: 0.2256 - val_loss: 0.1670 - val_mean_absolute_error: 0.0826 - val_mean_squared_error: 0.1230 - val_rmse: 0.2176\n",
      "Epoch 6/100\n",
      " - 736s - loss: 0.1669 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1224 - rmse: 0.2226 - val_loss: 0.1558 - val_mean_absolute_error: 0.0806 - val_mean_squared_error: 0.1095 - val_rmse: 0.2061\n",
      "Epoch 7/100\n",
      " - 736s - loss: 0.1626 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1191 - rmse: 0.2199 - val_loss: 0.1509 - val_mean_absolute_error: 0.0815 - val_mean_squared_error: 0.1127 - val_rmse: 0.2074\n",
      "Epoch 8/100\n",
      " - 736s - loss: 0.1629 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1219 - rmse: 0.2222 - val_loss: 0.1730 - val_mean_absolute_error: 0.0880 - val_mean_squared_error: 0.1283 - val_rmse: 0.2222\n",
      "Epoch 9/100\n",
      " - 736s - loss: 0.1602 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1199 - rmse: 0.2207 - val_loss: 0.1537 - val_mean_absolute_error: 0.0852 - val_mean_squared_error: 0.1145 - val_rmse: 0.2108\n",
      "Epoch 10/100\n",
      " - 737s - loss: 0.1179 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1058 - rmse: 0.2099 - val_loss: 0.1491 - val_mean_absolute_error: 0.0889 - val_mean_squared_error: 0.1385 - val_rmse: 0.2305\n",
      "Epoch 11/100\n",
      " - 736s - loss: 0.1156 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1045 - rmse: 0.2103 - val_loss: 0.0984 - val_mean_absolute_error: 0.0869 - val_mean_squared_error: 0.0872 - val_rmse: 0.1936\n",
      "Epoch 12/100\n",
      " - 736s - loss: 0.1119 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1007 - rmse: 0.2068 - val_loss: 0.1155 - val_mean_absolute_error: 0.0902 - val_mean_squared_error: 0.1043 - val_rmse: 0.2128\n",
      "Epoch 13/100\n",
      " - 738s - loss: 0.1116 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1003 - rmse: 0.2068 - val_loss: 0.1286 - val_mean_absolute_error: 0.0901 - val_mean_squared_error: 0.1174 - val_rmse: 0.2245\n",
      "Epoch 14/100\n",
      " - 736s - loss: 0.1116 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1003 - rmse: 0.2067 - val_loss: 0.1123 - val_mean_absolute_error: 0.0896 - val_mean_squared_error: 0.1011 - val_rmse: 0.2160\n",
      "Epoch 15/100\n",
      " - 737s - loss: 0.1114 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1003 - rmse: 0.2066 - val_loss: 0.0979 - val_mean_absolute_error: 0.0852 - val_mean_squared_error: 0.0869 - val_rmse: 0.1922\n",
      "Epoch 16/100\n",
      " - 736s - loss: 0.1113 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1002 - rmse: 0.2065 - val_loss: 0.1066 - val_mean_absolute_error: 0.0892 - val_mean_squared_error: 0.0955 - val_rmse: 0.2069\n",
      "Epoch 17/100\n",
      " - 739s - loss: 0.1114 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1003 - rmse: 0.2064 - val_loss: 0.1254 - val_mean_absolute_error: 0.0866 - val_mean_squared_error: 0.1143 - val_rmse: 0.2201\n",
      "Epoch 18/100\n",
      " - 737s - loss: 0.1128 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1015 - rmse: 0.2070 - val_loss: 0.1010 - val_mean_absolute_error: 0.0808 - val_mean_squared_error: 0.0893 - val_rmse: 0.1892\n",
      "Epoch 19/100\n",
      " - 738s - loss: 0.1122 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1005 - rmse: 0.2073 - val_loss: 0.1135 - val_mean_absolute_error: 0.0813 - val_mean_squared_error: 0.1019 - val_rmse: 0.2060\n",
      "Epoch 20/100\n",
      " - 738s - loss: 0.1113 - mean_absolute_error: 0.0884 - mean_squared_error: 0.0999 - rmse: 0.2074 - val_loss: 0.1109 - val_mean_absolute_error: 0.0891 - val_mean_squared_error: 0.0996 - val_rmse: 0.2041\n",
      "Epoch 21/100\n",
      " - 738s - loss: 0.1122 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1008 - rmse: 0.2081 - val_loss: 0.1091 - val_mean_absolute_error: 0.0884 - val_mean_squared_error: 0.0975 - val_rmse: 0.2094\n",
      "Epoch 22/100\n",
      " - 739s - loss: 0.1112 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0998 - rmse: 0.2076 - val_loss: 0.1019 - val_mean_absolute_error: 0.0852 - val_mean_squared_error: 0.0905 - val_rmse: 0.1990\n",
      "Epoch 23/100\n",
      " - 739s - loss: 0.1111 - mean_absolute_error: 0.0887 - mean_squared_error: 0.0998 - rmse: 0.2076 - val_loss: 0.1081 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0968 - val_rmse: 0.1944\n",
      "Epoch 24/100\n",
      " - 737s - loss: 0.1114 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1001 - rmse: 0.2076 - val_loss: 0.1012 - val_mean_absolute_error: 0.0875 - val_mean_squared_error: 0.0899 - val_rmse: 0.1954\n",
      "Epoch 25/100\n",
      " - 735s - loss: 0.1154 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1039 - rmse: 0.2109 - val_loss: 0.2105 - val_mean_absolute_error: 0.1112 - val_mean_squared_error: 0.1936 - val_rmse: 0.2778\n",
      "Epoch 26/100\n",
      " - 736s - loss: 0.1429 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1178 - rmse: 0.2190 - val_loss: 0.1398 - val_mean_absolute_error: 0.0905 - val_mean_squared_error: 0.1147 - val_rmse: 0.2188\n",
      "Epoch 27/100\n",
      " - 722s - loss: 0.1420 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1167 - rmse: 0.2177 - val_loss: 0.1414 - val_mean_absolute_error: 0.0923 - val_mean_squared_error: 0.1128 - val_rmse: 0.2223\n",
      "Epoch 28/100\n",
      " - 605s - loss: 0.1432 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1160 - rmse: 0.2169 - val_loss: 0.1338 - val_mean_absolute_error: 0.0860 - val_mean_squared_error: 0.1045 - val_rmse: 0.2082\n",
      "Epoch 29/100\n",
      " - 606s - loss: 0.1354 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1114 - rmse: 0.2138 - val_loss: 0.1020 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0921 - val_rmse: 0.1927\n",
      "Epoch 30/100\n",
      " - 505s - loss: 0.1123 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1020 - rmse: 0.2080 - val_loss: 0.1008 - val_mean_absolute_error: 0.0847 - val_mean_squared_error: 0.0900 - val_rmse: 0.1961\n",
      "Epoch 31/100\n",
      " - 477s - loss: 0.1109 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1000 - rmse: 0.2075 - val_loss: 0.1048 - val_mean_absolute_error: 0.0814 - val_mean_squared_error: 0.0937 - val_rmse: 0.1993\n",
      "Epoch 32/100\n",
      " - 477s - loss: 0.1112 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1002 - rmse: 0.2075 - val_loss: 0.1008 - val_mean_absolute_error: 0.0800 - val_mean_squared_error: 0.0899 - val_rmse: 0.1927\n",
      "Epoch 33/100\n",
      " - 478s - loss: 0.1120 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1011 - rmse: 0.2088 - val_loss: 0.1154 - val_mean_absolute_error: 0.0916 - val_mean_squared_error: 0.1046 - val_rmse: 0.2176\n",
      "Test loss: 0.11536406635512123\n",
      "val_mean_absolute_error: 0.09162844257821248\n",
      "score\n",
      "[0.11536406635512123, 0.09162844257821248, 0.10455388966832004, 0.2786162780675191]\n",
      "model.metrics_names\n",
      "['loss', 'mean_absolute_error', 'mean_squared_error', 'rmse']\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',   #categorical_crossentropy\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"mae\", \"mean_squared_error\", rmse])\n",
    "\n",
    "# Add CallBacks (including TensorBoard)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "        log_dir='TensorBoard_logs/' + str(file_name), write_graph = False, write_images=False, write_grads=False)\n",
    "EarlyStoppingCallBack = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_rmse', min_delta=0, patience=15, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit([x_train_1, x_train_2],\n",
    "                    y = y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    # validation_data=(x_test, y_test),\n",
    "                    validation_data=([x_test_1, x_test_2], y_test),\n",
    "                    #callbacks=[tbCallBack, EarlyStoppingCallBack, NBatchLogger(5e4)])\n",
    "                    callbacks=[tbCallBack, EarlyStoppingCallBack])\n",
    "#5e4\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = model.evaluate([x_test_1, x_test_2], y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('val_mean_absolute_error:', score[1])\n",
    "\n",
    "print(\"score\")\n",
    "print(score)\n",
    "\n",
    "print(\"model.metrics_names\")\n",
    "print(model.metrics_names)\n",
    "\n",
    "# creates a HDF5 file 'my_model.h5'\n",
    "model.save(\"./Saved-Networks/\" + str(file_name) +\".h5\")\n",
    "\n",
    "# Create output file\n",
    "OutputFile = open(\"./Loss-Values/\" +str(file_name) +\".txt\", \"w+\")\n",
    "OutputFile.write(\"Test loss: \" + str(score[0]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_absolute_error: \" +str(score[1]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_squared_error: \" +str(score[2]) + \"\\n\")\n",
    "OutputFile.write(\"RMSE: \" +str(score[3]) + \"\\n\")\n",
    "OutputFile.close()\n",
    "\n",
    "del history\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0**1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "with tf_session.as_default():\n",
    "    display(((K.abs(0.)) ** (K.clip(K.abs(.5), 0.5, 3))).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
