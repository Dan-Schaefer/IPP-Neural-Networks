{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added the following:\n",
    "-  Dense layers have \"tanh\" activation function, L2 regularization, weights and biases have Glorot initialization:\n",
    "\n",
    "`hidden1_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal')(visible_branch1)`\n",
    "\n",
    "\n",
    "-  Output layer has linear activation function:\n",
    "\n",
    "`# interpretation model\n",
    "output = Dense(1, activation='linear')(merge)`\n",
    "\n",
    "\n",
    "-  Plotting an overview of the layers now works (fixed graphviz package not working):\n",
    "\n",
    "`# summarize layers\n",
    "print(model.summary())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Gets the current file name. Useful for procedurally generating output/log files.\n",
    "file_name =  os.path.basename(sys.argv[0][:-3])\n",
    "print(file_name)\n",
    "\n",
    "if file_name == \"ipykernel_launcher\":\n",
    "    print(\"This is the Jupyter version.\")\n",
    "    print(\"Now MANUALLY run the next two cells!\")\n",
    "    print(\"STOP! This should not be in your code!!\")\n",
    "    exit(0)\n",
    "    time.sleep(10)\n",
    "    print(\"Testing if script has really stopped.\")\n",
    "else:\n",
    "    print(\"This is the Atom version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IN JUPYTER!!\n",
    "# Start here (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-16_Run0101c.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-16_Run0101c\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "file_name = file_name[:-6]\n",
    "print(file_name)\n",
    "\n",
    "is_Jupyter = True\n",
    "print(is_Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code for both ATOM & JUPYTER from now (Run all cells below now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Late Fusion Module (test) - Functional API\n",
    "'''\n",
    "\n",
    "# Multiple Inputs\n",
    "import keras\n",
    "from keras.optimizers import RMSprop, adam, Adam\n",
    "from keras.initializers import TruncatedNormal, glorot_normal\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new Metric: rmse = Root Mean Square Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( y_true-y_pred )))\n",
    "\n",
    "# Define custon LateFusionActivation function\n",
    "def custom_activation(LateFusionActivation):\n",
    "    return TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify for ATOM use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_Jupyter == True:\n",
    "    pass\n",
    "else:\n",
    "    # Gets the current file name. Useful for procedurally generating output/log files.\n",
    "    file_name =  os.path.basename(sys.argv[0][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters\n",
    "batch_size = 10\n",
    "#num_classes = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (which is in HDF5 or .h5 format)\n",
    "store = pandas.HDFStore(\"unstable_training_gen3_7D_nions0_flat_filter8.h5\")\n",
    "target_df = store['/output/efeETG_GB'].to_frame()  # This one is relatively easy to train\n",
    "input_df = store['input']\n",
    "\n",
    "# Puts inputs and outputs in the same pandas dataframe.\n",
    "# Also only keeps overlapping entries.\n",
    "joined_dataFrame = target_df.join(input_df)\n",
    "\n",
    "# Make a copy of joined_dataFrame for later use\n",
    "joined_dataFrame_original = deepcopy(joined_dataFrame)\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "# Standard configuration\n",
    "joined_dataFrame['efeETG_GB'] = (joined_dataFrame['efeETG_GB'] - joined_dataFrame['efeETG_GB'].mean()) / joined_dataFrame['efeETG_GB'].std()\n",
    "joined_dataFrame['Ati'] = (joined_dataFrame['Ati'] - joined_dataFrame['Ati'].mean()) / joined_dataFrame['Ati'].std()\n",
    "joined_dataFrame['Ate'] = (joined_dataFrame['Ate'] - joined_dataFrame['Ate'].mean()) / joined_dataFrame['Ate'].std()\n",
    "joined_dataFrame['An'] = (joined_dataFrame['An'] - joined_dataFrame['An'].mean()) / joined_dataFrame['An'].std()\n",
    "joined_dataFrame['q'] = (joined_dataFrame['q'] - joined_dataFrame['q'].mean()) / joined_dataFrame['q'].std()\n",
    "joined_dataFrame['smag'] = (joined_dataFrame['smag'] - joined_dataFrame['smag'].mean()) / joined_dataFrame['smag'].std()\n",
    "joined_dataFrame['x'] = (joined_dataFrame['x'] - joined_dataFrame['x'].mean()) / joined_dataFrame['x'].std()\n",
    "joined_dataFrame['Ti_Te'] = (joined_dataFrame['Ti_Te'] - joined_dataFrame['Ti_Te'].mean()) / joined_dataFrame['Ti_Te'].std()\n",
    "\n",
    "# Shuffles dataset\n",
    "shuffled_joined_dataFrame = joined_dataFrame.reindex(numpy.random.permutation(\n",
    "                                                joined_dataFrame.index))\n",
    "\n",
    "# Creates a pandas dataframe for the outputs\n",
    "shuffled_clean_output_df = shuffled_joined_dataFrame['efeETG_GB']\n",
    "\n",
    "# Make a copy of shuffled_joined_dataFrame for later use\n",
    "shuffled_joined_dataFrame_base = deepcopy(shuffled_joined_dataFrame)\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Creates a pandas dataframe for the inputs (7D)\n",
    "shuffled_clean_input_df_7D = shuffled_joined_dataFrame.drop('efeETG_GB', axis=1)\n",
    "\n",
    "# Creates training dataset (90% of total data) for outputs\n",
    "y_train = shuffled_clean_output_df.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9))]\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train = shuffled_clean_input_df_7D.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for outputs\n",
    "y_test = shuffled_clean_output_df.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9)):]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test = shuffled_clean_input_df_7D.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9)):]\n",
    "# *************************************************************************** #\n",
    "\n",
    "\n",
    "# Deletes pandas dataframes that are no longer needed\n",
    "del target_df, input_df\n",
    "\n",
    "# Closes the HDFStore. This is good practice.\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>Ate</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.633424e-12</td>\n",
       "      <td>-6.496300e-13</td>\n",
       "      <td>-4.409594e-14</td>\n",
       "      <td>3.983713e-14</td>\n",
       "      <td>-8.762553e-14</td>\n",
       "      <td>2.687112e-14</td>\n",
       "      <td>5.456717e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.848237e+00</td>\n",
       "      <td>-2.151511e+00</td>\n",
       "      <td>-4.175202e+00</td>\n",
       "      <td>-8.733971e-01</td>\n",
       "      <td>-1.264253e+00</td>\n",
       "      <td>-1.375717e+00</td>\n",
       "      <td>-1.667450e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.585430e-01</td>\n",
       "      <td>-6.647545e-01</td>\n",
       "      <td>-6.345777e-01</td>\n",
       "      <td>-6.748652e-01</td>\n",
       "      <td>-3.148231e-01</td>\n",
       "      <td>-9.568879e-01</td>\n",
       "      <td>-9.268335e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.486741e-01</td>\n",
       "      <td>-1.691691e-01</td>\n",
       "      <td>-4.447369e-02</td>\n",
       "      <td>-4.385177e-01</td>\n",
       "      <td>-5.588771e-02</td>\n",
       "      <td>-1.192290e-01</td>\n",
       "      <td>-6.771858e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.161291e-01</td>\n",
       "      <td>4.916113e-01</td>\n",
       "      <td>5.456303e-01</td>\n",
       "      <td>1.523511e-01</td>\n",
       "      <td>4.619831e-01</td>\n",
       "      <td>7.184299e-01</td>\n",
       "      <td>4.210880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.910539e+00</td>\n",
       "      <td>1.813172e+00</td>\n",
       "      <td>2.315942e+00</td>\n",
       "      <td>2.515826e+00</td>\n",
       "      <td>3.914455e+00</td>\n",
       "      <td>1.765503e+00</td>\n",
       "      <td>1.665323e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati           Ate            An             q          smag  \\\n",
       "count  6.393280e+05  6.393280e+05  6.393280e+05  6.393280e+05  6.393280e+05   \n",
       "mean   1.633424e-12 -6.496300e-13 -4.409594e-14  3.983713e-14 -8.762553e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.848237e+00 -2.151511e+00 -4.175202e+00 -8.733971e-01 -1.264253e+00   \n",
       "25%   -6.585430e-01 -6.647545e-01 -6.345777e-01 -6.748652e-01 -3.148231e-01   \n",
       "50%   -1.486741e-01 -1.691691e-01 -4.447369e-02 -4.385177e-01 -5.588771e-02   \n",
       "75%    6.161291e-01  4.916113e-01  5.456303e-01  1.523511e-01  4.619831e-01   \n",
       "max    2.910539e+00  1.813172e+00  2.315942e+00  2.515826e+00  3.914455e+00   \n",
       "\n",
       "                  x         Ti_Te  \n",
       "count  6.393280e+05  6.393280e+05  \n",
       "mean   2.687112e-14  5.456717e-14  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -1.375717e+00 -1.667450e+00  \n",
       "25%   -9.568879e-01 -9.268335e-01  \n",
       "50%   -1.192290e-01 -6.771858e-02  \n",
       "75%    7.184299e-01  4.210880e-01  \n",
       "max    1.765503e+00  1.665323e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_7D.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe for the inputs\n",
    "shuffled_clean_input_df_1 = shuffled_clean_input_df_7D.drop('Ate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "      <td>6.393280e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.633424e-12</td>\n",
       "      <td>-4.409594e-14</td>\n",
       "      <td>3.983713e-14</td>\n",
       "      <td>-8.762553e-14</td>\n",
       "      <td>2.687112e-14</td>\n",
       "      <td>5.456717e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.848237e+00</td>\n",
       "      <td>-4.175202e+00</td>\n",
       "      <td>-8.733971e-01</td>\n",
       "      <td>-1.264253e+00</td>\n",
       "      <td>-1.375717e+00</td>\n",
       "      <td>-1.667450e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.585430e-01</td>\n",
       "      <td>-6.345777e-01</td>\n",
       "      <td>-6.748652e-01</td>\n",
       "      <td>-3.148231e-01</td>\n",
       "      <td>-9.568879e-01</td>\n",
       "      <td>-9.268335e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.486741e-01</td>\n",
       "      <td>-4.447369e-02</td>\n",
       "      <td>-4.385177e-01</td>\n",
       "      <td>-5.588771e-02</td>\n",
       "      <td>-1.192290e-01</td>\n",
       "      <td>-6.771858e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.161291e-01</td>\n",
       "      <td>5.456303e-01</td>\n",
       "      <td>1.523511e-01</td>\n",
       "      <td>4.619831e-01</td>\n",
       "      <td>7.184299e-01</td>\n",
       "      <td>4.210880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.910539e+00</td>\n",
       "      <td>2.315942e+00</td>\n",
       "      <td>2.515826e+00</td>\n",
       "      <td>3.914455e+00</td>\n",
       "      <td>1.765503e+00</td>\n",
       "      <td>1.665323e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati            An             q          smag             x  \\\n",
       "count  6.393280e+05  6.393280e+05  6.393280e+05  6.393280e+05  6.393280e+05   \n",
       "mean   1.633424e-12 -4.409594e-14  3.983713e-14 -8.762553e-14  2.687112e-14   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.848237e+00 -4.175202e+00 -8.733971e-01 -1.264253e+00 -1.375717e+00   \n",
       "25%   -6.585430e-01 -6.345777e-01 -6.748652e-01 -3.148231e-01 -9.568879e-01   \n",
       "50%   -1.486741e-01 -4.447369e-02 -4.385177e-01 -5.588771e-02 -1.192290e-01   \n",
       "75%    6.161291e-01  5.456303e-01  1.523511e-01  4.619831e-01  7.184299e-01   \n",
       "max    2.910539e+00  2.315942e+00  2.515826e+00  3.914455e+00  1.765503e+00   \n",
       "\n",
       "              Ti_Te  \n",
       "count  6.393280e+05  \n",
       "mean   5.456717e-14  \n",
       "std    1.000000e+00  \n",
       "min   -1.667450e+00  \n",
       "25%   -9.268335e-01  \n",
       "50%   -6.771858e-02  \n",
       "75%    4.210880e-01  \n",
       "max    1.665323e+00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639328, 6)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_7D.drop('Ati', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('An', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('q', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('smag', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('x', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('Ti_Te', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.393280e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-6.496300e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.151511e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.647545e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.691691e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.916113e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.813172e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ate\n",
       "count  6.393280e+05\n",
       "mean  -6.496300e-13\n",
       "std    1.000000e+00\n",
       "min   -2.151511e+00\n",
       "25%   -6.647545e-01\n",
       "50%   -1.691691e-01\n",
       "75%    4.916113e-01\n",
       "max    1.813172e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639328, 1)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 1\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_1 = shuffled_clean_input_df_1.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_1 = shuffled_clean_input_df_1.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 2\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_2 = shuffled_clean_input_df_2.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_2 = shuffled_clean_input_df_2.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           210         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           930         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 31)           0           dense_2[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            32          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,172\n",
      "Trainable params: 1,172\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# branch1\n",
    "visible_branch1 = Input(shape=(6,))\n",
    "hidden1_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal')(visible_branch1)\n",
    "hidden2_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal')(hidden1_branch1)\n",
    "\n",
    "# branch2\n",
    "visible_branch2 = Input(shape=(1,))\n",
    "\n",
    "# merge input models\n",
    "merge = concatenate([hidden2_branch1, visible_branch2])\n",
    "\n",
    "# interpretation model\n",
    "output = Dense(1, activation='linear')(merge)\n",
    "\n",
    "model = Model(inputs=[visible_branch1, visible_branch2], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "\n",
    "# plot graph\n",
    "plot_model(model, 'ModelPlots/' + str(file_name) + '_model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 575395 samples, validate on 63933 samples\n",
      "Epoch 1/100\n",
      " - 72s - loss: 0.2549 - mean_absolute_error: 0.3605 - mean_squared_error: 0.2503 - rmse: 0.4723 - val_loss: 0.2978 - val_mean_absolute_error: 0.3887 - val_mean_squared_error: 0.2922 - val_rmse: 0.4708\n",
      "Epoch 2/100\n",
      " - 77s - loss: 0.2118 - mean_absolute_error: 0.3256 - mean_squared_error: 0.2059 - rmse: 0.4300 - val_loss: 0.2892 - val_mean_absolute_error: 0.3861 - val_mean_squared_error: 0.2830 - val_rmse: 0.4661\n",
      "Epoch 3/100\n",
      " - 67s - loss: 0.2074 - mean_absolute_error: 0.3211 - mean_squared_error: 0.2009 - rmse: 0.4244 - val_loss: 0.2659 - val_mean_absolute_error: 0.3609 - val_mean_squared_error: 0.2592 - val_rmse: 0.4409\n",
      "Epoch 4/100\n",
      " - 72s - loss: 0.2053 - mean_absolute_error: 0.3189 - mean_squared_error: 0.1983 - rmse: 0.4217 - val_loss: 0.2652 - val_mean_absolute_error: 0.3667 - val_mean_squared_error: 0.2581 - val_rmse: 0.4490\n",
      "Epoch 5/100\n",
      " - 112s - loss: 0.2041 - mean_absolute_error: 0.3174 - mean_squared_error: 0.1968 - rmse: 0.4198 - val_loss: 0.2591 - val_mean_absolute_error: 0.3619 - val_mean_squared_error: 0.2517 - val_rmse: 0.4459\n",
      "Epoch 6/100\n",
      " - 84s - loss: 0.2033 - mean_absolute_error: 0.3163 - mean_squared_error: 0.1958 - rmse: 0.4187 - val_loss: 0.2586 - val_mean_absolute_error: 0.3622 - val_mean_squared_error: 0.2510 - val_rmse: 0.4414\n",
      "Epoch 7/100\n",
      " - 75s - loss: 0.2027 - mean_absolute_error: 0.3157 - mean_squared_error: 0.1950 - rmse: 0.4177 - val_loss: 0.2551 - val_mean_absolute_error: 0.3552 - val_mean_squared_error: 0.2473 - val_rmse: 0.4364\n",
      "Epoch 8/100\n",
      " - 227s - loss: 0.2023 - mean_absolute_error: 0.3149 - mean_squared_error: 0.1944 - rmse: 0.4171 - val_loss: 0.2689 - val_mean_absolute_error: 0.3673 - val_mean_squared_error: 0.2609 - val_rmse: 0.4505\n",
      "Epoch 9/100\n",
      " - 86s - loss: 0.2019 - mean_absolute_error: 0.3143 - mean_squared_error: 0.1939 - rmse: 0.4164 - val_loss: 0.2604 - val_mean_absolute_error: 0.3659 - val_mean_squared_error: 0.2524 - val_rmse: 0.4440\n",
      "Epoch 10/100\n",
      " - 84s - loss: 0.2016 - mean_absolute_error: 0.3143 - mean_squared_error: 0.1935 - rmse: 0.4162 - val_loss: 0.2605 - val_mean_absolute_error: 0.3666 - val_mean_squared_error: 0.2523 - val_rmse: 0.4502\n",
      "Epoch 11/100\n",
      " - 76s - loss: 0.2011 - mean_absolute_error: 0.3137 - mean_squared_error: 0.1929 - rmse: 0.4154 - val_loss: 0.2633 - val_mean_absolute_error: 0.3551 - val_mean_squared_error: 0.2551 - val_rmse: 0.4359\n",
      "Epoch 12/100\n",
      " - 81s - loss: 0.2009 - mean_absolute_error: 0.3135 - mean_squared_error: 0.1926 - rmse: 0.4151 - val_loss: 0.2836 - val_mean_absolute_error: 0.3787 - val_mean_squared_error: 0.2753 - val_rmse: 0.4599\n",
      "Epoch 13/100\n",
      " - 88s - loss: 0.2005 - mean_absolute_error: 0.3132 - mean_squared_error: 0.1922 - rmse: 0.4145 - val_loss: 0.3278 - val_mean_absolute_error: 0.3987 - val_mean_squared_error: 0.3195 - val_rmse: 0.4812\n",
      "Epoch 14/100\n",
      " - 95s - loss: 0.2005 - mean_absolute_error: 0.3131 - mean_squared_error: 0.1921 - rmse: 0.4144 - val_loss: 0.2572 - val_mean_absolute_error: 0.3610 - val_mean_squared_error: 0.2489 - val_rmse: 0.4390\n",
      "Epoch 15/100\n",
      " - 86s - loss: 0.2003 - mean_absolute_error: 0.3129 - mean_squared_error: 0.1919 - rmse: 0.4143 - val_loss: 0.2634 - val_mean_absolute_error: 0.3569 - val_mean_squared_error: 0.2550 - val_rmse: 0.4387\n",
      "Epoch 16/100\n",
      " - 82s - loss: 0.2002 - mean_absolute_error: 0.3129 - mean_squared_error: 0.1917 - rmse: 0.4139 - val_loss: 0.2565 - val_mean_absolute_error: 0.3598 - val_mean_squared_error: 0.2480 - val_rmse: 0.4426\n",
      "Epoch 17/100\n",
      " - 71s - loss: 0.2000 - mean_absolute_error: 0.3128 - mean_squared_error: 0.1915 - rmse: 0.4140 - val_loss: 0.2786 - val_mean_absolute_error: 0.3725 - val_mean_squared_error: 0.2702 - val_rmse: 0.4564\n",
      "Epoch 18/100\n",
      " - 67s - loss: 0.2000 - mean_absolute_error: 0.3128 - mean_squared_error: 0.1915 - rmse: 0.4139 - val_loss: 0.2514 - val_mean_absolute_error: 0.3527 - val_mean_squared_error: 0.2429 - val_rmse: 0.4344\n",
      "Epoch 19/100\n",
      " - 67s - loss: 0.1998 - mean_absolute_error: 0.3124 - mean_squared_error: 0.1914 - rmse: 0.4138 - val_loss: 0.2581 - val_mean_absolute_error: 0.3520 - val_mean_squared_error: 0.2495 - val_rmse: 0.4332\n",
      "Epoch 20/100\n",
      " - 70s - loss: 0.1997 - mean_absolute_error: 0.3124 - mean_squared_error: 0.1912 - rmse: 0.4135 - val_loss: 0.2492 - val_mean_absolute_error: 0.3549 - val_mean_squared_error: 0.2407 - val_rmse: 0.4359\n",
      "Epoch 21/100\n",
      " - 71s - loss: 0.1997 - mean_absolute_error: 0.3125 - mean_squared_error: 0.1911 - rmse: 0.4135 - val_loss: 0.2588 - val_mean_absolute_error: 0.3621 - val_mean_squared_error: 0.2503 - val_rmse: 0.4445\n",
      "Epoch 22/100\n",
      " - 65s - loss: 0.1994 - mean_absolute_error: 0.3123 - mean_squared_error: 0.1909 - rmse: 0.4132 - val_loss: 0.2833 - val_mean_absolute_error: 0.3709 - val_mean_squared_error: 0.2748 - val_rmse: 0.4538\n",
      "Epoch 23/100\n",
      " - 66s - loss: 0.1995 - mean_absolute_error: 0.3124 - mean_squared_error: 0.1909 - rmse: 0.4134 - val_loss: 0.2628 - val_mean_absolute_error: 0.3637 - val_mean_squared_error: 0.2542 - val_rmse: 0.4448\n",
      "Epoch 24/100\n",
      " - 68s - loss: 0.1995 - mean_absolute_error: 0.3123 - mean_squared_error: 0.1909 - rmse: 0.4135 - val_loss: 0.2672 - val_mean_absolute_error: 0.3624 - val_mean_squared_error: 0.2586 - val_rmse: 0.4447\n",
      "Epoch 25/100\n",
      " - 75s - loss: 0.1994 - mean_absolute_error: 0.3121 - mean_squared_error: 0.1908 - rmse: 0.4132 - val_loss: 0.2758 - val_mean_absolute_error: 0.3649 - val_mean_squared_error: 0.2672 - val_rmse: 0.4461\n",
      "Epoch 26/100\n",
      " - 136s - loss: 0.1994 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1908 - rmse: 0.4133 - val_loss: 0.2621 - val_mean_absolute_error: 0.3635 - val_mean_squared_error: 0.2535 - val_rmse: 0.4437\n",
      "Epoch 27/100\n",
      " - 73s - loss: 0.1992 - mean_absolute_error: 0.3119 - mean_squared_error: 0.1906 - rmse: 0.4129 - val_loss: 0.2668 - val_mean_absolute_error: 0.3678 - val_mean_squared_error: 0.2582 - val_rmse: 0.4506\n",
      "Epoch 28/100\n",
      " - 65s - loss: 0.1991 - mean_absolute_error: 0.3121 - mean_squared_error: 0.1905 - rmse: 0.4128 - val_loss: 0.2692 - val_mean_absolute_error: 0.3587 - val_mean_squared_error: 0.2606 - val_rmse: 0.4387\n",
      "Epoch 29/100\n",
      " - 72s - loss: 0.1992 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1905 - rmse: 0.4129 - val_loss: 0.2723 - val_mean_absolute_error: 0.3644 - val_mean_squared_error: 0.2636 - val_rmse: 0.4423\n",
      "Epoch 30/100\n",
      " - 71s - loss: 0.1992 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1905 - rmse: 0.4128 - val_loss: 0.2489 - val_mean_absolute_error: 0.3494 - val_mean_squared_error: 0.2402 - val_rmse: 0.4308\n",
      "Epoch 31/100\n",
      " - 73s - loss: 0.1990 - mean_absolute_error: 0.3118 - mean_squared_error: 0.1903 - rmse: 0.4126 - val_loss: 0.2634 - val_mean_absolute_error: 0.3613 - val_mean_squared_error: 0.2547 - val_rmse: 0.4439\n",
      "Epoch 32/100\n",
      " - 72s - loss: 0.1990 - mean_absolute_error: 0.3118 - mean_squared_error: 0.1903 - rmse: 0.4125 - val_loss: 0.3065 - val_mean_absolute_error: 0.3958 - val_mean_squared_error: 0.2978 - val_rmse: 0.4744\n",
      "Epoch 33/100\n",
      " - 70s - loss: 0.1990 - mean_absolute_error: 0.3117 - mean_squared_error: 0.1903 - rmse: 0.4126 - val_loss: 0.2966 - val_mean_absolute_error: 0.3880 - val_mean_squared_error: 0.2879 - val_rmse: 0.4652\n",
      "Epoch 34/100\n",
      " - 80s - loss: 0.1991 - mean_absolute_error: 0.3118 - mean_squared_error: 0.1904 - rmse: 0.4126 - val_loss: 0.2782 - val_mean_absolute_error: 0.3655 - val_mean_squared_error: 0.2694 - val_rmse: 0.4461\n",
      "Epoch 35/100\n",
      " - 71s - loss: 0.1990 - mean_absolute_error: 0.3118 - mean_squared_error: 0.1903 - rmse: 0.4124 - val_loss: 0.2701 - val_mean_absolute_error: 0.3593 - val_mean_squared_error: 0.2614 - val_rmse: 0.4413\n",
      "Epoch 36/100\n",
      " - 69s - loss: 0.1991 - mean_absolute_error: 0.3116 - mean_squared_error: 0.1904 - rmse: 0.4125 - val_loss: 0.2615 - val_mean_absolute_error: 0.3583 - val_mean_squared_error: 0.2528 - val_rmse: 0.4366\n",
      "Epoch 37/100\n",
      " - 76s - loss: 0.1991 - mean_absolute_error: 0.3116 - mean_squared_error: 0.1903 - rmse: 0.4126 - val_loss: 0.2509 - val_mean_absolute_error: 0.3488 - val_mean_squared_error: 0.2421 - val_rmse: 0.4314\n",
      "Epoch 38/100\n",
      " - 67s - loss: 0.1990 - mean_absolute_error: 0.3116 - mean_squared_error: 0.1902 - rmse: 0.4124 - val_loss: 0.2525 - val_mean_absolute_error: 0.3517 - val_mean_squared_error: 0.2437 - val_rmse: 0.4340\n",
      "Epoch 39/100\n",
      " - 74s - loss: 0.1990 - mean_absolute_error: 0.3115 - mean_squared_error: 0.1902 - rmse: 0.4125 - val_loss: 0.2532 - val_mean_absolute_error: 0.3560 - val_mean_squared_error: 0.2445 - val_rmse: 0.4359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      " - 66s - loss: 0.1990 - mean_absolute_error: 0.3117 - mean_squared_error: 0.1902 - rmse: 0.4125 - val_loss: 0.2585 - val_mean_absolute_error: 0.3520 - val_mean_squared_error: 0.2497 - val_rmse: 0.4348\n",
      "Epoch 41/100\n",
      " - 73s - loss: 0.1990 - mean_absolute_error: 0.3117 - mean_squared_error: 0.1902 - rmse: 0.4126 - val_loss: 0.2515 - val_mean_absolute_error: 0.3489 - val_mean_squared_error: 0.2428 - val_rmse: 0.4299\n",
      "Epoch 42/100\n",
      " - 74s - loss: 0.1990 - mean_absolute_error: 0.3116 - mean_squared_error: 0.1902 - rmse: 0.4124 - val_loss: 0.2619 - val_mean_absolute_error: 0.3578 - val_mean_squared_error: 0.2531 - val_rmse: 0.4383\n",
      "Epoch 43/100\n",
      " - 67s - loss: 0.1988 - mean_absolute_error: 0.3113 - mean_squared_error: 0.1900 - rmse: 0.4120 - val_loss: 0.2729 - val_mean_absolute_error: 0.3674 - val_mean_squared_error: 0.2641 - val_rmse: 0.4482\n",
      "Epoch 44/100\n",
      " - 74s - loss: 0.1989 - mean_absolute_error: 0.3114 - mean_squared_error: 0.1901 - rmse: 0.4121 - val_loss: 0.2511 - val_mean_absolute_error: 0.3465 - val_mean_squared_error: 0.2423 - val_rmse: 0.4266\n",
      "Epoch 45/100\n",
      " - 69s - loss: 0.1990 - mean_absolute_error: 0.3115 - mean_squared_error: 0.1902 - rmse: 0.4124 - val_loss: 0.2667 - val_mean_absolute_error: 0.3591 - val_mean_squared_error: 0.2579 - val_rmse: 0.4383\n",
      "Epoch 46/100\n",
      " - 69s - loss: 0.1987 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4122 - val_loss: 0.2572 - val_mean_absolute_error: 0.3551 - val_mean_squared_error: 0.2484 - val_rmse: 0.4367\n",
      "Epoch 47/100\n",
      " - 69s - loss: 0.1988 - mean_absolute_error: 0.3113 - mean_squared_error: 0.1900 - rmse: 0.4121 - val_loss: 0.2808 - val_mean_absolute_error: 0.3754 - val_mean_squared_error: 0.2720 - val_rmse: 0.4596\n",
      "Epoch 48/100\n",
      " - 71s - loss: 0.1989 - mean_absolute_error: 0.3114 - mean_squared_error: 0.1900 - rmse: 0.4121 - val_loss: 0.2542 - val_mean_absolute_error: 0.3537 - val_mean_squared_error: 0.2454 - val_rmse: 0.4367\n",
      "Epoch 49/100\n",
      " - 76s - loss: 0.1988 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4120 - val_loss: 0.2636 - val_mean_absolute_error: 0.3616 - val_mean_squared_error: 0.2547 - val_rmse: 0.4404\n",
      "Epoch 50/100\n",
      " - 68s - loss: 0.1987 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4118 - val_loss: 0.2580 - val_mean_absolute_error: 0.3470 - val_mean_squared_error: 0.2491 - val_rmse: 0.4287\n",
      "Epoch 51/100\n",
      " - 75s - loss: 0.1989 - mean_absolute_error: 0.3114 - mean_squared_error: 0.1901 - rmse: 0.4122 - val_loss: 0.2608 - val_mean_absolute_error: 0.3539 - val_mean_squared_error: 0.2519 - val_rmse: 0.4339\n",
      "Epoch 52/100\n",
      " - 73s - loss: 0.1989 - mean_absolute_error: 0.3113 - mean_squared_error: 0.1900 - rmse: 0.4122 - val_loss: 0.2671 - val_mean_absolute_error: 0.3691 - val_mean_squared_error: 0.2582 - val_rmse: 0.4517\n",
      "Epoch 53/100\n",
      " - 69s - loss: 0.1988 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4121 - val_loss: 0.2665 - val_mean_absolute_error: 0.3520 - val_mean_squared_error: 0.2576 - val_rmse: 0.4327\n",
      "Epoch 54/100\n",
      " - 73s - loss: 0.1988 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4121 - val_loss: 0.2683 - val_mean_absolute_error: 0.3579 - val_mean_squared_error: 0.2595 - val_rmse: 0.4378\n",
      "Epoch 55/100\n",
      " - 77s - loss: 0.1988 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4121 - val_loss: 0.2642 - val_mean_absolute_error: 0.3601 - val_mean_squared_error: 0.2553 - val_rmse: 0.4422\n",
      "Epoch 56/100\n",
      " - 78s - loss: 0.1987 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1898 - rmse: 0.4120 - val_loss: 0.2632 - val_mean_absolute_error: 0.3576 - val_mean_squared_error: 0.2543 - val_rmse: 0.4384\n",
      "Epoch 57/100\n",
      " - 86s - loss: 0.1987 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1898 - rmse: 0.4122 - val_loss: 0.2651 - val_mean_absolute_error: 0.3588 - val_mean_squared_error: 0.2562 - val_rmse: 0.4415\n",
      "Epoch 58/100\n",
      " - 81s - loss: 0.1988 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1899 - rmse: 0.4121 - val_loss: 0.2652 - val_mean_absolute_error: 0.3587 - val_mean_squared_error: 0.2563 - val_rmse: 0.4382\n",
      "Epoch 59/100\n",
      " - 84s - loss: 0.1989 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1900 - rmse: 0.4119 - val_loss: 0.2550 - val_mean_absolute_error: 0.3497 - val_mean_squared_error: 0.2461 - val_rmse: 0.4313\n",
      "Epoch 60/100\n",
      " - 76s - loss: 0.1987 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1898 - rmse: 0.4120 - val_loss: 0.2535 - val_mean_absolute_error: 0.3534 - val_mean_squared_error: 0.2446 - val_rmse: 0.4343\n",
      "Epoch 61/100\n",
      " - 71s - loss: 0.1987 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1898 - rmse: 0.4118 - val_loss: 0.2639 - val_mean_absolute_error: 0.3623 - val_mean_squared_error: 0.2549 - val_rmse: 0.4395\n",
      "Epoch 62/100\n",
      " - 75s - loss: 0.1987 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1898 - rmse: 0.4119 - val_loss: 0.2651 - val_mean_absolute_error: 0.3568 - val_mean_squared_error: 0.2562 - val_rmse: 0.4368\n",
      "Epoch 63/100\n",
      " - 73s - loss: 0.1988 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1899 - rmse: 0.4119 - val_loss: 0.2599 - val_mean_absolute_error: 0.3534 - val_mean_squared_error: 0.2510 - val_rmse: 0.4350\n",
      "Epoch 64/100\n",
      " - 74s - loss: 0.1987 - mean_absolute_error: 0.3111 - mean_squared_error: 0.1898 - rmse: 0.4119 - val_loss: 0.2725 - val_mean_absolute_error: 0.3587 - val_mean_squared_error: 0.2636 - val_rmse: 0.4408\n",
      "Epoch 65/100\n",
      " - 75s - loss: 0.1986 - mean_absolute_error: 0.3110 - mean_squared_error: 0.1896 - rmse: 0.4115 - val_loss: 0.2435 - val_mean_absolute_error: 0.3454 - val_mean_squared_error: 0.2346 - val_rmse: 0.4263\n",
      "Epoch 66/100\n",
      " - 82s - loss: 0.1986 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1896 - rmse: 0.4118 - val_loss: 0.2718 - val_mean_absolute_error: 0.3707 - val_mean_squared_error: 0.2628 - val_rmse: 0.4506\n",
      "Epoch 67/100\n",
      " - 69s - loss: 0.1985 - mean_absolute_error: 0.3110 - mean_squared_error: 0.1896 - rmse: 0.4118 - val_loss: 0.2756 - val_mean_absolute_error: 0.3691 - val_mean_squared_error: 0.2666 - val_rmse: 0.4452\n",
      "Epoch 68/100\n",
      " - 74s - loss: 0.1986 - mean_absolute_error: 0.3112 - mean_squared_error: 0.1897 - rmse: 0.4119 - val_loss: 0.2480 - val_mean_absolute_error: 0.3451 - val_mean_squared_error: 0.2390 - val_rmse: 0.4270\n",
      "Epoch 69/100\n",
      " - 67s - loss: 0.1985 - mean_absolute_error: 0.3110 - mean_squared_error: 0.1895 - rmse: 0.4116 - val_loss: 0.2650 - val_mean_absolute_error: 0.3601 - val_mean_squared_error: 0.2560 - val_rmse: 0.4388\n",
      "Epoch 70/100\n",
      " - 75s - loss: 0.1984 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1894 - rmse: 0.4115 - val_loss: 0.2612 - val_mean_absolute_error: 0.3577 - val_mean_squared_error: 0.2522 - val_rmse: 0.4405\n",
      "Epoch 71/100\n",
      " - 68s - loss: 0.1984 - mean_absolute_error: 0.3108 - mean_squared_error: 0.1894 - rmse: 0.4115 - val_loss: 0.2541 - val_mean_absolute_error: 0.3501 - val_mean_squared_error: 0.2451 - val_rmse: 0.4327\n",
      "Epoch 72/100\n",
      " - 73s - loss: 0.1985 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1895 - rmse: 0.4116 - val_loss: 0.2561 - val_mean_absolute_error: 0.3565 - val_mean_squared_error: 0.2471 - val_rmse: 0.4392\n",
      "Epoch 73/100\n",
      " - 75s - loss: 0.1983 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1893 - rmse: 0.4115 - val_loss: 0.2616 - val_mean_absolute_error: 0.3557 - val_mean_squared_error: 0.2526 - val_rmse: 0.4399\n",
      "Epoch 74/100\n",
      " - 92s - loss: 0.1984 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1894 - rmse: 0.4114 - val_loss: 0.2624 - val_mean_absolute_error: 0.3570 - val_mean_squared_error: 0.2533 - val_rmse: 0.4378\n",
      "Epoch 75/100\n",
      " - 79s - loss: 0.1983 - mean_absolute_error: 0.3108 - mean_squared_error: 0.1893 - rmse: 0.4114 - val_loss: 0.2973 - val_mean_absolute_error: 0.3816 - val_mean_squared_error: 0.2883 - val_rmse: 0.4635\n",
      "Epoch 76/100\n",
      " - 88s - loss: 0.1983 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1893 - rmse: 0.4113 - val_loss: 0.2642 - val_mean_absolute_error: 0.3545 - val_mean_squared_error: 0.2552 - val_rmse: 0.4359\n",
      "Epoch 77/100\n",
      " - 74s - loss: 0.1984 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1893 - rmse: 0.4113 - val_loss: 0.2590 - val_mean_absolute_error: 0.3497 - val_mean_squared_error: 0.2499 - val_rmse: 0.4318\n",
      "Epoch 78/100\n",
      " - 67s - loss: 0.1985 - mean_absolute_error: 0.3109 - mean_squared_error: 0.1894 - rmse: 0.4115 - val_loss: 0.2781 - val_mean_absolute_error: 0.3603 - val_mean_squared_error: 0.2690 - val_rmse: 0.4416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      " - 72s - loss: 0.1983 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1892 - rmse: 0.4111 - val_loss: 0.2636 - val_mean_absolute_error: 0.3585 - val_mean_squared_error: 0.2545 - val_rmse: 0.4376\n",
      "Epoch 80/100\n",
      " - 68s - loss: 0.1983 - mean_absolute_error: 0.3108 - mean_squared_error: 0.1892 - rmse: 0.4113 - val_loss: 0.2490 - val_mean_absolute_error: 0.3473 - val_mean_squared_error: 0.2399 - val_rmse: 0.4290\n",
      "Epoch 81/100\n",
      " - 77s - loss: 0.1983 - mean_absolute_error: 0.3108 - mean_squared_error: 0.1892 - rmse: 0.4114 - val_loss: 0.2562 - val_mean_absolute_error: 0.3493 - val_mean_squared_error: 0.2470 - val_rmse: 0.4291\n",
      "Epoch 82/100\n",
      " - 67s - loss: 0.1984 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1892 - rmse: 0.4114 - val_loss: 0.2658 - val_mean_absolute_error: 0.3611 - val_mean_squared_error: 0.2567 - val_rmse: 0.4413\n",
      "Epoch 83/100\n",
      " - 73s - loss: 0.1984 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1892 - rmse: 0.4113 - val_loss: 0.2531 - val_mean_absolute_error: 0.3565 - val_mean_squared_error: 0.2439 - val_rmse: 0.4399\n",
      "Epoch 84/100\n",
      " - 72s - loss: 0.1983 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1891 - rmse: 0.4110 - val_loss: 0.2514 - val_mean_absolute_error: 0.3469 - val_mean_squared_error: 0.2422 - val_rmse: 0.4278\n",
      "Epoch 85/100\n",
      " - 74s - loss: 0.1983 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1891 - rmse: 0.4110 - val_loss: 0.2503 - val_mean_absolute_error: 0.3508 - val_mean_squared_error: 0.2411 - val_rmse: 0.4320\n",
      "Epoch 86/100\n",
      " - 73s - loss: 0.1982 - mean_absolute_error: 0.3106 - mean_squared_error: 0.1890 - rmse: 0.4110 - val_loss: 0.2632 - val_mean_absolute_error: 0.3524 - val_mean_squared_error: 0.2540 - val_rmse: 0.4334\n",
      "Epoch 87/100\n",
      " - 68s - loss: 0.1982 - mean_absolute_error: 0.3106 - mean_squared_error: 0.1890 - rmse: 0.4112 - val_loss: 0.2484 - val_mean_absolute_error: 0.3491 - val_mean_squared_error: 0.2391 - val_rmse: 0.4293\n",
      "Epoch 88/100\n",
      " - 80s - loss: 0.1983 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1890 - rmse: 0.4112 - val_loss: 0.2845 - val_mean_absolute_error: 0.3741 - val_mean_squared_error: 0.2753 - val_rmse: 0.4557\n",
      "Epoch 89/100\n",
      " - 82s - loss: 0.1982 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1890 - rmse: 0.4112 - val_loss: 0.2611 - val_mean_absolute_error: 0.3523 - val_mean_squared_error: 0.2518 - val_rmse: 0.4344\n",
      "Epoch 90/100\n",
      " - 79s - loss: 0.1981 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1889 - rmse: 0.4110 - val_loss: 0.2560 - val_mean_absolute_error: 0.3514 - val_mean_squared_error: 0.2468 - val_rmse: 0.4364\n",
      "Epoch 91/100\n",
      " - 74s - loss: 0.1983 - mean_absolute_error: 0.3106 - mean_squared_error: 0.1891 - rmse: 0.4112 - val_loss: 0.2652 - val_mean_absolute_error: 0.3546 - val_mean_squared_error: 0.2560 - val_rmse: 0.4359\n",
      "Epoch 92/100\n",
      " - 88s - loss: 0.1984 - mean_absolute_error: 0.3107 - mean_squared_error: 0.1892 - rmse: 0.4112 - val_loss: 0.2539 - val_mean_absolute_error: 0.3456 - val_mean_squared_error: 0.2446 - val_rmse: 0.4259\n",
      "Epoch 93/100\n",
      " - 72s - loss: 0.1983 - mean_absolute_error: 0.3106 - mean_squared_error: 0.1890 - rmse: 0.4110 - val_loss: 0.2619 - val_mean_absolute_error: 0.3524 - val_mean_squared_error: 0.2527 - val_rmse: 0.4349\n",
      "Epoch 94/100\n",
      " - 79s - loss: 0.1983 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1891 - rmse: 0.4111 - val_loss: 0.2586 - val_mean_absolute_error: 0.3515 - val_mean_squared_error: 0.2494 - val_rmse: 0.4351\n",
      "Epoch 95/100\n",
      " - 81s - loss: 0.1983 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1890 - rmse: 0.4110 - val_loss: 0.2503 - val_mean_absolute_error: 0.3475 - val_mean_squared_error: 0.2410 - val_rmse: 0.4305\n",
      "Epoch 96/100\n",
      " - 74s - loss: 0.1982 - mean_absolute_error: 0.3106 - mean_squared_error: 0.1890 - rmse: 0.4110 - val_loss: 0.2878 - val_mean_absolute_error: 0.3723 - val_mean_squared_error: 0.2785 - val_rmse: 0.4510\n",
      "Epoch 97/100\n",
      " - 99s - loss: 0.1984 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1891 - rmse: 0.4110 - val_loss: 0.2711 - val_mean_absolute_error: 0.3703 - val_mean_squared_error: 0.2618 - val_rmse: 0.4477\n",
      "Epoch 98/100\n",
      " - 86s - loss: 0.1983 - mean_absolute_error: 0.3106 - mean_squared_error: 0.1890 - rmse: 0.4111 - val_loss: 0.2579 - val_mean_absolute_error: 0.3497 - val_mean_squared_error: 0.2487 - val_rmse: 0.4341\n",
      "Epoch 99/100\n",
      " - 86s - loss: 0.1982 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1889 - rmse: 0.4107 - val_loss: 0.2544 - val_mean_absolute_error: 0.3581 - val_mean_squared_error: 0.2451 - val_rmse: 0.4367\n",
      "Epoch 100/100\n",
      " - 80s - loss: 0.1983 - mean_absolute_error: 0.3105 - mean_squared_error: 0.1890 - rmse: 0.4112 - val_loss: 0.2731 - val_mean_absolute_error: 0.3643 - val_mean_squared_error: 0.2638 - val_rmse: 0.4452\n",
      "Test loss: 0.2730659880845913\n",
      "val_mean_absolute_error: 0.3642691452105523\n",
      "score\n",
      "[0.2730659880845913, 0.3642691452105523, 0.2637864186353627, 0.462544815074873]\n",
      "model.metrics_names\n",
      "['loss', 'mean_absolute_error', 'mean_squared_error', 'rmse']\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',   #categorical_crossentropy\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"mae\", \"mean_squared_error\", rmse])\n",
    "\n",
    "# Add CallBacks (including TensorBoard)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "        log_dir='TensorBoard_logs/' + str(file_name), write_graph = False, write_images=False, write_grads=False)\n",
    "EarlyStoppingCallBack = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_rmse', min_delta=0, patience=15, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit([x_train_1, x_train_2],\n",
    "                    y = y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    # validation_data=(x_test, y_test),\n",
    "                    validation_data=([x_test_1, x_test_2], y_test),\n",
    "                    callbacks=[tbCallBack])\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = model.evaluate([x_test_1, x_test_2], y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('val_mean_absolute_error:', score[1])\n",
    "\n",
    "print(\"score\")\n",
    "print(score)\n",
    "\n",
    "print(\"model.metrics_names\")\n",
    "print(model.metrics_names)\n",
    "\n",
    "# creates a HDF5 file 'my_model.h5'\n",
    "model.save(\"./Saved-Networks/\" + str(file_name) +\".h5\")\n",
    "\n",
    "# Create output file\n",
    "OutputFile = open(\"./Loss-Values/\" +str(file_name) +\".txt\", \"w+\")\n",
    "OutputFile.write(\"Test loss: \" + str(score[0]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_absolute_error: \" +str(score[1]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_squared_error: \" +str(score[2]) + \"\\n\")\n",
    "OutputFile.write(\"RMSE: \" +str(score[3]) + \"\\n\")\n",
    "OutputFile.close()\n",
    "\n",
    "del history\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
