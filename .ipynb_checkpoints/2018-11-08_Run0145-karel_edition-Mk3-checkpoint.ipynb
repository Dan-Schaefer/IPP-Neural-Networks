{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run0145-karel_edition-Mk3\n",
    "\n",
    "\n",
    "Replaced\n",
    "\n",
    "```power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.0, 10)) ** (K.clip(K.abs(x[1]), 0.0, 2.0)))```\n",
    "\n",
    "with\n",
    "\n",
    "```power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.0, 10)) ** (K.clip(K.abs(x[1]), 1.0, 2.0)))```\n",
    "\n",
    "\n",
    "-  Karel didn't connect up the `m_branch` in `Run0145-karel_edition-Mk2`. This has now been added back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Gets the current file name. Useful for procedurally generating output/log files.\n",
    "file_name =  os.path.basename(sys.argv[0][:-3])\n",
    "print(file_name)\n",
    "\n",
    "if file_name == \"ipykernel_launcher\":\n",
    "    print(\"This is the Jupyter version.\")\n",
    "    print(\"Now MANUALLY run the next two cells!\")\n",
    "    print(\"STOP! This should not be in your code!!\")\n",
    "    exit(0)\n",
    "    time.sleep(10)\n",
    "    print(\"Testing if script has really stopped.\")\n",
    "else:\n",
    "    print(\"This is the Atom version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IN JUPYTER!!\n",
    "# Start here (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-08_Run0145-karel_edition-Mk3.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-08_Run0145-karel_edition-Mk3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "file_name = file_name[:-6]\n",
    "print(file_name)\n",
    "\n",
    "is_Jupyter = True\n",
    "print(is_Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code for both ATOM & JUPYTER from now (Run all cells below now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Late Fusion Module (test) - Functional API\n",
    "'''\n",
    "\n",
    "# Multiple Inputs\n",
    "import keras\n",
    "from keras.optimizers import RMSprop, adam, Adam\n",
    "from keras.initializers import TruncatedNormal, glorot_normal, Constant\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "#from keras.backend import switch\n",
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "\n",
    "#keras.backend.clear_session()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new Metric: rmse = Root Mean Square Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( y_true-y_pred )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify for ATOM use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_Jupyter == True:\n",
    "    pass\n",
    "else:\n",
    "    # Gets the current file name. Useful for procedurally generating output/log files.\n",
    "    file_name =  os.path.basename(sys.argv[0][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters\n",
    "batch_size = 10\n",
    "#num_classes = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (which is in HDF5 or .h5 format)\n",
    "store = pandas.HDFStore(\"training_gen3_7D_nions0_flat_filter8.h5\")\n",
    "target_df = store['/output/efeETG_GB'].to_frame()  # This one is relatively easy to train\n",
    "input_df = store['input']\n",
    "\n",
    "# Puts inputs and outputs in the same pandas dataframe.\n",
    "# Also only keeps overlapping entries.\n",
    "joined_dataFrame = target_df.join(input_df)\n",
    "\n",
    "# Make a copy of joined_dataFrame for later use\n",
    "joined_dataFrame_original = deepcopy(joined_dataFrame)\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "# Standard configuration\n",
    "joined_dataFrame['efeETG_GB'] = (joined_dataFrame['efeETG_GB'] - joined_dataFrame['efeETG_GB'].mean()) / joined_dataFrame['efeETG_GB'].std()\n",
    "joined_dataFrame['Ati'] = (joined_dataFrame['Ati'] - joined_dataFrame['Ati'].mean()) / joined_dataFrame['Ati'].std()\n",
    "joined_dataFrame['Ate'] = (joined_dataFrame['Ate'] - joined_dataFrame['Ate'].mean()) / joined_dataFrame['Ate'].std()\n",
    "joined_dataFrame['An'] = (joined_dataFrame['An'] - joined_dataFrame['An'].mean()) / joined_dataFrame['An'].std()\n",
    "joined_dataFrame['q'] = (joined_dataFrame['q'] - joined_dataFrame['q'].mean()) / joined_dataFrame['q'].std()\n",
    "joined_dataFrame['smag'] = (joined_dataFrame['smag'] - joined_dataFrame['smag'].mean()) / joined_dataFrame['smag'].std()\n",
    "joined_dataFrame['x'] = (joined_dataFrame['x'] - joined_dataFrame['x'].mean()) / joined_dataFrame['x'].std()\n",
    "joined_dataFrame['Ti_Te'] = (joined_dataFrame['Ti_Te'] - joined_dataFrame['Ti_Te'].mean()) / joined_dataFrame['Ti_Te'].std()\n",
    "\n",
    "# Shuffles dataset\n",
    "shuffled_joined_dataFrame = joined_dataFrame.reindex(numpy.random.permutation(\n",
    "                                                joined_dataFrame.index))\n",
    "\n",
    "# Creates a pandas dataframe for the outputs\n",
    "shuffled_clean_output_df = shuffled_joined_dataFrame['efeETG_GB']\n",
    "\n",
    "# Make a copy of shuffled_joined_dataFrame for later use\n",
    "shuffled_joined_dataFrame_base = deepcopy(shuffled_joined_dataFrame)\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Creates a pandas dataframe for the inputs (7D)\n",
    "shuffled_clean_input_df_7D = shuffled_joined_dataFrame.drop('efeETG_GB', axis=1)\n",
    "\n",
    "# Creates training dataset (90% of total data) for outputs\n",
    "y_train = shuffled_clean_output_df.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9))]\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train = shuffled_clean_input_df_7D.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for outputs\n",
    "y_test = shuffled_clean_output_df.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9)):]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test = shuffled_clean_input_df_7D.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9)):]\n",
    "# *************************************************************************** #\n",
    "\n",
    "\n",
    "# Deletes pandas dataframes that are no longer needed\n",
    "del target_df, input_df\n",
    "\n",
    "# Closes the HDFStore. This is good practice.\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>Ate</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.408126e-16</td>\n",
       "      <td>2.629128e-16</td>\n",
       "      <td>2.264543e-16</td>\n",
       "      <td>8.714849e-17</td>\n",
       "      <td>-1.771987e-17</td>\n",
       "      <td>-6.755442e-19</td>\n",
       "      <td>5.202348e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632300e+00</td>\n",
       "      <td>-1.639065e+00</td>\n",
       "      <td>-1.901001e+00</td>\n",
       "      <td>-8.370116e-01</td>\n",
       "      <td>-1.574307e+00</td>\n",
       "      <td>-1.405340e+00</td>\n",
       "      <td>-1.235044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.928000e-01</td>\n",
       "      <td>-7.898708e-01</td>\n",
       "      <td>-5.438138e-01</td>\n",
       "      <td>-6.367600e-01</td>\n",
       "      <td>-8.011463e-01</td>\n",
       "      <td>-9.907529e-01</td>\n",
       "      <td>-8.817246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.059360e-01</td>\n",
       "      <td>-9.507533e-02</td>\n",
       "      <td>1.347799e-01</td>\n",
       "      <td>-3.983652e-01</td>\n",
       "      <td>-1.936629e-01</td>\n",
       "      <td>-1.615792e-01</td>\n",
       "      <td>-1.750863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.809279e-01</td>\n",
       "      <td>5.997202e-01</td>\n",
       "      <td>6.437252e-01</td>\n",
       "      <td>1.976217e-01</td>\n",
       "      <td>9.108525e-01</td>\n",
       "      <td>6.675945e-01</td>\n",
       "      <td>7.576761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.641520e+00</td>\n",
       "      <td>2.684107e+00</td>\n",
       "      <td>1.831264e+00</td>\n",
       "      <td>2.581570e+00</td>\n",
       "      <td>1.739239e+00</td>\n",
       "      <td>1.704062e+00</td>\n",
       "      <td>1.944828e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati           Ate            An             q          smag  \\\n",
       "count  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06   \n",
       "mean  -1.408126e-16  2.629128e-16  2.264543e-16  8.714849e-17 -1.771987e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.632300e+00 -1.639065e+00 -1.901001e+00 -8.370116e-01 -1.574307e+00   \n",
       "25%   -7.928000e-01 -7.898708e-01 -5.438138e-01 -6.367600e-01 -8.011463e-01   \n",
       "50%   -1.059360e-01 -9.507533e-02  1.347799e-01 -3.983652e-01 -1.936629e-01   \n",
       "75%    5.809279e-01  5.997202e-01  6.437252e-01  1.976217e-01  9.108525e-01   \n",
       "max    2.641520e+00  2.684107e+00  1.831264e+00  2.581570e+00  1.739239e+00   \n",
       "\n",
       "                  x         Ti_Te  \n",
       "count  6.479137e+06  6.479137e+06  \n",
       "mean  -6.755442e-19  5.202348e-17  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -1.405340e+00 -1.235044e+00  \n",
       "25%   -9.907529e-01 -8.817246e-01  \n",
       "50%   -1.615792e-01 -1.750863e-01  \n",
       "75%    6.675945e-01  7.576761e-01  \n",
       "max    1.704062e+00  1.944828e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_7D.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe for the inputs\n",
    "shuffled_clean_input_df_1 = shuffled_clean_input_df_7D.drop('Ate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.408126e-16</td>\n",
       "      <td>2.264543e-16</td>\n",
       "      <td>8.714849e-17</td>\n",
       "      <td>-1.771987e-17</td>\n",
       "      <td>-6.755442e-19</td>\n",
       "      <td>5.202348e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632300e+00</td>\n",
       "      <td>-1.901001e+00</td>\n",
       "      <td>-8.370116e-01</td>\n",
       "      <td>-1.574307e+00</td>\n",
       "      <td>-1.405340e+00</td>\n",
       "      <td>-1.235044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.928000e-01</td>\n",
       "      <td>-5.438138e-01</td>\n",
       "      <td>-6.367600e-01</td>\n",
       "      <td>-8.011463e-01</td>\n",
       "      <td>-9.907529e-01</td>\n",
       "      <td>-8.817246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.059360e-01</td>\n",
       "      <td>1.347799e-01</td>\n",
       "      <td>-3.983652e-01</td>\n",
       "      <td>-1.936629e-01</td>\n",
       "      <td>-1.615792e-01</td>\n",
       "      <td>-1.750863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.809279e-01</td>\n",
       "      <td>6.437252e-01</td>\n",
       "      <td>1.976217e-01</td>\n",
       "      <td>9.108525e-01</td>\n",
       "      <td>6.675945e-01</td>\n",
       "      <td>7.576761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.641520e+00</td>\n",
       "      <td>1.831264e+00</td>\n",
       "      <td>2.581570e+00</td>\n",
       "      <td>1.739239e+00</td>\n",
       "      <td>1.704062e+00</td>\n",
       "      <td>1.944828e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati            An             q          smag             x  \\\n",
       "count  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06   \n",
       "mean  -1.408126e-16  2.264543e-16  8.714849e-17 -1.771987e-17 -6.755442e-19   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.632300e+00 -1.901001e+00 -8.370116e-01 -1.574307e+00 -1.405340e+00   \n",
       "25%   -7.928000e-01 -5.438138e-01 -6.367600e-01 -8.011463e-01 -9.907529e-01   \n",
       "50%   -1.059360e-01  1.347799e-01 -3.983652e-01 -1.936629e-01 -1.615792e-01   \n",
       "75%    5.809279e-01  6.437252e-01  1.976217e-01  9.108525e-01  6.675945e-01   \n",
       "max    2.641520e+00  1.831264e+00  2.581570e+00  1.739239e+00  1.704062e+00   \n",
       "\n",
       "              Ti_Te  \n",
       "count  6.479137e+06  \n",
       "mean   5.202348e-17  \n",
       "std    1.000000e+00  \n",
       "min   -1.235044e+00  \n",
       "25%   -8.817246e-01  \n",
       "50%   -1.750863e-01  \n",
       "75%    7.576761e-01  \n",
       "max    1.944828e+00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 6)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_7D.drop('Ati', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('An', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('q', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('smag', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('x', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('Ti_Te', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.629128e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.639065e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.898708e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.507533e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.997202e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.684107e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ate\n",
       "count  6.479137e+06\n",
       "mean   2.629128e-16\n",
       "std    1.000000e+00\n",
       "min   -1.639065e+00\n",
       "25%   -7.898708e-01\n",
       "50%   -9.507533e-02\n",
       "75%    5.997202e-01\n",
       "max    2.684107e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 1)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 1\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_1 = shuffled_clean_input_df_1.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_1 = shuffled_clean_input_df_1.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 2\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_2 = shuffled_clean_input_df_2.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_2 = shuffled_clean_input_df_2.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[7].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[3].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[14] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[14].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def power_function(x):\n",
    "    #from keras import backend as K\n",
    "    x = model.get_layer(\"c_3_branch3_feeder\").get_weights()[0]\n",
    "    c_3 = K.cast(x, dtype='float32')\n",
    "    if (c_3 >= 0.0):\n",
    "        return c_3\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    return 1.0 ** c_3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def power_function(x):\n",
    "    #from keras import backend as K\n",
    "    x = model.get_layer(\"c_3_branch3_feeder\").get_weights()[0]\n",
    "    c_3 = K.cast(x, dtype='float32')\n",
    "    #if (c_3 >= 0.0):\n",
    "    #    pass\n",
    "    #else:\n",
    "    #    c_3 = 0.0\n",
    "    #\n",
    "    return 1.0 ** c_3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def power_function(x):\n",
    "    print(\"counter = 0\")\n",
    "    print(\"x: \")\n",
    "    print(x)\n",
    "    print(\"type(x): \")\n",
    "    print(type(x))\n",
    "    counter = 1\n",
    "    if (counter == 0):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"counter = 1\")\n",
    "        print(\"x: \")\n",
    "        print(x)\n",
    "        print(\"type(x): \")\n",
    "        print(type(x))\n",
    "        a = K.cast(x, dtype='float32')\n",
    "        print(\"a: \")\n",
    "        print(a)\n",
    "        try:\n",
    "            print(model.layers[14])\n",
    "            c_3 = model.layers[14].get_weights()[0][0][0]\n",
    "            print(c_3)\n",
    "            print(\"type(c_3): \")\n",
    "            print(type(c_3))\n",
    "            if (c_3 >= 0.0):\n",
    "                pass\n",
    "            else:\n",
    "                c_3 = 0.0\n",
    "            pooling = 1.0 ** c_3\n",
    "            power_pooling_output = K.cast(pooling, dtype='float32')\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "    return power_pooling_output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Lambda(lambda x: 1 ** x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "6D_INPUTS (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch1 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch1 (Dense)         (None, 30)           930         hidden1_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1 (Dense)           (None, 1)            31          hidden2_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Ate_INPUT (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch3 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch4 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1_feeder (Dense)    (None, 1)            2           theta_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "visible_branch2_feeder (Dense)  (None, 1)            2           Ate_INPUT[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch3 (Dense)         (None, 30)           930         hidden1_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch4 (Dense)         (None, 30)           930         hidden1_branch4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Addition_Pooling (Add)          (None, 1)            0           theta_branch1_feeder[0][0]       \n",
      "                                                                 visible_branch2_feeder[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3 (Dense)             (None, 1)            31          hidden2_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "m_branch4 (Dense)               (None, 1)            31          hidden2_branch4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "TR (Dense)                      (None, 1)            2           Addition_Pooling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3_feeder (Dense)      (None, 1)            2           c_3_branch3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "m_branch4_feeder (Dense)        (None, 1)            2           m_branch4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           TR[0][0]                         \n",
      "                                                                 c_3_branch3_feeder[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Multiplication_Pooling (Multipl (None, 1)            0           m_branch4_feeder[0][0]           \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer (Dense)            (None, 1)            2           Multiplication_Pooling[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,525\n",
      "Trainable params: 3,517\n",
      "Non-trainable params: 8\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# branch1\n",
    "visible_branch1 = Input(shape=(6, ), name=\"6D_INPUTS\")\n",
    "hidden1_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch1\")(visible_branch1)\n",
    "hidden2_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch1\")(hidden1_branch1)\n",
    "theta_branch1 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"theta_branch1\")(hidden2_branch1)\n",
    "theta_branch1_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=-1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"theta_branch1_feeder\")(theta_branch1)\n",
    "\n",
    "# branch2 (Ate input)\n",
    "visible_branch2 = Input(shape=(1, ), name=\"Ate_INPUT\")\n",
    "visible_branch2_feeder = Dense(1,\n",
    "                activation='linear',\n",
    "                name=\"visible_branch2_feeder\")(visible_branch2)\n",
    "\n",
    "# addition_pooling (effectively subtraction though...)\n",
    "addition_pooling = keras.layers.Add(name=\"Addition_Pooling\")([theta_branch1_feeder, visible_branch2_feeder])\n",
    "\n",
    "TR = Dense(1, activation='relu',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=False,\n",
    "           name=\"TR\")(addition_pooling)\n",
    "\n",
    "# branch 3 (for c_3)\n",
    "hidden1_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch3\")(visible_branch1)\n",
    "hidden2_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch3\")(hidden1_branch3)\n",
    "c_3_branch3 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"c_3_branch3\")(hidden2_branch3)\n",
    "c_3_branch3_feeder = Dense(1,\n",
    "        kernel_initializer=Constant(value=+1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"c_3_branch3_feeder\")(c_3_branch3)\n",
    "\n",
    "# Power_Pooling\n",
    "#merge = concatenate([TR, c_3_branch3_feeder], name=\"merge\")\n",
    "#power_pooling = Lambda(power_function, name=\"Power_Pooling\")(merge)\n",
    "#power_pooling = Lambda(lambda x: 1 ** x)(c_3_branch3_feeder)\n",
    "def power_lambda(x):\n",
    "    if x[0] <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x[0] ** x[1]\n",
    "power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 1e-32, numpy.inf)) ** (K.clip(K.abs(x[1]), -1., 3.)))\n",
    "#power_layer = Lambda(lambda x: K.tf.where(K.tf.less_equal(x[0], 1e-6), K.tf.fill(tf.shape(x[0]), 0.), K.abs(x[0]) ** K.clip(K.abs(x[1]), 0.5, 3.)))\n",
    "#power_layer = Lambda(lambda x: K.tf.where(K.tf.greater(x[0], 1e-6), K.tf.fill(tf.shape(x[0]), 0.), K.tf.fill(tf.shape(x[0]), 1000000000.)))\n",
    "\n",
    "power_pooling = power_layer([TR, c_3_branch3_feeder])\n",
    "\n",
    "\n",
    "# branch 4 (for the gradient)\n",
    "hidden1_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch4\")(visible_branch1)\n",
    "hidden2_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch4\")(hidden1_branch4)\n",
    "m_branch4 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"m_branch4\")(hidden2_branch4)\n",
    "m_branch4_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=+1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"m_branch4_feeder\")(m_branch4)\n",
    "\n",
    "# multiplication pooling\n",
    "multiplication_pooling = keras.layers.Multiply(name=\"Multiplication_Pooling\")([m_branch4_feeder, power_pooling])\n",
    "\n",
    "# interpretation model\n",
    "output = Dense(1, activation='linear',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=True,\n",
    "           name=\"Output_Layer\")(multiplication_pooling)\n",
    "\n",
    "model = Model(inputs=[visible_branch1, visible_branch2], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph\n",
    "plot_model(model, 'ModelPlots/' + str(file_name) + '_model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed\n",
    "class NBatchLogger(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Logger that log average performance per `display` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.step += 1\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display\n",
    "                if abs(val) > 1e-3:\n",
    "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            if self.params['steps'] is None:\n",
    "                steps_per_epoch = int(numpy.ceil(self.params['samples'] / self.params['batch_size']))\n",
    "            else:\n",
    "                steps = self.params['steps']\n",
    "            #embed()\n",
    "            epoch = int(numpy.floor((self.step - 1)/ steps_per_epoch))\n",
    "            step_in_epoch = self.step - epoch * steps_per_epoch\n",
    "            print('step: {}/{} epoch {}: ... {}'.format(step_in_epoch,\n",
    "                                          steps_per_epoch,\n",
    "                                          epoch,\n",
    "                                          metrics_log))\n",
    "            self.metric_cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5831223 samples, validate on 647914 samples\n",
      "Epoch 1/100\n",
      "step: 50000/583123 epoch 0: ...  - loss: 0.5076 - mean_absolute_error: 0.3093 - mean_squared_error: 0.5017 - rmse: 0.5383\n",
      "step: 100000/583123 epoch 0: ...  - loss: 0.4039 - mean_absolute_error: 0.2838 - mean_squared_error: 0.3969 - rmse: 0.4850\n",
      "step: 150000/583123 epoch 0: ...  - loss: 0.3443 - mean_absolute_error: 0.2639 - mean_squared_error: 0.3366 - rmse: 0.4463\n",
      "step: 200000/583123 epoch 0: ...  - loss: 0.3554 - mean_absolute_error: 0.2800 - mean_squared_error: 0.3465 - rmse: 0.4599\n",
      "step: 250000/583123 epoch 0: ...  - loss: 0.3505 - mean_absolute_error: 0.2710 - mean_squared_error: 0.3415 - rmse: 0.4519\n",
      "step: 300000/583123 epoch 0: ...  - loss: 0.3634 - mean_absolute_error: 0.2832 - mean_squared_error: 0.3536 - rmse: 0.4650\n",
      "step: 350000/583123 epoch 0: ...  - loss: 0.3342 - mean_absolute_error: 0.2722 - mean_squared_error: 0.3243 - rmse: 0.4447\n",
      "step: 400000/583123 epoch 0: ...  - loss: 0.3083 - mean_absolute_error: 0.2654 - mean_squared_error: 0.2986 - rmse: 0.4305\n",
      "step: 450000/583123 epoch 0: ...  - loss: 0.3343 - mean_absolute_error: 0.2768 - mean_squared_error: 0.3246 - rmse: 0.4481\n",
      "step: 500000/583123 epoch 0: ...  - loss: 0.3521 - mean_absolute_error: 0.2912 - mean_squared_error: 0.3423 - rmse: 0.4649\n",
      "step: 550000/583123 epoch 0: ...  - loss: 0.3289 - mean_absolute_error: 0.2772 - mean_squared_error: 0.3187 - rmse: 0.4449\n",
      " - 575s - loss: 0.3602 - mean_absolute_error: 0.2790 - mean_squared_error: 0.3512 - rmse: 0.4607 - val_loss: 0.3327 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.3224 - val_rmse: 0.4872\n",
      "Epoch 2/100\n",
      "step: 16877/583123 epoch 1: ...  - loss: 0.3204 - mean_absolute_error: 0.2635 - mean_squared_error: 0.3104 - rmse: 0.4328\n",
      "step: 66877/583123 epoch 1: ...  - loss: 0.3296 - mean_absolute_error: 0.2616 - mean_squared_error: 0.3195 - rmse: 0.4349\n",
      "step: 116877/583123 epoch 1: ...  - loss: 0.3612 - mean_absolute_error: 0.2848 - mean_squared_error: 0.3507 - rmse: 0.4637\n",
      "step: 166877/583123 epoch 1: ...  - loss: 0.3253 - mean_absolute_error: 0.2736 - mean_squared_error: 0.3150 - rmse: 0.4425\n",
      "step: 216877/583123 epoch 1: ...  - loss: 0.3261 - mean_absolute_error: 0.2654 - mean_squared_error: 0.3160 - rmse: 0.4366\n",
      "step: 266877/583123 epoch 1: ...  - loss: 0.3270 - mean_absolute_error: 0.2703 - mean_squared_error: 0.3168 - rmse: 0.4406\n",
      "step: 316877/583123 epoch 1: ...  - loss: 0.3063 - mean_absolute_error: 0.2633 - mean_squared_error: 0.2963 - rmse: 0.4271\n",
      "step: 366877/583123 epoch 1: ...  - loss: 0.3236 - mean_absolute_error: 0.2518 - mean_squared_error: 0.3136 - rmse: 0.4270\n",
      "step: 416877/583123 epoch 1: ...  - loss: 0.3156 - mean_absolute_error: 0.2512 - mean_squared_error: 0.3058 - rmse: 0.4234\n",
      "step: 466877/583123 epoch 1: ...  - loss: 0.3242 - mean_absolute_error: 0.2678 - mean_squared_error: 0.3146 - rmse: 0.4352\n",
      "step: 516877/583123 epoch 1: ...  - loss: 0.3403 - mean_absolute_error: 0.2750 - mean_squared_error: 0.3303 - rmse: 0.4485\n",
      "step: 566877/583123 epoch 1: ...  - loss: 0.3196 - mean_absolute_error: 0.2577 - mean_squared_error: 0.3096 - rmse: 0.4288\n",
      " - 569s - loss: 0.3255 - mean_absolute_error: 0.2646 - mean_squared_error: 0.3154 - rmse: 0.4357 - val_loss: 0.2765 - val_mean_absolute_error: 0.2693 - val_mean_squared_error: 0.2667 - val_rmse: 0.4194\n",
      "Epoch 3/100\n",
      "step: 33754/583123 epoch 2: ...  - loss: 0.3101 - mean_absolute_error: 0.2589 - mean_squared_error: 0.3003 - rmse: 0.4269\n",
      "step: 83754/583123 epoch 2: ...  - loss: 0.3368 - mean_absolute_error: 0.2695 - mean_squared_error: 0.3268 - rmse: 0.4432\n",
      "step: 133754/583123 epoch 2: ...  - loss: 0.3340 - mean_absolute_error: 0.2630 - mean_squared_error: 0.3239 - rmse: 0.4382\n",
      "step: 183754/583123 epoch 2: ...  - loss: 0.3218 - mean_absolute_error: 0.2536 - mean_squared_error: 0.3118 - rmse: 0.4264\n",
      "step: 233754/583123 epoch 2: ...  - loss: 0.3450 - mean_absolute_error: 0.2811 - mean_squared_error: 0.3346 - rmse: 0.4548\n",
      "step: 283754/583123 epoch 2: ...  - loss: 0.3263 - mean_absolute_error: 0.2710 - mean_squared_error: 0.3161 - rmse: 0.4408\n",
      "step: 333754/583123 epoch 2: ...  - loss: 0.3414 - mean_absolute_error: 0.2661 - mean_squared_error: 0.3314 - rmse: 0.4440\n",
      "step: 383754/583123 epoch 2: ...  - loss: 0.3215 - mean_absolute_error: 0.2631 - mean_squared_error: 0.3112 - rmse: 0.4324\n",
      "step: 433754/583123 epoch 2: ...  - loss: 0.3095 - mean_absolute_error: 0.2455 - mean_squared_error: 0.2998 - rmse: 0.4159\n",
      "step: 483754/583123 epoch 2: ...  - loss: 0.3093 - mean_absolute_error: 0.2538 - mean_squared_error: 0.2996 - rmse: 0.4216\n",
      "step: 533754/583123 epoch 2: ...  - loss: 0.3250 - mean_absolute_error: 0.2574 - mean_squared_error: 0.3152 - rmse: 0.4306\n",
      " - 566s - loss: 0.3275 - mean_absolute_error: 0.2638 - mean_squared_error: 0.3174 - rmse: 0.4360 - val_loss: 0.3108 - val_mean_absolute_error: 0.2120 - val_mean_squared_error: 0.3010 - val_rmse: 0.3977\n",
      "Epoch 4/100\n",
      "step: 631/583123 epoch 3: ...  - loss: 0.3378 - mean_absolute_error: 0.2777 - mean_squared_error: 0.3277 - rmse: 0.4495\n",
      "step: 50631/583123 epoch 3: ...  - loss: 0.3208 - mean_absolute_error: 0.2564 - mean_squared_error: 0.3111 - rmse: 0.4280\n",
      "step: 100631/583123 epoch 3: ...  - loss: 0.3109 - mean_absolute_error: 0.2574 - mean_squared_error: 0.3011 - rmse: 0.4248\n",
      "step: 150631/583123 epoch 3: ...  - loss: 0.3093 - mean_absolute_error: 0.2449 - mean_squared_error: 0.2999 - rmse: 0.4157\n",
      "step: 200631/583123 epoch 3: ...  - loss: 0.3209 - mean_absolute_error: 0.2399 - mean_squared_error: 0.3117 - rmse: 0.4172\n",
      "step: 250631/583123 epoch 3: ...  - loss: 0.3455 - mean_absolute_error: 0.2784 - mean_squared_error: 0.3357 - rmse: 0.4512\n",
      "step: 300631/583123 epoch 3: ...  - loss: 0.3317 - mean_absolute_error: 0.2707 - mean_squared_error: 0.3220 - rmse: 0.4411\n",
      "step: 350631/583123 epoch 3: ...  - loss: 0.3394 - mean_absolute_error: 0.2683 - mean_squared_error: 0.3295 - rmse: 0.4445\n",
      "step: 400631/583123 epoch 3: ...  - loss: 0.3719 - mean_absolute_error: 0.2661 - mean_squared_error: 0.3622 - rmse: 0.4551\n",
      "step: 450631/583123 epoch 3: ...  - loss: 0.3439 - mean_absolute_error: 0.2728 - mean_squared_error: 0.3341 - rmse: 0.4504\n",
      "step: 500631/583123 epoch 3: ...  - loss: 0.3419 - mean_absolute_error: 0.2651 - mean_squared_error: 0.3319 - rmse: 0.4433\n",
      "step: 550631/583123 epoch 3: ...  - loss: 0.3229 - mean_absolute_error: 0.2675 - mean_squared_error: 0.3127 - rmse: 0.4358\n",
      " - 561s - loss: 0.3329 - mean_absolute_error: 0.2634 - mean_squared_error: 0.3231 - rmse: 0.4377 - val_loss: 0.3053 - val_mean_absolute_error: 0.2449 - val_mean_squared_error: 0.2951 - val_rmse: 0.4181\n",
      "Epoch 5/100\n",
      "step: 17508/583123 epoch 4: ...  - loss: 0.3362 - mean_absolute_error: 0.2776 - mean_squared_error: 0.3260 - rmse: 0.4484\n",
      "step: 67508/583123 epoch 4: ...  - loss: 0.3359 - mean_absolute_error: 0.2744 - mean_squared_error: 0.3256 - rmse: 0.4447\n",
      "step: 117508/583123 epoch 4: ...  - loss: 0.3396 - mean_absolute_error: 0.2734 - mean_squared_error: 0.3290 - rmse: 0.4465\n",
      "step: 167508/583123 epoch 4: ...  - loss: 0.3253 - mean_absolute_error: 0.2653 - mean_squared_error: 0.3152 - rmse: 0.4356\n",
      "step: 217508/583123 epoch 4: ...  - loss: 0.3128 - mean_absolute_error: 0.2537 - mean_squared_error: 0.3033 - rmse: 0.4238\n",
      "step: 267508/583123 epoch 4: ...  - loss: 0.3227 - mean_absolute_error: 0.2563 - mean_squared_error: 0.3132 - rmse: 0.4276\n",
      "step: 317508/583123 epoch 4: ...  - loss: 0.3234 - mean_absolute_error: 0.2518 - mean_squared_error: 0.3140 - rmse: 0.4260\n",
      "step: 367508/583123 epoch 4: ...  - loss: 0.3141 - mean_absolute_error: 0.2533 - mean_squared_error: 0.3045 - rmse: 0.4246\n",
      "step: 417508/583123 epoch 4: ...  - loss: 0.3174 - mean_absolute_error: 0.2565 - mean_squared_error: 0.3079 - rmse: 0.4267\n",
      "step: 467508/583123 epoch 4: ...  - loss: 0.3049 - mean_absolute_error: 0.2490 - mean_squared_error: 0.2954 - rmse: 0.4169\n",
      "step: 517508/583123 epoch 4: ...  - loss: 0.3153 - mean_absolute_error: 0.2523 - mean_squared_error: 0.3058 - rmse: 0.4243\n",
      "step: 567508/583123 epoch 4: ...  - loss: 0.3560 - mean_absolute_error: 0.2778 - mean_squared_error: 0.3462 - rmse: 0.4564\n",
      " - 563s - loss: 0.3248 - mean_absolute_error: 0.2615 - mean_squared_error: 0.3150 - rmse: 0.4331 - val_loss: 0.3330 - val_mean_absolute_error: 0.2719 - val_mean_squared_error: 0.3230 - val_rmse: 0.4448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "step: 34385/583123 epoch 5: ...  - loss: 0.3179 - mean_absolute_error: 0.2708 - mean_squared_error: 0.3080 - rmse: 0.4367\n",
      "step: 84385/583123 epoch 5: ...  - loss: 0.3030 - mean_absolute_error: 0.2484 - mean_squared_error: 0.2934 - rmse: 0.4163\n",
      "step: 134385/583123 epoch 5: ...  - loss: 0.3262 - mean_absolute_error: 0.2642 - mean_squared_error: 0.3167 - rmse: 0.4355\n",
      "step: 184385/583123 epoch 5: ...  - loss: 0.3218 - mean_absolute_error: 0.2641 - mean_squared_error: 0.3124 - rmse: 0.4341\n",
      "step: 234385/583123 epoch 5: ...  - loss: 0.3247 - mean_absolute_error: 0.2632 - mean_squared_error: 0.3152 - rmse: 0.4328\n",
      "step: 284385/583123 epoch 5: ...  - loss: 0.3233 - mean_absolute_error: 0.2627 - mean_squared_error: 0.3133 - rmse: 0.4341\n",
      "step: 334385/583123 epoch 5: ...  - loss: 0.3150 - mean_absolute_error: 0.2463 - mean_squared_error: 0.3054 - rmse: 0.4197\n",
      "step: 384385/583123 epoch 5: ...  - loss: 0.3152 - mean_absolute_error: 0.2473 - mean_squared_error: 0.3058 - rmse: 0.4205\n",
      "step: 434385/583123 epoch 5: ...  - loss: 0.3169 - mean_absolute_error: 0.2439 - mean_squared_error: 0.3075 - rmse: 0.4185\n",
      "step: 484385/583123 epoch 5: ...  - loss: 0.3185 - mean_absolute_error: 0.2666 - mean_squared_error: 0.3087 - rmse: 0.4326\n",
      "step: 534385/583123 epoch 5: ...  - loss: 0.3203 - mean_absolute_error: 0.2636 - mean_squared_error: 0.3101 - rmse: 0.4334\n",
      " - 562s - loss: 0.3175 - mean_absolute_error: 0.2570 - mean_squared_error: 0.3079 - rmse: 0.4273 - val_loss: 0.2724 - val_mean_absolute_error: 0.2275 - val_mean_squared_error: 0.2624 - val_rmse: 0.3832\n",
      "Epoch 7/100\n",
      "step: 1262/583123 epoch 6: ...  - loss: 0.3096 - mean_absolute_error: 0.2517 - mean_squared_error: 0.2998 - rmse: 0.4200\n",
      "step: 51262/583123 epoch 6: ...  - loss: 0.3101 - mean_absolute_error: 0.2503 - mean_squared_error: 0.3001 - rmse: 0.4196\n",
      "step: 101262/583123 epoch 6: ...  - loss: 0.3070 - mean_absolute_error: 0.2402 - mean_squared_error: 0.2973 - rmse: 0.4120\n",
      "step: 151262/583123 epoch 6: ...  - loss: 0.3093 - mean_absolute_error: 0.2627 - mean_squared_error: 0.2996 - rmse: 0.4272\n",
      "step: 201262/583123 epoch 6: ...  - loss: 0.3333 - mean_absolute_error: 0.2599 - mean_squared_error: 0.3235 - rmse: 0.4354\n",
      "step: 251262/583123 epoch 6: ...  - loss: 0.2939 - mean_absolute_error: 0.2359 - mean_squared_error: 0.2840 - rmse: 0.4051\n",
      "step: 301262/583123 epoch 6: ...  - loss: 0.2929 - mean_absolute_error: 0.2432 - mean_squared_error: 0.2831 - rmse: 0.4081\n",
      "step: 351262/583123 epoch 6: ...  - loss: 0.3207 - mean_absolute_error: 0.2567 - mean_squared_error: 0.3107 - rmse: 0.4271\n",
      "step: 401262/583123 epoch 6: ...  - loss: 0.3442 - mean_absolute_error: 0.2593 - mean_squared_error: 0.3346 - rmse: 0.4412\n",
      "step: 451262/583123 epoch 6: ...  - loss: 0.3206 - mean_absolute_error: 0.2500 - mean_squared_error: 0.3109 - rmse: 0.4238\n",
      "step: 501262/583123 epoch 6: ...  - loss: 0.3256 - mean_absolute_error: 0.2531 - mean_squared_error: 0.3160 - rmse: 0.4283\n",
      "step: 551262/583123 epoch 6: ...  - loss: 0.3135 - mean_absolute_error: 0.2571 - mean_squared_error: 0.3037 - rmse: 0.4273\n",
      " - 559s - loss: 0.3156 - mean_absolute_error: 0.2520 - mean_squared_error: 0.3058 - rmse: 0.4234 - val_loss: 0.2571 - val_mean_absolute_error: 0.2041 - val_mean_squared_error: 0.2470 - val_rmse: 0.3617\n",
      "Epoch 8/100\n",
      "step: 18139/583123 epoch 7: ...  - loss: 0.3188 - mean_absolute_error: 0.2553 - mean_squared_error: 0.3087 - rmse: 0.4268\n",
      "step: 68139/583123 epoch 7: ...  - loss: 0.3243 - mean_absolute_error: 0.2548 - mean_squared_error: 0.3146 - rmse: 0.4277\n",
      "step: 118139/583123 epoch 7: ...  - loss: 0.3261 - mean_absolute_error: 0.2601 - mean_squared_error: 0.3164 - rmse: 0.4329\n",
      "step: 168139/583123 epoch 7: ...  - loss: 0.3128 - mean_absolute_error: 0.2578 - mean_squared_error: 0.3031 - rmse: 0.4244\n",
      "step: 218139/583123 epoch 7: ...  - loss: 0.3133 - mean_absolute_error: 0.2596 - mean_squared_error: 0.3035 - rmse: 0.4272\n",
      "step: 268139/583123 epoch 7: ...  - loss: 0.3306 - mean_absolute_error: 0.2624 - mean_squared_error: 0.3207 - rmse: 0.4350\n",
      "step: 318139/583123 epoch 7: ...  - loss: 0.3173 - mean_absolute_error: 0.2638 - mean_squared_error: 0.3072 - rmse: 0.4317\n",
      "step: 368139/583123 epoch 7: ...  - loss: 0.3225 - mean_absolute_error: 0.2562 - mean_squared_error: 0.3130 - rmse: 0.4295\n",
      "step: 418139/583123 epoch 7: ...  - loss: 0.3344 - mean_absolute_error: 0.2624 - mean_squared_error: 0.3250 - rmse: 0.4378\n",
      "step: 468139/583123 epoch 7: ...  - loss: 0.3193 - mean_absolute_error: 0.2647 - mean_squared_error: 0.3095 - rmse: 0.4333\n",
      "step: 518139/583123 epoch 7: ...  - loss: 0.3342 - mean_absolute_error: 0.2418 - mean_squared_error: 0.3247 - rmse: 0.4242\n",
      "step: 568139/583123 epoch 7: ...  - loss: 0.3156 - mean_absolute_error: 0.2439 - mean_squared_error: 0.3061 - rmse: 0.4176\n",
      " - 564s - loss: 0.3225 - mean_absolute_error: 0.2560 - mean_squared_error: 0.3128 - rmse: 0.4284 - val_loss: 0.2749 - val_mean_absolute_error: 0.1781 - val_mean_squared_error: 0.2659 - val_rmse: 0.3551\n",
      "Epoch 9/100\n",
      "step: 35016/583123 epoch 8: ...  - loss: 0.3115 - mean_absolute_error: 0.2372 - mean_squared_error: 0.3024 - rmse: 0.4119\n",
      "step: 85016/583123 epoch 8: ...  - loss: 0.3096 - mean_absolute_error: 0.2353 - mean_squared_error: 0.3005 - rmse: 0.4105\n",
      "step: 135016/583123 epoch 8: ...  - loss: 0.2938 - mean_absolute_error: 0.2327 - mean_squared_error: 0.2849 - rmse: 0.4019\n",
      "step: 185016/583123 epoch 8: ...  - loss: 0.2921 - mean_absolute_error: 0.2334 - mean_squared_error: 0.2832 - rmse: 0.4012\n",
      "step: 235016/583123 epoch 8: ...  - loss: 0.3105 - mean_absolute_error: 0.2295 - mean_squared_error: 0.3017 - rmse: 0.4071\n",
      "step: 285016/583123 epoch 8: ...  - loss: 0.3062 - mean_absolute_error: 0.2281 - mean_squared_error: 0.2975 - rmse: 0.4050\n",
      "step: 335016/583123 epoch 8: ...  - loss: 0.3244 - mean_absolute_error: 0.2570 - mean_squared_error: 0.3155 - rmse: 0.4306\n",
      "step: 385016/583123 epoch 8: ...  - loss: 0.3118 - mean_absolute_error: 0.2462 - mean_squared_error: 0.3028 - rmse: 0.4181\n",
      "step: 435016/583123 epoch 8: ...  - loss: 0.3177 - mean_absolute_error: 0.2469 - mean_squared_error: 0.3089 - rmse: 0.4207\n",
      "step: 485016/583123 epoch 8: ...  - loss: 0.3070 - mean_absolute_error: 0.2305 - mean_squared_error: 0.2983 - rmse: 0.4056\n",
      "step: 535016/583123 epoch 8: ...  - loss: 0.3276 - mean_absolute_error: 0.2466 - mean_squared_error: 0.3191 - rmse: 0.4255\n",
      " - 560s - loss: 0.3100 - mean_absolute_error: 0.2392 - mean_squared_error: 0.3012 - rmse: 0.4129 - val_loss: 0.2647 - val_mean_absolute_error: 0.2171 - val_mean_squared_error: 0.2560 - val_rmse: 0.3796\n",
      "Epoch 10/100\n",
      "step: 1893/583123 epoch 9: ...  - loss: 0.3080 - mean_absolute_error: 0.2426 - mean_squared_error: 0.2991 - rmse: 0.4141\n",
      "step: 51893/583123 epoch 9: ...  - loss: 0.3144 - mean_absolute_error: 0.2578 - mean_squared_error: 0.3056 - rmse: 0.4265\n",
      "step: 101893/583123 epoch 9: ...  - loss: 0.3173 - mean_absolute_error: 0.2530 - mean_squared_error: 0.3082 - rmse: 0.4240\n",
      "step: 151893/583123 epoch 9: ...  - loss: 0.3031 - mean_absolute_error: 0.2431 - mean_squared_error: 0.2940 - rmse: 0.4129\n",
      "step: 201893/583123 epoch 9: ...  - loss: 0.3084 - mean_absolute_error: 0.2299 - mean_squared_error: 0.2998 - rmse: 0.4067\n",
      "step: 251893/583123 epoch 9: ...  - loss: 0.3208 - mean_absolute_error: 0.2381 - mean_squared_error: 0.3121 - rmse: 0.4166\n",
      "step: 301893/583123 epoch 9: ...  - loss: 0.3160 - mean_absolute_error: 0.2373 - mean_squared_error: 0.3071 - rmse: 0.4144\n",
      "step: 351893/583123 epoch 9: ...  - loss: 0.3070 - mean_absolute_error: 0.2247 - mean_squared_error: 0.2984 - rmse: 0.4025\n",
      "step: 401893/583123 epoch 9: ...  - loss: 0.3339 - mean_absolute_error: 0.2388 - mean_squared_error: 0.3254 - rmse: 0.4239\n",
      "step: 451893/583123 epoch 9: ...  - loss: 0.3068 - mean_absolute_error: 0.2363 - mean_squared_error: 0.2982 - rmse: 0.4095\n",
      "step: 501893/583123 epoch 9: ...  - loss: 0.3239 - mean_absolute_error: 0.2615 - mean_squared_error: 0.3151 - rmse: 0.4334\n",
      "step: 551893/583123 epoch 9: ...  - loss: 0.2976 - mean_absolute_error: 0.2396 - mean_squared_error: 0.2890 - rmse: 0.4080\n",
      " - 558s - loss: 0.3134 - mean_absolute_error: 0.2428 - mean_squared_error: 0.3046 - rmse: 0.4168 - val_loss: 0.2341 - val_mean_absolute_error: 0.1815 - val_mean_squared_error: 0.2256 - val_rmse: 0.3402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "step: 18770/583123 epoch 10: ...  - loss: 0.3306 - mean_absolute_error: 0.2685 - mean_squared_error: 0.3220 - rmse: 0.4412\n",
      "step: 68770/583123 epoch 10: ...  - loss: 0.3062 - mean_absolute_error: 0.2471 - mean_squared_error: 0.2972 - rmse: 0.4170\n",
      "step: 118770/583123 epoch 10: ...  - loss: 0.3026 - mean_absolute_error: 0.2469 - mean_squared_error: 0.2938 - rmse: 0.4153\n",
      "step: 168770/583123 epoch 10: ...  - loss: 0.3593 - mean_absolute_error: 0.2782 - mean_squared_error: 0.3499 - rmse: 0.4574\n",
      "step: 218770/583123 epoch 10: ...  - loss: 0.3192 - mean_absolute_error: 0.2594 - mean_squared_error: 0.3101 - rmse: 0.4282\n",
      "step: 268770/583123 epoch 10: ...  - loss: 0.3259 - mean_absolute_error: 0.2647 - mean_squared_error: 0.3165 - rmse: 0.4356\n",
      "step: 318770/583123 epoch 10: ...  - loss: 0.3284 - mean_absolute_error: 0.2575 - mean_squared_error: 0.3191 - rmse: 0.4316\n",
      "step: 368770/583123 epoch 10: ...  - loss: 0.3297 - mean_absolute_error: 0.2725 - mean_squared_error: 0.3201 - rmse: 0.4410\n",
      "step: 418770/583123 epoch 10: ...  - loss: 0.3128 - mean_absolute_error: 0.2535 - mean_squared_error: 0.3033 - rmse: 0.4221\n",
      "step: 468770/583123 epoch 10: ...  - loss: 0.3304 - mean_absolute_error: 0.2731 - mean_squared_error: 0.3207 - rmse: 0.4435\n",
      "step: 518770/583123 epoch 10: ...  - loss: 0.3010 - mean_absolute_error: 0.2355 - mean_squared_error: 0.2917 - rmse: 0.4069\n",
      "step: 568770/583123 epoch 10: ...  - loss: 0.3118 - mean_absolute_error: 0.2436 - mean_squared_error: 0.3029 - rmse: 0.4159\n",
      " - 563s - loss: 0.3221 - mean_absolute_error: 0.2583 - mean_squared_error: 0.3128 - rmse: 0.4298 - val_loss: 0.3055 - val_mean_absolute_error: 0.2363 - val_mean_squared_error: 0.2966 - val_rmse: 0.4087\n",
      "Epoch 12/100\n",
      "step: 35647/583123 epoch 11: ...  - loss: 0.3300 - mean_absolute_error: 0.2634 - mean_squared_error: 0.3211 - rmse: 0.4370\n",
      "step: 85647/583123 epoch 11: ...  - loss: 0.3209 - mean_absolute_error: 0.2541 - mean_squared_error: 0.3119 - rmse: 0.4273\n",
      "step: 135647/583123 epoch 11: ...  - loss: 0.3770 - mean_absolute_error: 0.2496 - mean_squared_error: 0.3682 - rmse: 0.4484\n",
      "step: 185647/583123 epoch 11: ...  - loss: 0.3338 - mean_absolute_error: 0.2544 - mean_squared_error: 0.3247 - rmse: 0.4325\n",
      "step: 235647/583123 epoch 11: ...  - loss: 0.3079 - mean_absolute_error: 0.2279 - mean_squared_error: 0.2991 - rmse: 0.4050\n",
      "step: 285647/583123 epoch 11: ...  - loss: 0.3161 - mean_absolute_error: 0.2341 - mean_squared_error: 0.3073 - rmse: 0.4128\n",
      "step: 335647/583123 epoch 11: ...  - loss: 0.3270 - mean_absolute_error: 0.2471 - mean_squared_error: 0.3180 - rmse: 0.4259\n",
      "step: 385647/583123 epoch 11: ...  - loss: 0.3135 - mean_absolute_error: 0.2576 - mean_squared_error: 0.3041 - rmse: 0.4273\n",
      "step: 435647/583123 epoch 11: ...  - loss: 0.3121 - mean_absolute_error: 0.2583 - mean_squared_error: 0.3023 - rmse: 0.4261\n",
      "step: 485647/583123 epoch 11: ...  - loss: 0.3310 - mean_absolute_error: 0.2562 - mean_squared_error: 0.3215 - rmse: 0.4325\n",
      "step: 535647/583123 epoch 11: ...  - loss: 0.3389 - mean_absolute_error: 0.2625 - mean_squared_error: 0.3294 - rmse: 0.4407\n",
      " - 558s - loss: 0.3284 - mean_absolute_error: 0.2528 - mean_squared_error: 0.3192 - rmse: 0.4297 - val_loss: 0.4091 - val_mean_absolute_error: 0.3909 - val_mean_squared_error: 0.3995 - val_rmse: 0.5523\n",
      "Epoch 13/100\n",
      "step: 2524/583123 epoch 12: ...  - loss: 0.3314 - mean_absolute_error: 0.2715 - mean_squared_error: 0.3219 - rmse: 0.4425\n",
      "step: 52524/583123 epoch 12: ...  - loss: 0.3571 - mean_absolute_error: 0.2747 - mean_squared_error: 0.3476 - rmse: 0.4556\n",
      "step: 102524/583123 epoch 12: ...  - loss: 0.3136 - mean_absolute_error: 0.2473 - mean_squared_error: 0.3042 - rmse: 0.4189\n",
      "step: 152524/583123 epoch 12: ...  - loss: 0.3047 - mean_absolute_error: 0.2521 - mean_squared_error: 0.2954 - rmse: 0.4183\n",
      "step: 202524/583123 epoch 12: ...  - loss: 0.3157 - mean_absolute_error: 0.2527 - mean_squared_error: 0.3063 - rmse: 0.4240\n",
      "step: 252524/583123 epoch 12: ...  - loss: 0.3125 - mean_absolute_error: 0.2536 - mean_squared_error: 0.3031 - rmse: 0.4227\n",
      "step: 302524/583123 epoch 12: ...  - loss: 0.3004 - mean_absolute_error: 0.2391 - mean_squared_error: 0.2913 - rmse: 0.4090\n",
      "step: 352524/583123 epoch 12: ...  - loss: 0.3213 - mean_absolute_error: 0.2524 - mean_squared_error: 0.3121 - rmse: 0.4261\n",
      "step: 402524/583123 epoch 12: ...  - loss: 0.3164 - mean_absolute_error: 0.2625 - mean_squared_error: 0.3068 - rmse: 0.4282\n",
      "step: 452524/583123 epoch 12: ...  - loss: 0.3117 - mean_absolute_error: 0.2705 - mean_squared_error: 0.3020 - rmse: 0.4335\n",
      "step: 502524/583123 epoch 12: ...  - loss: 0.3110 - mean_absolute_error: 0.2534 - mean_squared_error: 0.3014 - rmse: 0.4218\n",
      "step: 552524/583123 epoch 12: ...  - loss: 0.3237 - mean_absolute_error: 0.2547 - mean_squared_error: 0.3143 - rmse: 0.4270\n",
      " - 564s - loss: 0.3165 - mean_absolute_error: 0.2549 - mean_squared_error: 0.3071 - rmse: 0.4251 - val_loss: 0.3078 - val_mean_absolute_error: 0.2794 - val_mean_squared_error: 0.2985 - val_rmse: 0.4439\n",
      "Epoch 14/100\n",
      "step: 19401/583123 epoch 13: ...  - loss: 0.3045 - mean_absolute_error: 0.2343 - mean_squared_error: 0.2952 - rmse: 0.4065\n",
      "step: 69401/583123 epoch 13: ...  - loss: 0.3234 - mean_absolute_error: 0.2625 - mean_squared_error: 0.3140 - rmse: 0.4332\n",
      "step: 119401/583123 epoch 13: ...  - loss: 0.3112 - mean_absolute_error: 0.2576 - mean_squared_error: 0.3017 - rmse: 0.4245\n",
      "step: 169401/583123 epoch 13: ...  - loss: 0.3059 - mean_absolute_error: 0.2434 - mean_squared_error: 0.2968 - rmse: 0.4130\n",
      "step: 219401/583123 epoch 13: ...  - loss: 0.3169 - mean_absolute_error: 0.2597 - mean_squared_error: 0.3077 - rmse: 0.4284\n",
      "step: 269401/583123 epoch 13: ...  - loss: 0.3182 - mean_absolute_error: 0.2720 - mean_squared_error: 0.3085 - rmse: 0.4381\n",
      "step: 319401/583123 epoch 13: ...  - loss: 0.3337 - mean_absolute_error: 0.2774 - mean_squared_error: 0.3240 - rmse: 0.4475\n",
      "step: 369401/583123 epoch 13: ...  - loss: 0.3081 - mean_absolute_error: 0.2551 - mean_squared_error: 0.2985 - rmse: 0.4223\n",
      "step: 419401/583123 epoch 13: ...  - loss: 0.3295 - mean_absolute_error: 0.2580 - mean_squared_error: 0.3200 - rmse: 0.4325\n",
      "step: 469401/583123 epoch 13: ...  - loss: 0.3205 - mean_absolute_error: 0.2508 - mean_squared_error: 0.3112 - rmse: 0.4251\n",
      "step: 519401/583123 epoch 13: ...  - loss: 0.3213 - mean_absolute_error: 0.2691 - mean_squared_error: 0.3119 - rmse: 0.4383\n",
      "step: 569401/583123 epoch 13: ...  - loss: 0.3507 - mean_absolute_error: 0.2922 - mean_squared_error: 0.3408 - rmse: 0.4636\n",
      " - 559s - loss: 0.3212 - mean_absolute_error: 0.2618 - mean_squared_error: 0.3117 - rmse: 0.4321 - val_loss: 0.2711 - val_mean_absolute_error: 0.2313 - val_mean_squared_error: 0.2616 - val_rmse: 0.3847\n",
      "Epoch 15/100\n",
      "step: 36278/583123 epoch 14: ...  - loss: 0.3286 - mean_absolute_error: 0.2430 - mean_squared_error: 0.3192 - rmse: 0.4237\n",
      "step: 86278/583123 epoch 14: ...  - loss: 0.3118 - mean_absolute_error: 0.2401 - mean_squared_error: 0.3026 - rmse: 0.4139\n",
      "step: 136278/583123 epoch 14: ...  - loss: 0.3148 - mean_absolute_error: 0.2447 - mean_squared_error: 0.3057 - rmse: 0.4181\n",
      "step: 186278/583123 epoch 14: ...  - loss: 0.3422 - mean_absolute_error: 0.2655 - mean_squared_error: 0.3327 - rmse: 0.4414\n",
      "step: 236278/583123 epoch 14: ...  - loss: 0.3274 - mean_absolute_error: 0.2472 - mean_squared_error: 0.3181 - rmse: 0.4246\n",
      "step: 286278/583123 epoch 14: ...  - loss: 0.3291 - mean_absolute_error: 0.2402 - mean_squared_error: 0.3201 - rmse: 0.4209\n",
      "step: 336278/583123 epoch 14: ...  - loss: 0.3132 - mean_absolute_error: 0.2442 - mean_squared_error: 0.3041 - rmse: 0.4166\n",
      "step: 386278/583123 epoch 14: ...  - loss: 0.3214 - mean_absolute_error: 0.2404 - mean_squared_error: 0.3125 - rmse: 0.4177\n",
      "step: 436278/583123 epoch 14: ...  - loss: 0.3043 - mean_absolute_error: 0.2454 - mean_squared_error: 0.2952 - rmse: 0.4146\n",
      "step: 486278/583123 epoch 14: ...  - loss: 0.3194 - mean_absolute_error: 0.2561 - mean_squared_error: 0.3102 - rmse: 0.4272\n",
      "step: 536278/583123 epoch 14: ...  - loss: 0.3213 - mean_absolute_error: 0.2436 - mean_squared_error: 0.3121 - rmse: 0.4199\n",
      " - 560s - loss: 0.3207 - mean_absolute_error: 0.2463 - mean_squared_error: 0.3115 - rmse: 0.4214 - val_loss: 0.3072 - val_mean_absolute_error: 0.2695 - val_mean_squared_error: 0.2983 - val_rmse: 0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "step: 3155/583123 epoch 15: ...  - loss: 0.3149 - mean_absolute_error: 0.2426 - mean_squared_error: 0.3057 - rmse: 0.4175\n",
      "step: 53155/583123 epoch 15: ...  - loss: 0.3085 - mean_absolute_error: 0.2356 - mean_squared_error: 0.2995 - rmse: 0.4105\n",
      "step: 103155/583123 epoch 15: ...  - loss: 0.3130 - mean_absolute_error: 0.2487 - mean_squared_error: 0.3038 - rmse: 0.4206\n",
      "step: 153155/583123 epoch 15: ...  - loss: 0.3034 - mean_absolute_error: 0.2463 - mean_squared_error: 0.2940 - rmse: 0.4143\n",
      "step: 203155/583123 epoch 15: ...  - loss: 0.3021 - mean_absolute_error: 0.2417 - mean_squared_error: 0.2928 - rmse: 0.4111\n",
      "step: 253155/583123 epoch 15: ...  - loss: 0.3070 - mean_absolute_error: 0.2404 - mean_squared_error: 0.2977 - rmse: 0.4117\n",
      "step: 303155/583123 epoch 15: ...  - loss: 0.3230 - mean_absolute_error: 0.2497 - mean_squared_error: 0.3139 - rmse: 0.4243\n",
      "step: 353155/583123 epoch 15: ...  - loss: 0.3359 - mean_absolute_error: 0.2549 - mean_squared_error: 0.3267 - rmse: 0.4341\n",
      "step: 403155/583123 epoch 15: ...  - loss: 0.3134 - mean_absolute_error: 0.2502 - mean_squared_error: 0.3041 - rmse: 0.4214\n",
      "step: 453155/583123 epoch 15: ...  - loss: 0.3019 - mean_absolute_error: 0.2486 - mean_squared_error: 0.2925 - rmse: 0.4147\n",
      "step: 503155/583123 epoch 15: ...  - loss: 0.3209 - mean_absolute_error: 0.2494 - mean_squared_error: 0.3114 - rmse: 0.4235\n",
      "step: 553155/583123 epoch 15: ...  - loss: 0.3019 - mean_absolute_error: 0.2332 - mean_squared_error: 0.2926 - rmse: 0.4047\n",
      " - 562s - loss: 0.3121 - mean_absolute_error: 0.2455 - mean_squared_error: 0.3028 - rmse: 0.4175 - val_loss: 0.3675 - val_mean_absolute_error: 0.3653 - val_mean_squared_error: 0.3578 - val_rmse: 0.5203\n",
      "Epoch 17/100\n",
      "step: 20032/583123 epoch 16: ...  - loss: 0.3192 - mean_absolute_error: 0.2569 - mean_squared_error: 0.3097 - rmse: 0.4273\n",
      "step: 70032/583123 epoch 16: ...  - loss: 0.3196 - mean_absolute_error: 0.2737 - mean_squared_error: 0.3095 - rmse: 0.4391\n",
      "step: 120032/583123 epoch 16: ...  - loss: 0.3273 - mean_absolute_error: 0.2671 - mean_squared_error: 0.3175 - rmse: 0.4363\n",
      "step: 170032/583123 epoch 16: ...  - loss: 0.3321 - mean_absolute_error: 0.2728 - mean_squared_error: 0.3217 - rmse: 0.4430\n",
      "step: 220032/583123 epoch 16: ...  - loss: 0.3099 - mean_absolute_error: 0.2598 - mean_squared_error: 0.2997 - rmse: 0.4251\n",
      "step: 270032/583123 epoch 16: ...  - loss: 0.3078 - mean_absolute_error: 0.2441 - mean_squared_error: 0.2980 - rmse: 0.4155\n",
      "step: 320032/583123 epoch 16: ...  - loss: 0.3148 - mean_absolute_error: 0.2383 - mean_squared_error: 0.3054 - rmse: 0.4136\n",
      "step: 370032/583123 epoch 16: ...  - loss: 0.3166 - mean_absolute_error: 0.2589 - mean_squared_error: 0.3072 - rmse: 0.4274\n",
      "step: 420032/583123 epoch 16: ...  - loss: 0.3056 - mean_absolute_error: 0.2433 - mean_squared_error: 0.2963 - rmse: 0.4130\n",
      "step: 470032/583123 epoch 16: ...  - loss: 0.3409 - mean_absolute_error: 0.2604 - mean_squared_error: 0.3317 - rmse: 0.4385\n",
      "step: 520032/583123 epoch 16: ...  - loss: 0.3321 - mean_absolute_error: 0.2696 - mean_squared_error: 0.3224 - rmse: 0.4424\n",
      "step: 570032/583123 epoch 16: ...  - loss: 0.3240 - mean_absolute_error: 0.2494 - mean_squared_error: 0.3145 - rmse: 0.4248\n",
      " - 558s - loss: 0.3206 - mean_absolute_error: 0.2581 - mean_squared_error: 0.3109 - rmse: 0.4289 - val_loss: 0.3196 - val_mean_absolute_error: 0.2860 - val_mean_squared_error: 0.3100 - val_rmse: 0.4493\n",
      "Epoch 18/100\n",
      "step: 36909/583123 epoch 17: ...  - loss: 0.3263 - mean_absolute_error: 0.2579 - mean_squared_error: 0.3168 - rmse: 0.4317\n",
      "step: 86909/583123 epoch 17: ...  - loss: 0.3233 - mean_absolute_error: 0.2663 - mean_squared_error: 0.3133 - rmse: 0.4344\n",
      "step: 136909/583123 epoch 17: ...  - loss: 0.3146 - mean_absolute_error: 0.2582 - mean_squared_error: 0.3046 - rmse: 0.4277\n",
      "step: 186909/583123 epoch 17: ...  - loss: 0.3254 - mean_absolute_error: 0.2556 - mean_squared_error: 0.3157 - rmse: 0.4305\n",
      "step: 236909/583123 epoch 17: ...  - loss: 0.3229 - mean_absolute_error: 0.2393 - mean_squared_error: 0.3134 - rmse: 0.4184\n",
      "step: 286909/583123 epoch 17: ...  - loss: 0.3184 - mean_absolute_error: 0.2451 - mean_squared_error: 0.3089 - rmse: 0.4200\n",
      "step: 336909/583123 epoch 17: ...  - loss: 0.3044 - mean_absolute_error: 0.2298 - mean_squared_error: 0.2951 - rmse: 0.4039\n",
      "step: 386909/583123 epoch 17: ...  - loss: 0.3030 - mean_absolute_error: 0.2402 - mean_squared_error: 0.2937 - rmse: 0.4099\n",
      "step: 436909/583123 epoch 17: ...  - loss: 0.3083 - mean_absolute_error: 0.2441 - mean_squared_error: 0.2986 - rmse: 0.4143\n",
      "step: 486909/583123 epoch 17: ...  - loss: 0.3313 - mean_absolute_error: 0.2569 - mean_squared_error: 0.3214 - rmse: 0.4312\n",
      "step: 536909/583123 epoch 17: ...  - loss: 0.3235 - mean_absolute_error: 0.2602 - mean_squared_error: 0.3138 - rmse: 0.4315\n",
      " - 564s - loss: 0.3188 - mean_absolute_error: 0.2507 - mean_squared_error: 0.3092 - rmse: 0.4235 - val_loss: 0.4283 - val_mean_absolute_error: 0.3830 - val_mean_squared_error: 0.4187 - val_rmse: 0.5599\n",
      "Epoch 19/100\n",
      "step: 3786/583123 epoch 18: ...  - loss: 0.3287 - mean_absolute_error: 0.2583 - mean_squared_error: 0.3190 - rmse: 0.4316\n",
      "step: 53786/583123 epoch 18: ...  - loss: 0.3105 - mean_absolute_error: 0.2611 - mean_squared_error: 0.3006 - rmse: 0.4260\n",
      "step: 103786/583123 epoch 18: ...  - loss: 0.3056 - mean_absolute_error: 0.2414 - mean_squared_error: 0.2962 - rmse: 0.4107\n",
      "step: 153786/583123 epoch 18: ...  - loss: 0.3117 - mean_absolute_error: 0.2454 - mean_squared_error: 0.3024 - rmse: 0.4172\n",
      "step: 203786/583123 epoch 18: ...  - loss: 0.3096 - mean_absolute_error: 0.2483 - mean_squared_error: 0.3004 - rmse: 0.4180\n",
      "step: 253786/583123 epoch 18: ...  - loss: 0.3290 - mean_absolute_error: 0.2646 - mean_squared_error: 0.3197 - rmse: 0.4377\n",
      "step: 303786/583123 epoch 18: ...  - loss: 0.3253 - mean_absolute_error: 0.2600 - mean_squared_error: 0.3156 - rmse: 0.4336\n",
      "step: 353786/583123 epoch 18: ...  - loss: 0.3274 - mean_absolute_error: 0.2462 - mean_squared_error: 0.3180 - rmse: 0.4243\n",
      "step: 403786/583123 epoch 18: ...  - loss: 0.2990 - mean_absolute_error: 0.2359 - mean_squared_error: 0.2899 - rmse: 0.4066\n",
      "step: 453786/583123 epoch 18: ...  - loss: 0.3788 - mean_absolute_error: 0.2522 - mean_squared_error: 0.3698 - rmse: 0.4507\n",
      "step: 503786/583123 epoch 18: ...  - loss: 0.3184 - mean_absolute_error: 0.2564 - mean_squared_error: 0.3091 - rmse: 0.4282\n",
      "step: 553786/583123 epoch 18: ...  - loss: 0.3366 - mean_absolute_error: 0.2736 - mean_squared_error: 0.3269 - rmse: 0.4456\n",
      " - 560s - loss: 0.3241 - mean_absolute_error: 0.2548 - mean_squared_error: 0.3147 - rmse: 0.4286 - val_loss: 0.2520 - val_mean_absolute_error: 0.2013 - val_mean_squared_error: 0.2417 - val_rmse: 0.3632\n",
      "Epoch 20/100\n",
      "step: 20663/583123 epoch 19: ...  - loss: 0.3295 - mean_absolute_error: 0.2748 - mean_squared_error: 0.3195 - rmse: 0.4429\n",
      "step: 70663/583123 epoch 19: ...  - loss: 0.3150 - mean_absolute_error: 0.2574 - mean_squared_error: 0.3052 - rmse: 0.4265\n",
      "step: 120663/583123 epoch 19: ...  - loss: 0.3280 - mean_absolute_error: 0.2719 - mean_squared_error: 0.3181 - rmse: 0.4406\n",
      "step: 170663/583123 epoch 19: ...  - loss: 0.3151 - mean_absolute_error: 0.2598 - mean_squared_error: 0.3048 - rmse: 0.4265\n",
      "step: 220663/583123 epoch 19: ...  - loss: 0.3014 - mean_absolute_error: 0.2587 - mean_squared_error: 0.2916 - rmse: 0.4212\n",
      "step: 270663/583123 epoch 19: ...  - loss: 0.3083 - mean_absolute_error: 0.2502 - mean_squared_error: 0.2989 - rmse: 0.4196\n",
      "step: 320663/583123 epoch 19: ...  - loss: 0.3173 - mean_absolute_error: 0.2505 - mean_squared_error: 0.3077 - rmse: 0.4221\n",
      "step: 370663/583123 epoch 19: ...  - loss: 0.3004 - mean_absolute_error: 0.2413 - mean_squared_error: 0.2910 - rmse: 0.4109\n",
      "step: 420663/583123 epoch 19: ...  - loss: 0.3317 - mean_absolute_error: 0.2608 - mean_squared_error: 0.3222 - rmse: 0.4350\n",
      "step: 470663/583123 epoch 19: ...  - loss: 0.3003 - mean_absolute_error: 0.2430 - mean_squared_error: 0.2912 - rmse: 0.4114\n",
      "step: 520663/583123 epoch 19: ...  - loss: 0.3252 - mean_absolute_error: 0.2635 - mean_squared_error: 0.3160 - rmse: 0.4346\n",
      "step: 570663/583123 epoch 19: ...  - loss: 0.3237 - mean_absolute_error: 0.2509 - mean_squared_error: 0.3144 - rmse: 0.4252\n",
      " - 559s - loss: 0.3152 - mean_absolute_error: 0.2554 - mean_squared_error: 0.3056 - rmse: 0.4249 - val_loss: 0.2468 - val_mean_absolute_error: 0.2238 - val_mean_squared_error: 0.2377 - val_rmse: 0.3696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "step: 37540/583123 epoch 20: ...  - loss: 0.3104 - mean_absolute_error: 0.2410 - mean_squared_error: 0.3012 - rmse: 0.4137\n",
      "step: 87540/583123 epoch 20: ...  - loss: 0.3223 - mean_absolute_error: 0.2579 - mean_squared_error: 0.3133 - rmse: 0.4307\n",
      "step: 137540/583123 epoch 20: ...  - loss: 0.3566 - mean_absolute_error: 0.2686 - mean_squared_error: 0.3474 - rmse: 0.4503\n",
      "step: 187540/583123 epoch 20: ...  - loss: 0.3147 - mean_absolute_error: 0.2435 - mean_squared_error: 0.3059 - rmse: 0.4167\n",
      "step: 237540/583123 epoch 20: ...  - loss: 0.3229 - mean_absolute_error: 0.2468 - mean_squared_error: 0.3140 - rmse: 0.4228\n",
      "step: 287540/583123 epoch 20: ...  - loss: 0.3194 - mean_absolute_error: 0.2630 - mean_squared_error: 0.3102 - rmse: 0.4319\n",
      "step: 337540/583123 epoch 20: ...  - loss: 0.3014 - mean_absolute_error: 0.2520 - mean_squared_error: 0.2919 - rmse: 0.4171\n",
      "step: 387540/583123 epoch 20: ...  - loss: 0.3061 - mean_absolute_error: 0.2458 - mean_squared_error: 0.2969 - rmse: 0.4155\n",
      "step: 437540/583123 epoch 20: ...  - loss: 0.3396 - mean_absolute_error: 0.2642 - mean_squared_error: 0.3303 - rmse: 0.4401\n",
      "step: 487540/583123 epoch 20: ...  - loss: 0.3049 - mean_absolute_error: 0.2457 - mean_squared_error: 0.2956 - rmse: 0.4146\n",
      "step: 537540/583123 epoch 20: ...  - loss: 0.3144 - mean_absolute_error: 0.2605 - mean_squared_error: 0.3045 - rmse: 0.4270\n",
      " - 563s - loss: 0.3186 - mean_absolute_error: 0.2534 - mean_squared_error: 0.3093 - rmse: 0.4250 - val_loss: 0.2472 - val_mean_absolute_error: 0.2138 - val_mean_squared_error: 0.2375 - val_rmse: 0.3722\n",
      "Epoch 22/100\n",
      "step: 4417/583123 epoch 21: ...  - loss: 0.3041 - mean_absolute_error: 0.2471 - mean_squared_error: 0.2946 - rmse: 0.4152\n",
      "step: 54417/583123 epoch 21: ...  - loss: 0.3373 - mean_absolute_error: 0.2817 - mean_squared_error: 0.3277 - rmse: 0.4511\n",
      "step: 104417/583123 epoch 21: ...  - loss: 0.3138 - mean_absolute_error: 0.2575 - mean_squared_error: 0.3043 - rmse: 0.4246\n",
      "step: 154417/583123 epoch 21: ...  - loss: 0.3240 - mean_absolute_error: 0.2490 - mean_squared_error: 0.3146 - rmse: 0.4237\n",
      "step: 204417/583123 epoch 21: ...  - loss: 0.3047 - mean_absolute_error: 0.2471 - mean_squared_error: 0.2952 - rmse: 0.4142\n",
      "step: 254417/583123 epoch 21: ...  - loss: 0.3102 - mean_absolute_error: 0.2508 - mean_squared_error: 0.3006 - rmse: 0.4210\n",
      "step: 304417/583123 epoch 21: ...  - loss: 0.3199 - mean_absolute_error: 0.2626 - mean_squared_error: 0.3101 - rmse: 0.4315\n",
      "step: 354417/583123 epoch 21: ...  - loss: 0.3342 - mean_absolute_error: 0.2511 - mean_squared_error: 0.3247 - rmse: 0.4306\n",
      "step: 404417/583123 epoch 21: ...  - loss: 0.3171 - mean_absolute_error: 0.2486 - mean_squared_error: 0.3077 - rmse: 0.4220\n",
      "step: 454417/583123 epoch 21: ...  - loss: 0.3197 - mean_absolute_error: 0.2678 - mean_squared_error: 0.3100 - rmse: 0.4342\n",
      "step: 504417/583123 epoch 21: ...  - loss: 0.3323 - mean_absolute_error: 0.2700 - mean_squared_error: 0.3226 - rmse: 0.4420\n",
      "step: 554417/583123 epoch 21: ...  - loss: 0.3080 - mean_absolute_error: 0.2629 - mean_squared_error: 0.2981 - rmse: 0.4269\n",
      " - 561s - loss: 0.3186 - mean_absolute_error: 0.2587 - mean_squared_error: 0.3090 - rmse: 0.4285 - val_loss: 0.4652 - val_mean_absolute_error: 0.3618 - val_mean_squared_error: 0.4555 - val_rmse: 0.5526\n",
      "Epoch 23/100\n",
      "step: 21294/583123 epoch 22: ...  - loss: 0.2975 - mean_absolute_error: 0.2591 - mean_squared_error: 0.2878 - rmse: 0.4208\n",
      "step: 71294/583123 epoch 22: ...  - loss: 0.3328 - mean_absolute_error: 0.2723 - mean_squared_error: 0.3231 - rmse: 0.4429\n",
      "step: 121294/583123 epoch 22: ...  - loss: 0.3170 - mean_absolute_error: 0.2736 - mean_squared_error: 0.3070 - rmse: 0.4375\n",
      "step: 171294/583123 epoch 22: ...  - loss: 0.3753 - mean_absolute_error: 0.3045 - mean_squared_error: 0.3647 - rmse: 0.4809\n",
      "step: 221294/583123 epoch 22: ...  - loss: 0.3394 - mean_absolute_error: 0.2994 - mean_squared_error: 0.3284 - rmse: 0.4632\n",
      "step: 271294/583123 epoch 22: ...  - loss: 0.3099 - mean_absolute_error: 0.2567 - mean_squared_error: 0.2998 - rmse: 0.4217\n",
      "step: 321294/583123 epoch 22: ...  - loss: 0.3017 - mean_absolute_error: 0.2500 - mean_squared_error: 0.2922 - rmse: 0.4152\n",
      "step: 371294/583123 epoch 22: ...  - loss: 0.3202 - mean_absolute_error: 0.2678 - mean_squared_error: 0.3105 - rmse: 0.4340\n",
      "step: 421294/583123 epoch 22: ...  - loss: 0.3105 - mean_absolute_error: 0.2531 - mean_squared_error: 0.3012 - rmse: 0.4214\n",
      "step: 471294/583123 epoch 22: ...  - loss: 0.3116 - mean_absolute_error: 0.2628 - mean_squared_error: 0.3020 - rmse: 0.4288\n",
      "step: 521294/583123 epoch 22: ...  - loss: 0.3346 - mean_absolute_error: 0.2611 - mean_squared_error: 0.3249 - rmse: 0.4361\n",
      "step: 571294/583123 epoch 22: ...  - loss: 0.3267 - mean_absolute_error: 0.2380 - mean_squared_error: 0.3176 - rmse: 0.4186\n",
      " - 565s - loss: 0.3246 - mean_absolute_error: 0.2671 - mean_squared_error: 0.3147 - rmse: 0.4360 - val_loss: 0.2479 - val_mean_absolute_error: 0.2521 - val_mean_squared_error: 0.2386 - val_rmse: 0.3927\n",
      "Epoch 24/100\n",
      "step: 38171/583123 epoch 23: ...  - loss: 0.3225 - mean_absolute_error: 0.2568 - mean_squared_error: 0.3131 - rmse: 0.4290\n",
      "step: 88171/583123 epoch 23: ...  - loss: 0.3265 - mean_absolute_error: 0.2673 - mean_squared_error: 0.3169 - rmse: 0.4374\n",
      "step: 138171/583123 epoch 23: ...  - loss: 0.3331 - mean_absolute_error: 0.2537 - mean_squared_error: 0.3238 - rmse: 0.4301\n",
      "step: 188171/583123 epoch 23: ...  - loss: 0.3399 - mean_absolute_error: 0.2571 - mean_squared_error: 0.3307 - rmse: 0.4347\n",
      "step: 238171/583123 epoch 23: ...  - loss: 0.3323 - mean_absolute_error: 0.2442 - mean_squared_error: 0.3233 - rmse: 0.4248\n",
      "step: 288171/583123 epoch 23: ...  - loss: 0.3145 - mean_absolute_error: 0.2381 - mean_squared_error: 0.3057 - rmse: 0.4136\n",
      "step: 338171/583123 epoch 23: ...  - loss: 0.3400 - mean_absolute_error: 0.2514 - mean_squared_error: 0.3311 - rmse: 0.4338\n",
      "step: 388171/583123 epoch 23: ...  - loss: 0.3154 - mean_absolute_error: 0.2532 - mean_squared_error: 0.3065 - rmse: 0.4244\n",
      "step: 438171/583123 epoch 23: ...  - loss: 0.3124 - mean_absolute_error: 0.2510 - mean_squared_error: 0.3034 - rmse: 0.4213\n",
      "step: 488171/583123 epoch 23: ...  - loss: 0.3166 - mean_absolute_error: 0.2487 - mean_squared_error: 0.3076 - rmse: 0.4220\n",
      "step: 538171/583123 epoch 23: ...  - loss: 0.3196 - mean_absolute_error: 0.2465 - mean_squared_error: 0.3107 - rmse: 0.4212\n",
      " - 559s - loss: 0.3238 - mean_absolute_error: 0.2518 - mean_squared_error: 0.3147 - rmse: 0.4263 - val_loss: 0.2432 - val_mean_absolute_error: 0.1851 - val_mean_squared_error: 0.2342 - val_rmse: 0.3456\n",
      "Epoch 25/100\n",
      "step: 5048/583123 epoch 24: ...  - loss: 0.3095 - mean_absolute_error: 0.2543 - mean_squared_error: 0.3004 - rmse: 0.4221\n",
      "step: 55048/583123 epoch 24: ...  - loss: 0.3077 - mean_absolute_error: 0.2482 - mean_squared_error: 0.2986 - rmse: 0.4173\n",
      "step: 105048/583123 epoch 24: ...  - loss: 0.3480 - mean_absolute_error: 0.2638 - mean_squared_error: 0.3388 - rmse: 0.4426\n",
      "step: 155048/583123 epoch 24: ...  - loss: 0.3039 - mean_absolute_error: 0.2412 - mean_squared_error: 0.2950 - rmse: 0.4108\n",
      "step: 205048/583123 epoch 24: ...  - loss: 0.3331 - mean_absolute_error: 0.2465 - mean_squared_error: 0.3244 - rmse: 0.4264\n",
      "step: 255048/583123 epoch 24: ...  - loss: 0.3656 - mean_absolute_error: 0.2601 - mean_squared_error: 0.3568 - rmse: 0.4508\n",
      "step: 305048/583123 epoch 24: ...  - loss: 0.3281 - mean_absolute_error: 0.2600 - mean_squared_error: 0.3192 - rmse: 0.4331\n",
      "step: 355048/583123 epoch 24: ...  - loss: 0.3074 - mean_absolute_error: 0.2445 - mean_squared_error: 0.2986 - rmse: 0.4137\n",
      "step: 405048/583123 epoch 24: ...  - loss: 0.3126 - mean_absolute_error: 0.2432 - mean_squared_error: 0.3040 - rmse: 0.4161\n",
      "step: 455048/583123 epoch 24: ...  - loss: 0.3284 - mean_absolute_error: 0.2611 - mean_squared_error: 0.3191 - rmse: 0.4349\n",
      "step: 505048/583123 epoch 24: ...  - loss: 0.3188 - mean_absolute_error: 0.2554 - mean_squared_error: 0.3097 - rmse: 0.4263\n",
      "step: 555048/583123 epoch 24: ...  - loss: 0.3327 - mean_absolute_error: 0.2548 - mean_squared_error: 0.3236 - rmse: 0.4330\n",
      " - 560s - loss: 0.3255 - mean_absolute_error: 0.2528 - mean_squared_error: 0.3165 - rmse: 0.4276 - val_loss: 0.2415 - val_mean_absolute_error: 0.2070 - val_mean_squared_error: 0.2322 - val_rmse: 0.3574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.24154194670862872\n",
      "val_mean_absolute_error: 0.20695933225676527\n",
      "score\n",
      "[0.24154194670862872, 0.20695933225676527, 0.23217169452717262, 0.4216520327460986]\n",
      "model.metrics_names\n",
      "['loss', 'mean_absolute_error', 'mean_squared_error', 'rmse']\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',   #categorical_crossentropy\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"mae\", \"mean_squared_error\", rmse])\n",
    "\n",
    "# Add CallBacks (including TensorBoard)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "        log_dir='TensorBoard_logs/' + str(file_name), write_graph = False, write_images=False, write_grads=False)\n",
    "EarlyStoppingCallBack = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_rmse', min_delta=0, patience=15, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit([x_train_1, x_train_2],\n",
    "                    y = y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    # validation_data=(x_test, y_test),\n",
    "                    validation_data=([x_test_1, x_test_2], y_test),\n",
    "                    callbacks=[tbCallBack, EarlyStoppingCallBack, NBatchLogger(5e4)])\n",
    "#5e4\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = model.evaluate([x_test_1, x_test_2], y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('val_mean_absolute_error:', score[1])\n",
    "\n",
    "print(\"score\")\n",
    "print(score)\n",
    "\n",
    "print(\"model.metrics_names\")\n",
    "print(model.metrics_names)\n",
    "\n",
    "# creates a HDF5 file 'my_model.h5'\n",
    "model.save(\"./Saved-Networks/\" + str(file_name) +\".h5\")\n",
    "\n",
    "# Create output file\n",
    "OutputFile = open(\"./Loss-Values/\" +str(file_name) +\".txt\", \"w+\")\n",
    "OutputFile.write(\"Test loss: \" + str(score[0]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_absolute_error: \" +str(score[1]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_squared_error: \" +str(score[2]) + \"\\n\")\n",
    "OutputFile.write(\"RMSE: \" +str(score[3]) + \"\\n\")\n",
    "OutputFile.close()\n",
    "\n",
    "del history\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0**1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "with tf_session.as_default():\n",
    "    display(((K.abs(0.)) ** (K.clip(K.abs(.5), 0.5, 3))).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
