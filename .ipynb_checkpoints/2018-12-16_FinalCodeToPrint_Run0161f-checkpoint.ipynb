{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.optimizers import RMSprop, adam, Adam\n",
    "from keras.initializers import TruncatedNormal, glorot_normal, Constant\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new Metric: rmse = Root Mean Square Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( y_true-y_pred )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the current file name. Useful for procedurally generating output/log files.\n",
    "file_name =  os.path.basename(sys.argv[0][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters\n",
    "batch_size = 10\n",
    "epochs = 100\n",
    "L2_regularization = 5E-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (which is in HDF5 or .h5 format)\n",
    "store = pandas.HDFStore(\"training_gen3_7D_nions0_flat_filter8.h5\")\n",
    "target_df = store['/output/efeETG_GB'].to_frame()  # This one is relatively easy to train\n",
    "input_df = store['input']\n",
    "\n",
    "# Puts inputs and outputs in the same pandas dataframe.\n",
    "# Also only keeps overlapping entries.\n",
    "joined_dataFrame = target_df.join(input_df)\n",
    "\n",
    "# Make a copy of joined_dataFrame for later use\n",
    "joined_dataFrame_original = deepcopy(joined_dataFrame)\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "# Standard configuration\n",
    "joined_dataFrame['efeETG_GB'] = (joined_dataFrame['efeETG_GB'] - joined_dataFrame['efeETG_GB'].mean()) / joined_dataFrame['efeETG_GB'].std()\n",
    "joined_dataFrame['Ati'] = (joined_dataFrame['Ati'] - joined_dataFrame['Ati'].mean()) / joined_dataFrame['Ati'].std()\n",
    "joined_dataFrame['Ate'] = (joined_dataFrame['Ate'] - joined_dataFrame['Ate'].mean()) / joined_dataFrame['Ate'].std()\n",
    "joined_dataFrame['An'] = (joined_dataFrame['An'] - joined_dataFrame['An'].mean()) / joined_dataFrame['An'].std()\n",
    "joined_dataFrame['q'] = (joined_dataFrame['q'] - joined_dataFrame['q'].mean()) / joined_dataFrame['q'].std()\n",
    "joined_dataFrame['smag'] = (joined_dataFrame['smag'] - joined_dataFrame['smag'].mean()) / joined_dataFrame['smag'].std()\n",
    "joined_dataFrame['x'] = (joined_dataFrame['x'] - joined_dataFrame['x'].mean()) / joined_dataFrame['x'].std()\n",
    "joined_dataFrame['Ti_Te'] = (joined_dataFrame['Ti_Te'] - joined_dataFrame['Ti_Te'].mean()) / joined_dataFrame['Ti_Te'].std()\n",
    "\n",
    "# Shuffles dataset\n",
    "shuffled_joined_dataFrame = joined_dataFrame.reindex(numpy.random.permutation(\n",
    "                                                joined_dataFrame.index))\n",
    "\n",
    "# Creates a pandas dataframe for the outputs\n",
    "shuffled_clean_output_df = shuffled_joined_dataFrame['efeETG_GB']\n",
    "\n",
    "# Make a copy of shuffled_joined_dataFrame for later use\n",
    "shuffled_joined_dataFrame_base = deepcopy(shuffled_joined_dataFrame)\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Creates a pandas dataframe for the inputs (7D)\n",
    "shuffled_clean_input_df_7D = shuffled_joined_dataFrame.drop('efeETG_GB', axis=1)\n",
    "\n",
    "# Creates training dataset (90% of total data) for outputs\n",
    "y_train = shuffled_clean_output_df.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9))]\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train = shuffled_clean_input_df_7D.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for outputs\n",
    "y_test = shuffled_clean_output_df.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9)):]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test = shuffled_clean_input_df_7D.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9)):]\n",
    "# *************************************************************************** #\n",
    "\n",
    "\n",
    "# Deletes pandas dataframes that are no longer needed\n",
    "del target_df, input_df\n",
    "\n",
    "# Closes the HDFStore. This is good practice.\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe for the inputs\n",
    "shuffled_clean_input_df_1 = shuffled_clean_input_df_7D.drop('Ate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_7D.drop('Ati', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('An', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('q', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('smag', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('x', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('Ti_Te', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 1)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 1\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_1 = shuffled_clean_input_df_1.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_1 = shuffled_clean_input_df_1.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 2\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_2 = shuffled_clean_input_df_2.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_2 = shuffled_clean_input_df_2.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "6D_INPUTS (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch1 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch1 (Dense)         (None, 30)           930         hidden1_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1 (Dense)           (None, 1)            31          hidden2_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch3 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1_feeder (Dense)    (None, 1)            2           theta_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Ate_INPUT (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch3 (Dense)         (None, 30)           930         hidden1_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch4 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Addition_Operator (Add)         (None, 1)            0           theta_branch1_feeder[0][0]       \n",
      "                                                                 Ate_INPUT[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3 (Dense)             (None, 1)            31          hidden2_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch4 (Dense)         (None, 30)           930         hidden1_branch4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "TR (Dense)                      (None, 1)            2           Addition_Operator[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Power_Operator (Lambda)         (None, 1)            0           Addition_Operator[0][0]          \n",
      "                                                                 c_3_branch3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "m_branch4 (Dense)               (None, 1)            31          hidden2_branch4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Multiplication_Operator_1 (Mult (None, 1)            0           TR[0][0]                         \n",
      "                                                                 Power_Operator[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Multiplication_Operator_2 (Mult (None, 1)            0           m_branch4[0][0]                  \n",
      "                                                                 Multiplication_Operator_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer (Dense)            (None, 1)            2           Multiplication_Operator_2[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 3,519\n",
      "Trainable params: 3,515\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# branch1\n",
    "visible_branch1 = Input(shape=(6, ), name=\"6D_INPUTS\")\n",
    "hidden1_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch1\")(visible_branch1)\n",
    "hidden2_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch1\")(hidden1_branch1)\n",
    "theta_branch1 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"theta_branch1\")(hidden2_branch1)\n",
    "theta_branch1_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=-1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"theta_branch1_feeder\")(theta_branch1)\n",
    "\n",
    "# branch2 (Ate input)\n",
    "visible_branch2 = Input(shape=(1, ), name=\"Ate_INPUT\")\n",
    "\n",
    "# Addition_Operator (effectively subtraction though...)\n",
    "addition_operator = keras.layers.Add(name=\"Addition_Operator\")([theta_branch1_feeder, visible_branch2])\n",
    "\n",
    "# ReLU Layer\n",
    "TR = Dense(1, activation='relu',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=False,\n",
    "           name=\"TR\")(addition_operator)\n",
    "\n",
    "# branch 3 (for c_3)\n",
    "hidden1_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch3\")(visible_branch1)\n",
    "hidden2_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch3\")(hidden1_branch3)\n",
    "c_3_branch3 = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        trainable=True,\n",
    "        name=\"c_3_branch3\")(hidden2_branch3)\n",
    "\n",
    "# Power_Operator    \n",
    "power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.00001, 1000)) ** (K.clip(x[1], -2., 4.)), name=\"Power_Operator\")\n",
    "power_operator = power_layer([addition_operator, c_3_branch3])\n",
    "\n",
    "# branch 4 (for the gradient)\n",
    "hidden1_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch4\")(visible_branch1)\n",
    "hidden2_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch4\")(hidden1_branch4)\n",
    "m_branch4 = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        trainable=True,\n",
    "        name=\"m_branch4\")(hidden2_branch4)   \n",
    "\n",
    "# Multiplication_Operator_1\n",
    "multiplication_operator_1 = keras.layers.Multiply(name=\"Multiplication_Operator_1\")([TR, power_operator])\n",
    "\n",
    "# Multiplication_Operator_2\n",
    "multiplication_operator_2 = keras.layers.Multiply(name=\"Multiplication_Operator_2\")([m_branch4, multiplication_operator_1])\n",
    "\n",
    "# Output_Layer\n",
    "output = Dense(1, activation='linear',\n",
    "           kernel_initializer='Ones',\n",
    "           kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=True,\n",
    "           name=\"Output_Layer\")(multiplication_operator_2)\n",
    "\n",
    "model = Model(inputs=[visible_branch1, visible_branch2], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph\n",
    "plot_model(model, 'ModelPlots/' + str(file_name) + '_model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5831223 samples, validate on 647914 samples\n",
      "Epoch 1/100\n",
      " - 865s - loss: 0.1028 - mean_absolute_error: 0.0913 - mean_squared_error: 0.1025 - rmse: 0.2148 - val_loss: 0.0759 - val_mean_absolute_error: 0.0788 - val_mean_squared_error: 0.0755 - val_rmse: 0.1824\n",
      "Epoch 2/100\n",
      " - 894s - loss: 0.0759 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0754 - rmse: 0.1834 - val_loss: 0.0657 - val_mean_absolute_error: 0.0739 - val_mean_squared_error: 0.0651 - val_rmse: 0.1715\n",
      "Epoch 3/100\n",
      " - 898s - loss: 0.0714 - mean_absolute_error: 0.0729 - mean_squared_error: 0.0707 - rmse: 0.1762 - val_loss: 0.0667 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0660 - val_rmse: 0.1700\n",
      "Epoch 4/100\n",
      " - 895s - loss: 0.0689 - mean_absolute_error: 0.0711 - mean_squared_error: 0.0681 - rmse: 0.1723 - val_loss: 0.0659 - val_mean_absolute_error: 0.0711 - val_mean_squared_error: 0.0651 - val_rmse: 0.1684\n",
      "Epoch 5/100\n",
      " - 895s - loss: 0.0680 - mean_absolute_error: 0.0705 - mean_squared_error: 0.0671 - rmse: 0.1708 - val_loss: 0.0616 - val_mean_absolute_error: 0.0650 - val_mean_squared_error: 0.0607 - val_rmse: 0.1625\n",
      "Epoch 6/100\n",
      " - 895s - loss: 0.0673 - mean_absolute_error: 0.0699 - mean_squared_error: 0.0664 - rmse: 0.1696 - val_loss: 0.0695 - val_mean_absolute_error: 0.0714 - val_mean_squared_error: 0.0685 - val_rmse: 0.1718\n",
      "Epoch 7/100\n",
      " - 895s - loss: 0.0668 - mean_absolute_error: 0.0694 - mean_squared_error: 0.0658 - rmse: 0.1687 - val_loss: 0.0642 - val_mean_absolute_error: 0.0648 - val_mean_squared_error: 0.0632 - val_rmse: 0.1633\n",
      "Epoch 8/100\n",
      " - 895s - loss: 0.0665 - mean_absolute_error: 0.0690 - mean_squared_error: 0.0655 - rmse: 0.1679 - val_loss: 0.0608 - val_mean_absolute_error: 0.0654 - val_mean_squared_error: 0.0597 - val_rmse: 0.1610\n",
      "Epoch 9/100\n",
      " - 896s - loss: 0.0662 - mean_absolute_error: 0.0688 - mean_squared_error: 0.0651 - rmse: 0.1675 - val_loss: 0.0621 - val_mean_absolute_error: 0.0675 - val_mean_squared_error: 0.0610 - val_rmse: 0.1591\n",
      "Epoch 10/100\n",
      " - 893s - loss: 0.0661 - mean_absolute_error: 0.0686 - mean_squared_error: 0.0649 - rmse: 0.1671 - val_loss: 0.0634 - val_mean_absolute_error: 0.0688 - val_mean_squared_error: 0.0622 - val_rmse: 0.1667\n",
      "Epoch 11/100\n",
      " - 893s - loss: 0.0662 - mean_absolute_error: 0.0686 - mean_squared_error: 0.0650 - rmse: 0.1670 - val_loss: 0.0750 - val_mean_absolute_error: 0.0704 - val_mean_squared_error: 0.0737 - val_rmse: 0.1741\n",
      "Epoch 12/100\n",
      " - 892s - loss: 0.0658 - mean_absolute_error: 0.0684 - mean_squared_error: 0.0646 - rmse: 0.1666 - val_loss: 0.0631 - val_mean_absolute_error: 0.0663 - val_mean_squared_error: 0.0619 - val_rmse: 0.1636\n",
      "Epoch 13/100\n",
      " - 889s - loss: 0.0656 - mean_absolute_error: 0.0682 - mean_squared_error: 0.0643 - rmse: 0.1661 - val_loss: 0.0618 - val_mean_absolute_error: 0.0685 - val_mean_squared_error: 0.0605 - val_rmse: 0.1629\n",
      "Epoch 14/100\n",
      " - 889s - loss: 0.0654 - mean_absolute_error: 0.0681 - mean_squared_error: 0.0641 - rmse: 0.1658 - val_loss: 0.0647 - val_mean_absolute_error: 0.0673 - val_mean_squared_error: 0.0633 - val_rmse: 0.1637\n",
      "Epoch 15/100\n",
      " - 890s - loss: 0.0653 - mean_absolute_error: 0.0679 - mean_squared_error: 0.0639 - rmse: 0.1655 - val_loss: 0.0586 - val_mean_absolute_error: 0.0634 - val_mean_squared_error: 0.0572 - val_rmse: 0.1546\n",
      "Epoch 16/100\n",
      " - 890s - loss: 0.0650 - mean_absolute_error: 0.0678 - mean_squared_error: 0.0636 - rmse: 0.1652 - val_loss: 0.0799 - val_mean_absolute_error: 0.0714 - val_mean_squared_error: 0.0784 - val_rmse: 0.1748\n",
      "Epoch 17/100\n",
      " - 893s - loss: 0.0652 - mean_absolute_error: 0.0679 - mean_squared_error: 0.0638 - rmse: 0.1653 - val_loss: 0.0618 - val_mean_absolute_error: 0.0644 - val_mean_squared_error: 0.0603 - val_rmse: 0.1593\n",
      "Epoch 18/100\n",
      " - 892s - loss: 0.0650 - mean_absolute_error: 0.0677 - mean_squared_error: 0.0635 - rmse: 0.1651 - val_loss: 0.0627 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0612 - val_rmse: 0.1610\n",
      "Epoch 19/100\n",
      " - 890s - loss: 0.0648 - mean_absolute_error: 0.0676 - mean_squared_error: 0.0633 - rmse: 0.1646 - val_loss: 0.0628 - val_mean_absolute_error: 0.0685 - val_mean_squared_error: 0.0613 - val_rmse: 0.1610\n",
      "Epoch 20/100\n",
      " - 891s - loss: 0.0648 - mean_absolute_error: 0.0675 - mean_squared_error: 0.0633 - rmse: 0.1643 - val_loss: 0.0628 - val_mean_absolute_error: 0.0623 - val_mean_squared_error: 0.0613 - val_rmse: 0.1577\n",
      "Epoch 21/100\n",
      " - 889s - loss: 0.0642 - mean_absolute_error: 0.0672 - mean_squared_error: 0.0626 - rmse: 0.1637 - val_loss: 0.0657 - val_mean_absolute_error: 0.0639 - val_mean_squared_error: 0.0642 - val_rmse: 0.1626\n",
      "Epoch 22/100\n",
      " - 890s - loss: 0.0640 - mean_absolute_error: 0.0670 - mean_squared_error: 0.0625 - rmse: 0.1633 - val_loss: 0.0627 - val_mean_absolute_error: 0.0656 - val_mean_squared_error: 0.0612 - val_rmse: 0.1614\n",
      "Epoch 23/100\n",
      " - 889s - loss: 0.0642 - mean_absolute_error: 0.0671 - mean_squared_error: 0.0626 - rmse: 0.1635 - val_loss: 0.0688 - val_mean_absolute_error: 0.0718 - val_mean_squared_error: 0.0672 - val_rmse: 0.1707\n",
      "Epoch 24/100\n",
      " - 889s - loss: 0.0637 - mean_absolute_error: 0.0668 - mean_squared_error: 0.0621 - rmse: 0.1627 - val_loss: 0.0650 - val_mean_absolute_error: 0.0658 - val_mean_squared_error: 0.0634 - val_rmse: 0.1657\n",
      "Epoch 25/100\n",
      " - 890s - loss: 0.0636 - mean_absolute_error: 0.0667 - mean_squared_error: 0.0620 - rmse: 0.1624 - val_loss: 0.0702 - val_mean_absolute_error: 0.0730 - val_mean_squared_error: 0.0686 - val_rmse: 0.1706\n",
      "Epoch 26/100\n",
      " - 892s - loss: 0.0635 - mean_absolute_error: 0.0667 - mean_squared_error: 0.0619 - rmse: 0.1624 - val_loss: 0.0598 - val_mean_absolute_error: 0.0656 - val_mean_squared_error: 0.0582 - val_rmse: 0.1559\n",
      "Epoch 27/100\n",
      " - 892s - loss: 0.0633 - mean_absolute_error: 0.0664 - mean_squared_error: 0.0617 - rmse: 0.1619 - val_loss: 0.0765 - val_mean_absolute_error: 0.0800 - val_mean_squared_error: 0.0748 - val_rmse: 0.1819\n",
      "Epoch 28/100\n",
      " - 892s - loss: 0.0634 - mean_absolute_error: 0.0665 - mean_squared_error: 0.0618 - rmse: 0.1621 - val_loss: 0.0736 - val_mean_absolute_error: 0.0719 - val_mean_squared_error: 0.0720 - val_rmse: 0.1794\n",
      "Epoch 29/100\n",
      " - 890s - loss: 0.0632 - mean_absolute_error: 0.0664 - mean_squared_error: 0.0615 - rmse: 0.1618 - val_loss: 0.0697 - val_mean_absolute_error: 0.0728 - val_mean_squared_error: 0.0680 - val_rmse: 0.1695\n",
      "Epoch 30/100\n",
      " - 889s - loss: 0.0633 - mean_absolute_error: 0.0663 - mean_squared_error: 0.0616 - rmse: 0.1617 - val_loss: 0.0646 - val_mean_absolute_error: 0.0643 - val_mean_squared_error: 0.0630 - val_rmse: 0.1626\n",
      "Test loss: 0.06464518402595539\n",
      "val_mean_absolute_error: 0.06431469321667191\n",
      "score\n",
      "[0.06464518402595539, 0.06431469321667191, 0.06296635629553392, 0.20963224122264976]\n",
      "model.metrics_names\n",
      "['loss', 'mean_absolute_error', 'mean_squared_error', 'rmse']\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',   #categorical_crossentropy\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"mae\", \"mean_squared_error\", rmse])\n",
    "\n",
    "# Add CallBacks (including TensorBoard)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "        log_dir='TensorBoard_logs/' + str(file_name), write_graph = False, write_images=False, write_grads=False)\n",
    "EarlyStoppingCallBack = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_rmse', min_delta=0, patience=15, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit([x_train_1, x_train_2],\n",
    "                    y = y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    validation_data=([x_test_1, x_test_2], y_test),\n",
    "                    callbacks=[tbCallBack, EarlyStoppingCallBack])\n",
    "\n",
    "score = model.evaluate([x_test_1, x_test_2], y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('val_mean_absolute_error:', score[1])\n",
    "\n",
    "print(\"score\")\n",
    "print(score)\n",
    "\n",
    "print(\"model.metrics_names\")\n",
    "print(model.metrics_names)\n",
    "\n",
    "# creates a HDF5 file 'my_model.h5'\n",
    "model.save(\"./Saved-Networks/\" + str(file_name) +\".h5\")\n",
    "\n",
    "# Create output file\n",
    "OutputFile = open(\"./Loss-Values/\" +str(file_name) +\".txt\", \"w+\")\n",
    "OutputFile.write(\"Test loss: \" + str(score[0]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_absolute_error: \" +str(score[1]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_squared_error: \" +str(score[2]) + \"\\n\")\n",
    "OutputFile.write(\"RMSE: \" +str(score[3]) + \"\\n\")\n",
    "OutputFile.close()\n",
    "\n",
    "del history\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
