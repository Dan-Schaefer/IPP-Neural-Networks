{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting dataslices for Run0126g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting_Run0126g\n",
    "-  Experiment: see if cut-off in Bokeh viewer is possible a Bokeh front-end artefact or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Gets the current file name. Useful for procedurally generating output/log files.\n",
    "file_name =  os.path.basename(sys.argv[0][:-3])\n",
    "print(file_name)\n",
    "\n",
    "if file_name == \"ipykernel_launcher\":\n",
    "    print(\"This is the Jupyter version.\")\n",
    "    print(\"Now MANUALLY run the next two cells!\")\n",
    "    print(\"STOP! This should not be in your code!!\")\n",
    "    exit(0)\n",
    "    time.sleep(10)\n",
    "    print(\"Testing if script has really stopped.\")\n",
    "else:\n",
    "    print(\"This is the Atom version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IN JUPYTER!!\n",
    "# Start here (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = file_name[:-6]\n",
    "print(file_name)\n",
    "\n",
    "is_Jupyter = True\n",
    "print(is_Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code for both ATOM & JUPYTER from now (Run all cells below now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Late Fusion Module - Functional API\n",
    "'''\n",
    "\n",
    "# Multiple Inputs\n",
    "import keras\n",
    "from keras.optimizers import RMSprop, adam, Adam\n",
    "from keras.initializers import TruncatedNormal, glorot_normal\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.backend import switch\n",
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new Metric: rmse = Root Mean Square Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( y_true-y_pred )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify for ATOM use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_Jupyter == True:\n",
    "    pass\n",
    "else:\n",
    "    # Gets the current file name. Useful for procedurally generating output/log files.\n",
    "    file_name =  os.path.basename(sys.argv[0][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters\n",
    "batch_size = 10\n",
    "#num_classes = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (which is in HDF5 or .h5 format)\n",
    "store = pandas.HDFStore(\"../unstable_training_gen3_7D_nions0_flat_filter8.h5\")\n",
    "target_df = store['/output/efeETG_GB'].to_frame()  # This one is relatively easy to train\n",
    "input_df = store['input']\n",
    "\n",
    "# Puts inputs and outputs in the same pandas dataframe.\n",
    "# Also only keeps overlapping entries.\n",
    "joined_dataFrame = target_df.join(input_df)\n",
    "\n",
    "# Make a copy of joined_dataFrame for later use\n",
    "joined_dataFrame_original = deepcopy(joined_dataFrame)\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "# Standard configuration\n",
    "joined_dataFrame['efeETG_GB'] = (joined_dataFrame['efeETG_GB'] - joined_dataFrame['efeETG_GB'].mean()) / joined_dataFrame['efeETG_GB'].std()\n",
    "joined_dataFrame['Ati'] = (joined_dataFrame['Ati'] - joined_dataFrame['Ati'].mean()) / joined_dataFrame['Ati'].std()\n",
    "joined_dataFrame['Ate'] = (joined_dataFrame['Ate'] - joined_dataFrame['Ate'].mean()) / joined_dataFrame['Ate'].std()\n",
    "joined_dataFrame['An'] = (joined_dataFrame['An'] - joined_dataFrame['An'].mean()) / joined_dataFrame['An'].std()\n",
    "joined_dataFrame['q'] = (joined_dataFrame['q'] - joined_dataFrame['q'].mean()) / joined_dataFrame['q'].std()\n",
    "joined_dataFrame['smag'] = (joined_dataFrame['smag'] - joined_dataFrame['smag'].mean()) / joined_dataFrame['smag'].std()\n",
    "joined_dataFrame['x'] = (joined_dataFrame['x'] - joined_dataFrame['x'].mean()) / joined_dataFrame['x'].std()\n",
    "joined_dataFrame['Ti_Te'] = (joined_dataFrame['Ti_Te'] - joined_dataFrame['Ti_Te'].mean()) / joined_dataFrame['Ti_Te'].std()\n",
    "\n",
    "# Shuffles dataset\n",
    "shuffled_joined_dataFrame = joined_dataFrame.reindex(numpy.random.permutation(\n",
    "                                                joined_dataFrame.index))\n",
    "\n",
    "# Creates a pandas dataframe for the outputs\n",
    "shuffled_clean_output_df = shuffled_joined_dataFrame['efeETG_GB']\n",
    "\n",
    "# Make a copy of shuffled_joined_dataFrame for later use\n",
    "shuffled_joined_dataFrame_base = deepcopy(shuffled_joined_dataFrame)\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Creates a pandas dataframe for the inputs (7D)\n",
    "shuffled_clean_input_df_7D = shuffled_joined_dataFrame.drop('efeETG_GB', axis=1)\n",
    "\n",
    "# Creates training dataset (90% of total data) for outputs\n",
    "y_train = shuffled_clean_output_df.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9))]\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train = shuffled_clean_input_df_7D.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for outputs\n",
    "y_test = shuffled_clean_output_df.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9)):]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test = shuffled_clean_input_df_7D.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9)):]\n",
    "# *************************************************************************** #\n",
    "\n",
    "\n",
    "# Deletes pandas dataframes that are no longer needed\n",
    "del target_df, input_df\n",
    "\n",
    "# Closes the HDFStore. This is good practice.\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_7D.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe for the inputs\n",
    "shuffled_clean_input_df_1 = shuffled_clean_input_df_7D.drop('Ate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shuffled_clean_input_df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_7D.drop('Ati', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('An', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('q', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('smag', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('x', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('Ti_Te', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shuffled_clean_input_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 1\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_1 = shuffled_clean_input_df_1.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_1 = shuffled_clean_input_df_1.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 2\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_2 = shuffled_clean_input_df_2.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_2 = shuffled_clean_input_df_2.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('../Saved-Networks/2018-10-18_Run0126g.h5', custom_objects={'rmse': rmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions (Global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Global\" in this sense means that I've fed model.predict() with all the possible parameters. This gives a good overview of the overall performance of the network. This can be useful to spot large-scale phenomena like network overfitting but is not so great at looking at say individual data slices. This is done later.\n",
    "\n",
    "***Nota Bene: all data here is NORMALIZED at this stage.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np_array = y_test.values\n",
    "print(y_test_np_array)\n",
    "print(y_test_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_np_array = x_test.values\n",
    "print(x_test_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1_np_array = x_test_1.values\n",
    "x_test_2_np_array = x_test_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test_1_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test_2_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_global = new_model.predict([x_test_1_np_array, x_test_2_np_array], batch_size = 10, verbose=0)\n",
    "print(type(predictions_global))\n",
    "\n",
    "predictions_global = predictions_global.flatten()\n",
    "print(predictions_global.shape)\n",
    "print(type(predictions_global))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions (Global) review - De-Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_global_deNormalized = (predictions_global * joined_dataFrame_original['efeETG_GB'].std()) + joined_dataFrame_original['efeETG_GB'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_deNormalized = (y_test * joined_dataFrame_original['efeETG_GB'].std()) + joined_dataFrame_original['efeETG_GB'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_deNormalized_np_array = y_test_deNormalized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions_global_deNormalized)\n",
    "plt.title('QuaLiKiz-NN Predictions (De-Normalized) Histogram')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Counts')\n",
    "# plt.savefig('./2018-07-10_Run0050b_DataSlicerPlot/NN_Predictions.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions_global.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_deNormalized_np_array, predictions_global_deNormalized, 'r.', ms = 5, label = 'QuaLiKiz-NN')\n",
    "plt.title('QuaLiKiz-NN predictions (De-Normalized) (efeETG_GB) vs. QuaLiKiz (efeETG_GB)')\n",
    "plt.xlabel('QuaLiKiz')\n",
    "plt.ylabel('Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(y_test_deNormalized_np_array, predictions_global_deNormalized, bins=100, cmin=5)\n",
    "# plt.plot( [0,1],[0,1] )\n",
    "plt.title('QuaLiKiz vs Neural Network (De-Normalized) (non-log scale)')\n",
    "plt.xlabel('QuaLiKiz')\n",
    "plt.ylabel('Neural Network')\n",
    "plt.ylim(0)\n",
    "plt.xlim(0)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Counts')\n",
    "# plt.savefig('./2018-07-10_Run0050b_DataSlicerPlot/QuaLiKiz-vs-NN_nonLogScale_bins100.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmas (De-Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist2d(y_test_np_array, predictions_global,bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_deNormalized = plt.hist2d(y_test_deNormalized_np_array, predictions_global_deNormalized,bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_deNormalized = []\n",
    "Qualikiz_deNormalized = y_test_deNormalized_np_array\n",
    "for i in range(len(h[0])):\n",
    "    sigmas_deNormalized.append(numpy.std(h_deNormalized[0][i] / numpy.max(h_deNormalized[0][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((numpy.array(h_deNormalized[1][1:]) + numpy.array(h_deNormalized[1][:-1]))/2.,sigmas_deNormalized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot((h_deNormalized[1][1:] + h_deNormalized[1][:-1])/2., h_deNormalized[0][i]/numpy.max(h_deNormalized[0][i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_deNormalized_np_array, predictions_global_deNormalized - y_test_deNormalized_np_array, 'b.', ms = 0.5)\n",
    "plt.title('Neural Network predictions (De-Normalized) vs. QuaLiKiz input')\n",
    "plt.xlabel('QuaLiKiz')\n",
    "plt.ylabel('NN Predictions - QuaLiKiz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_deNormalized_np_array, predictions_global_deNormalized - y_test_deNormalized_np_array, 'b.', ms = 0.1, alpha=0.5)\n",
    "plt.title('Neural Network predictions vs. QuaLiKiz input (De-Normalized)')\n",
    "plt.xlabel('QuaLiKiz')\n",
    "plt.ylabel('NN Predictions - QuaLiKiz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions (single Data Slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions - Initialise table to feed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table (Original values from input file unstable_training_gen2_7D_nions0_flat_filter7.h5)\n",
    "# Hard-coded variables for the data slice\n",
    "\n",
    "table = numpy.zeros((200,7))\n",
    "\n",
    "table[:,0] = 5.75    # Ati\n",
    "table[:,1] = numpy.linspace(2,14,200)   # Ate\n",
    "table[:,2] = 3       # An\n",
    "table[:,3] = 3       # qx\n",
    "table[:,4] = 0.7     # smag\n",
    "table[:,5] = 0.45    # x\n",
    "table[:,6] = 1.33    # Ti_Te\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized table (inputs for model.predict())\n",
    "table_normalized = numpy.zeros((200,7))\n",
    "\n",
    "DataSlice_Ati = 5.75\n",
    "DataSlice_Ate = numpy.linspace(2,14,200)\n",
    "DataSlice_An = 3\n",
    "DataSlice_q = 3\n",
    "DataSlice_smag = 0.7\n",
    "DataSlice_x = 0.45\n",
    "DataSlice_Ti_Te = 1.33\n",
    "\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "table_normalized[:,0] = (DataSlice_Ati - joined_dataFrame_original['Ati'].mean()) / joined_dataFrame_original['Ati'].std()\n",
    "table_normalized[:,1] = (DataSlice_Ate - joined_dataFrame_original['Ate'].mean()) / joined_dataFrame_original['Ate'].std()\n",
    "table_normalized[:,2] = (DataSlice_An - joined_dataFrame_original['An'].mean()) / joined_dataFrame_original['An'].std()\n",
    "table_normalized[:,3] = (DataSlice_q - joined_dataFrame_original['q'].mean()) / joined_dataFrame_original['q'].std()\n",
    "table_normalized[:,4] = (DataSlice_smag - joined_dataFrame_original['smag'].mean()) / joined_dataFrame_original['smag'].std()\n",
    "table_normalized[:,5] = (DataSlice_x - joined_dataFrame_original['x'].mean()) / joined_dataFrame_original['x'].std()\n",
    "table_normalized[:,6] = (DataSlice_Ti_Te - joined_dataFrame_original['Ti_Te'].mean()) / joined_dataFrame_original['Ti_Te'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized table (inputs for model.predict())\n",
    "table_branch1_normalized = numpy.zeros((200,6))\n",
    "\n",
    "DataSlice_Ati = 5.75\n",
    "#DataSlice_Ate = numpy.linspace(2,14,200)\n",
    "DataSlice_An = 3\n",
    "DataSlice_q = 3\n",
    "DataSlice_smag = 0.7\n",
    "DataSlice_x = 0.45\n",
    "DataSlice_Ti_Te = 1.33\n",
    "\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "table_branch1_normalized[:,0] = (DataSlice_Ati - joined_dataFrame_original['Ati'].mean()) / joined_dataFrame_original['Ati'].std()\n",
    "#table_normalized[:,1] = (DataSlice_Ate - joined_dataFrame_original['Ate'].mean()) / joined_dataFrame_original['Ate'].std()\n",
    "table_branch1_normalized[:,1] = (DataSlice_An - joined_dataFrame_original['An'].mean()) / joined_dataFrame_original['An'].std()\n",
    "table_branch1_normalized[:,2] = (DataSlice_q - joined_dataFrame_original['q'].mean()) / joined_dataFrame_original['q'].std()\n",
    "table_branch1_normalized[:,3] = (DataSlice_smag - joined_dataFrame_original['smag'].mean()) / joined_dataFrame_original['smag'].std()\n",
    "table_branch1_normalized[:,4] = (DataSlice_x - joined_dataFrame_original['x'].mean()) / joined_dataFrame_original['x'].std()\n",
    "table_branch1_normalized[:,5] = (DataSlice_Ti_Te - joined_dataFrame_original['Ti_Te'].mean()) / joined_dataFrame_original['Ti_Te'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized table (inputs for model.predict())\n",
    "table_branch2_normalized = numpy.zeros((200,1))\n",
    "\n",
    "DataSlice_Ate = numpy.linspace(2,14,200)\n",
    "\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "table_branch2_normalized[:,0] = (DataSlice_Ate - joined_dataFrame_original['Ate'].mean()) / joined_dataFrame_original['Ate'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict([table_branch1_normalized] + [table_branch2_normalized], batch_size = 10, verbose=0)\n",
    "print(type(predictions))\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "print(predictions.shape)\n",
    "print(type(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are used to rapidly select which parameters to look at (for a given data slice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ate_mask1 = joined_dataFrame_original.Ate == 2\n",
    "Ate_mask2 = joined_dataFrame_original.Ate == 2.75\n",
    "Ate_mask3 = joined_dataFrame_original.Ate == 3.5\n",
    "Ate_mask4 = joined_dataFrame_original.Ate == 4.25\n",
    "Ate_mask5 = joined_dataFrame_original.Ate == 5\n",
    "Ate_mask6 = joined_dataFrame_original.Ate == 5.75\n",
    "Ate_mask7 = joined_dataFrame_original.Ate == 6.5\n",
    "Ate_mask8 = joined_dataFrame_original.Ate == 7.25\n",
    "Ate_mask9 = joined_dataFrame_original.Ate == 8\n",
    "Ate_mask10 = joined_dataFrame_original.Ate == 10\n",
    "Ate_mask11 = joined_dataFrame_original.Ate == 14\n",
    "\n",
    "Ate_anti_mask1 = joined_dataFrame_original.Ate != 2\n",
    "Ate_anti_mask2 = joined_dataFrame_original.Ate != 2.75\n",
    "Ate_anti_mask3 = joined_dataFrame_original.Ate != 3.5\n",
    "Ate_anti_mask4 = joined_dataFrame_original.Ate != 4.25\n",
    "Ate_anti_mask5 = joined_dataFrame_original.Ate != 5\n",
    "Ate_anti_mask6 = joined_dataFrame_original.Ate != 5.75\n",
    "Ate_anti_mask7 = joined_dataFrame_original.Ate != 6.5\n",
    "Ate_anti_mask8 = joined_dataFrame_original.Ate != 7.25\n",
    "Ate_anti_mask9 = joined_dataFrame_original.Ate != 8\n",
    "Ate_anti_mask10 = joined_dataFrame_original.Ate != 10\n",
    "Ate_anti_mask11 = joined_dataFrame_original.Ate != 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "An_mask1 = joined_dataFrame_original.An == -5\n",
    "An_mask2 = joined_dataFrame_original.An == -3\n",
    "An_mask3 = joined_dataFrame_original.An == -1\n",
    "An_mask4 = numpy.array(joined_dataFrame_original.An <= 1.1e-14) * numpy.array(joined_dataFrame_original.An >= 9E-15)\n",
    "An_mask5 = joined_dataFrame_original.An == 0.5\n",
    "An_mask6 = joined_dataFrame_original.An == 1.0\n",
    "An_mask7 = joined_dataFrame_original.An == 1.5\n",
    "An_mask8 = joined_dataFrame_original.An == 2.0\n",
    "An_mask9 = joined_dataFrame_original.An == 2.5\n",
    "An_mask10 = joined_dataFrame_original.An == 3.0\n",
    "An_mask11 = joined_dataFrame_original.An == 4.0\n",
    "An_mask12 = joined_dataFrame_original.An == 6.0\n",
    "\n",
    "An_anti_mask1 = joined_dataFrame_original.An != -5\n",
    "An_anti_mask2 = joined_dataFrame_original.An != -3\n",
    "An_anti_mask3 = joined_dataFrame_original.An != -1\n",
    "An_anti_mask4 = numpy.array(joined_dataFrame_original.An >= 1.1e-14) * numpy.array(joined_dataFrame_original.An <= 9E-15)\n",
    "An_anti_mask5 = joined_dataFrame_original.An != 0.5\n",
    "An_anti_mask6 = joined_dataFrame_original.An != 1.0\n",
    "An_anti_mask7 = joined_dataFrame_original.An != 1.5\n",
    "An_anti_mask8 = joined_dataFrame_original.An != 2.0\n",
    "An_anti_mask9 = joined_dataFrame_original.An != 2.5\n",
    "An_anti_mask10 = joined_dataFrame_original.An != 3.0\n",
    "An_anti_mask11 = joined_dataFrame_original.An != 4.0\n",
    "An_anti_mask12 = joined_dataFrame_original.An != 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ati_mask1 = numpy.array(joined_dataFrame_original.Ati <= 1.1e-14) * numpy.array(joined_dataFrame_original.Ati >= 9E-15)\n",
    "Ati_mask2 = joined_dataFrame_original.Ati == 2\n",
    "Ati_mask3 = joined_dataFrame_original.Ati == 2.75\n",
    "Ati_mask4 = joined_dataFrame_original.Ati == 3.5\n",
    "Ati_mask5 = joined_dataFrame_original.Ati == 4.25\n",
    "Ati_mask6 = joined_dataFrame_original.Ati == 5\n",
    "Ati_mask7 = joined_dataFrame_original.Ati == 5.75\n",
    "Ati_mask8 = joined_dataFrame_original.Ati == 6.5\n",
    "Ati_mask9 = joined_dataFrame_original.Ati == 7.25\n",
    "Ati_mask10 = joined_dataFrame_original.Ati == 8\n",
    "Ati_mask11 = joined_dataFrame_original.Ati == 10\n",
    "Ati_mask12 = joined_dataFrame_original.Ati == 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_mask0 = numpy.array(joined_dataFrame_original.q <= 0.67) * numpy.array(joined_dataFrame_original.q >= 0.65)  #0.66\n",
    "q_mask1 = joined_dataFrame_original.q == 1.0\n",
    "q_mask2 = joined_dataFrame_original.q == 1.5\n",
    "q_mask3 = joined_dataFrame_original.q == 2.0\n",
    "q_mask4 = joined_dataFrame_original.q == 2.5\n",
    "q_mask5 = joined_dataFrame_original.q == 3.0\n",
    "q_mask6 = joined_dataFrame_original.q == 4.0\n",
    "q_mask7 = joined_dataFrame_original.q == 5.0\n",
    "q_mask8 = joined_dataFrame_original.q == 10.00\n",
    "q_mask9 = joined_dataFrame_original.q == 15.00\n",
    "\n",
    "q_anti_mask0 = numpy.array(joined_dataFrame_original.q >= 0.67) * numpy.array(joined_dataFrame_original.q <= 0.65)  #0.66\n",
    "q_anti_mask1 = joined_dataFrame_original.q != 1.0\n",
    "q_anti_mask2 = joined_dataFrame_original.q != 1.5\n",
    "q_anti_mask3 = joined_dataFrame_original.q != 2.0\n",
    "q_anti_mask4 = joined_dataFrame_original.q != 2.5\n",
    "q_anti_mask5 = joined_dataFrame_original.q != 3.0\n",
    "q_anti_mask6 = joined_dataFrame_original.q != 4.0\n",
    "q_anti_mask7 = joined_dataFrame_original.q != 5.0\n",
    "q_anti_mask8 = joined_dataFrame_original.q != 10.00\n",
    "q_anti_mask9 = joined_dataFrame_original.q != 15.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### smag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smag_mask1 = joined_dataFrame_original.smag == -1.0\n",
    "smag_mask2 = numpy.array(joined_dataFrame_original.smag <= 0.11) * numpy.array(joined_dataFrame_original.smag >= 0.09)   # 0.1\n",
    "smag_mask3 = numpy.array(joined_dataFrame_original.smag <= 0.41) * numpy.array(joined_dataFrame_original.smag >= 0.39)   # 0.4\n",
    "smag_mask4 = numpy.array(joined_dataFrame_original.smag <= 0.71) * numpy.array(joined_dataFrame_original.smag >= 0.68)   # 0.7\n",
    "smag_mask5 = joined_dataFrame_original.smag == 1\n",
    "smag_mask6 = joined_dataFrame_original.smag == 1.5\n",
    "smag_mask7 = joined_dataFrame_original.smag == 2.0\n",
    "smag_mask8 = joined_dataFrame_original.smag == 2.75\n",
    "smag_mask9 = joined_dataFrame_original.smag == 3.5\n",
    "smag_mask10 = joined_dataFrame_original.smag == 5.0\n",
    "\n",
    "smag_anti_mask1 = joined_dataFrame_original.smag != -1.0\n",
    "smag_anti_mask2 = numpy.array(joined_dataFrame_original.smag >= 0.11) * numpy.array(joined_dataFrame_original.smag <= 0.09)   # 0.1\n",
    "smag_anti_mask3 = numpy.array(joined_dataFrame_original.smag >= 0.41) * numpy.array(joined_dataFrame_original.smag <= 0.39)   # 0.4\n",
    "smag_anti_mask4 = numpy.array(joined_dataFrame_original.smag >= 0.71) * numpy.array(joined_dataFrame_original.smag <= 0.68)   # 0.7\n",
    "smag_anti_mask5 = joined_dataFrame_original.smag != 1\n",
    "smag_anti_mask6 = joined_dataFrame_original.smag != 1.5\n",
    "smag_anti_mask7 = joined_dataFrame_original.smag != 2.0\n",
    "smag_anti_mask8 = joined_dataFrame_original.smag != 2.75\n",
    "smag_anti_mask9 = joined_dataFrame_original.smag != 3.5\n",
    "smag_anti_mask10 = joined_dataFrame_original.smag != 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask1 = numpy.array(joined_dataFrame_original.x <= 0.10) * numpy.array(joined_dataFrame_original.x >= 0.08)   # 0.09\n",
    "x_mask2 = numpy.array(joined_dataFrame_original.x <= 0.22) * numpy.array(joined_dataFrame_original.x >= 0.20)   # 0.21\n",
    "x_mask3 = numpy.array(joined_dataFrame_original.x <= 0.34) * numpy.array(joined_dataFrame_original.x >= 0.32)   # 0.33\n",
    "x_mask4 = numpy.array(joined_dataFrame_original.x <= 0.46) * numpy.array(joined_dataFrame_original.x >= 0.44)   # 0.45\n",
    "x_mask5 = numpy.array(joined_dataFrame_original.x <= 0.58) * numpy.array(joined_dataFrame_original.x >= 0.56)   # 0.57\n",
    "x_mask6 = numpy.array(joined_dataFrame_original.x <= 0.70) * numpy.array(joined_dataFrame_original.x >= 0.68)   # 0.69\n",
    "x_mask7 = numpy.array(joined_dataFrame_original.x <= 0.85) * numpy.array(joined_dataFrame_original.x >= 0.83)   # 0.84\n",
    "x_mask8 = numpy.array(joined_dataFrame_original.x <= 1.00) * numpy.array(joined_dataFrame_original.x >= 0.98)   # 0.99\n",
    "x_mask = {0.09: x_mask1}\n",
    "\n",
    "x_anti_mask1 = numpy.array(joined_dataFrame_original.x >= 0.10) * numpy.array(joined_dataFrame_original.x <= 0.08)   # 0.09\n",
    "x_anti_mask2 = numpy.array(joined_dataFrame_original.x >= 0.22) * numpy.array(joined_dataFrame_original.x <= 0.20)   # 0.21\n",
    "x_anti_mask3 = numpy.array(joined_dataFrame_original.x >= 0.34) * numpy.array(joined_dataFrame_original.x <= 0.32)   # 0.33\n",
    "x_anti_mask4 = numpy.array(joined_dataFrame_original.x >= 0.46) * numpy.array(joined_dataFrame_original.x <= 0.44)   # 0.45\n",
    "x_anti_mask5 = numpy.array(joined_dataFrame_original.x >= 0.58) * numpy.array(joined_dataFrame_original.x <= 0.56)   # 0.57\n",
    "x_anti_mask6 = numpy.array(joined_dataFrame_original.x >= 0.70) * numpy.array(joined_dataFrame_original.x <= 0.68)   # 0.69\n",
    "x_anti_mask7 = numpy.array(joined_dataFrame_original.x >= 0.85) * numpy.array(joined_dataFrame_original.x <= 0.83)   # 0.84\n",
    "x_anti_mask8 = numpy.array(joined_dataFrame_original.x >= 1.00) * numpy.array(joined_dataFrame_original.x <= 0.98)   # 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ti_Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ti_Te_mask1 = joined_dataFrame_original.Ti_Te == 0.25\n",
    "Ti_Te_mask2 = joined_dataFrame_original.Ti_Te == 0.5\n",
    "Ti_Te_mask3 = joined_dataFrame_original.Ti_Te == 0.75\n",
    "Ti_Te_mask4 = joined_dataFrame_original.Ti_Te == 1\n",
    "Ti_Te_mask5 = numpy.array(joined_dataFrame_original.Ti_Te <= 1.34) * numpy.array(joined_dataFrame_original.Ti_Te >= 1.32)   # 1.33\n",
    "Ti_Te_mask6 = numpy.array(joined_dataFrame_original.Ti_Te <= 1.67) * numpy.array(joined_dataFrame_original.Ti_Te >= 1.65)   # 1.66\n",
    "Ti_Te_mask7 = joined_dataFrame_original.Ti_Te == 2.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'An': 3,\n",
    "'Ati': 5.75,\n",
    "'Ti_Te': 1.33,\n",
    "'q': 3,\n",
    "'smag': 0.7,\n",
    "'x': 0.45}\n",
    "'''\n",
    "newDF = joined_dataFrame[An_mask10 & Ati_mask7 & q_mask5 & smag_mask4 & x_mask4 & Ti_Te_mask5]  # Variable \n",
    "newDF_Mk2 = joined_dataFrame_original[An_mask10 & Ati_mask7 & q_mask5 & smag_mask4 & x_mask4 & Ti_Te_mask5]  # Variable \n",
    "print(newDF)\n",
    "print(type(newDF))\n",
    "\n",
    "print(newDF_Mk2)\n",
    "print(type(newDF_Mk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efeETG_DF = newDF['efeETG_GB']\n",
    "efeETG_DF_np_array = efeETG_DF.values\n",
    "print(efeETG_DF_np_array)\n",
    "\n",
    "Ate_DF = newDF['Ate']\n",
    "Ate_DF_np_array = Ate_DF.values\n",
    "print(Ate_DF_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efeETG_DF_Mk2 = newDF_Mk2['efeETG_GB']\n",
    "efeETG_DF_Mk2_np_array = efeETG_DF_Mk2.values\n",
    "print(efeETG_DF_Mk2_np_array)\n",
    "\n",
    "Ate_DF_Mk2 = newDF_Mk2['Ate']\n",
    "Ate_DF_Mk2_np_array = Ate_DF_Mk2.values\n",
    "print(Ate_DF_Mk2_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efeETG_DF = newDF['efeETG_GB']\n",
    "Ate_DF = newDF['Ate']\n",
    "plt.plot(table_normalized[:,1], predictions, 'r.', ms = 5, label = 'QuaLiKiz-NN')\n",
    "plt.plot(Ate_DF_np_array, efeETG_DF_np_array, 'b.', ms = 5, label = 'QuaLiKiz')\n",
    "plt.title('Data Slice NN vs. QuaLiKiz (Non-Normalized)')\n",
    "plt.xlabel('Ate')\n",
    "plt.ylabel('efeETG_GB')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_deNormalized = (predictions * joined_dataFrame_original['efeETG_GB'].std()) + joined_dataFrame_original['efeETG_GB'].mean()\n",
    "print(predictions_deNormalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(table[:,1], predictions_deNormalized, 'r-', ms = 5, label = 'QuaLiKiz-NN')\n",
    "plt.plot(Ate_DF_Mk2_np_array, efeETG_DF_Mk2_np_array, 'b.', ms = 5, label = 'QuaLiKiz')\n",
    "plt.title('Data Slice NN vs. QuaLiKiz (De-Normalized)')\n",
    "plt.ylim(-15, 110)\n",
    "plt.xlabel('Ate')\n",
    "plt.ylabel('efeETG_GB')\n",
    "plt.legend()\n",
    "# plt.savefig('./2018-07-19_Plotting-Clean-Run0054/NN_Predictions.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
