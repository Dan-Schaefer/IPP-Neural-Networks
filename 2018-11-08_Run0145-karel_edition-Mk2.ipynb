{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run0145\n",
    "\n",
    "\n",
    "Replaced\n",
    "\n",
    "```power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.0, 10)) ** (K.clip(K.abs(x[1]), 0.0, 2.0)))```\n",
    "\n",
    "with\n",
    "\n",
    "```power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 0.0, 10)) ** (K.clip(K.abs(x[1]), 1.0, 2.0)))```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Gets the current file name. Useful for procedurally generating output/log files.\n",
    "file_name =  os.path.basename(sys.argv[0][:-3])\n",
    "print(file_name)\n",
    "\n",
    "if file_name == \"ipykernel_launcher\":\n",
    "    print(\"This is the Jupyter version.\")\n",
    "    print(\"Now MANUALLY run the next two cells!\")\n",
    "    print(\"STOP! This should not be in your code!!\")\n",
    "    exit(0)\n",
    "    time.sleep(10)\n",
    "    print(\"Testing if script has really stopped.\")\n",
    "else:\n",
    "    print(\"This is the Atom version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IN JUPYTER!!\n",
    "# Start here (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('file_name = \"' + IPython.notebook.notebook_name + '\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-08_Run0145-karel_edition-Mk2.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-08_Run0145-karel_edition-Mk2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "file_name = file_name[:-6]\n",
    "print(file_name)\n",
    "\n",
    "is_Jupyter = True\n",
    "print(is_Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code for both ATOM & JUPYTER from now (Run all cells below now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Late Fusion Module (test) - Functional API\n",
    "'''\n",
    "\n",
    "# Multiple Inputs\n",
    "import keras\n",
    "from keras.optimizers import RMSprop, adam, Adam\n",
    "from keras.initializers import TruncatedNormal, glorot_normal, Constant\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxoutDense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "#from keras.backend import switch\n",
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "\n",
    "#keras.backend.clear_session()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new Metric: rmse = Root Mean Square Error\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square( y_true-y_pred )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify for ATOM use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_Jupyter == True:\n",
    "    pass\n",
    "else:\n",
    "    # Gets the current file name. Useful for procedurally generating output/log files.\n",
    "    file_name =  os.path.basename(sys.argv[0][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network parameters\n",
    "batch_size = 10\n",
    "#num_classes = 1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (which is in HDF5 or .h5 format)\n",
    "store = pandas.HDFStore(\"training_gen3_7D_nions0_flat_filter8.h5\")\n",
    "target_df = store['/output/efeETG_GB'].to_frame()  # This one is relatively easy to train\n",
    "input_df = store['input']\n",
    "\n",
    "# Puts inputs and outputs in the same pandas dataframe.\n",
    "# Also only keeps overlapping entries.\n",
    "joined_dataFrame = target_df.join(input_df)\n",
    "\n",
    "# Make a copy of joined_dataFrame for later use\n",
    "joined_dataFrame_original = deepcopy(joined_dataFrame)\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Normalize data by standard deviation and mean-centering the data\n",
    "# Standard configuration\n",
    "joined_dataFrame['efeETG_GB'] = (joined_dataFrame['efeETG_GB'] - joined_dataFrame['efeETG_GB'].mean()) / joined_dataFrame['efeETG_GB'].std()\n",
    "joined_dataFrame['Ati'] = (joined_dataFrame['Ati'] - joined_dataFrame['Ati'].mean()) / joined_dataFrame['Ati'].std()\n",
    "joined_dataFrame['Ate'] = (joined_dataFrame['Ate'] - joined_dataFrame['Ate'].mean()) / joined_dataFrame['Ate'].std()\n",
    "joined_dataFrame['An'] = (joined_dataFrame['An'] - joined_dataFrame['An'].mean()) / joined_dataFrame['An'].std()\n",
    "joined_dataFrame['q'] = (joined_dataFrame['q'] - joined_dataFrame['q'].mean()) / joined_dataFrame['q'].std()\n",
    "joined_dataFrame['smag'] = (joined_dataFrame['smag'] - joined_dataFrame['smag'].mean()) / joined_dataFrame['smag'].std()\n",
    "joined_dataFrame['x'] = (joined_dataFrame['x'] - joined_dataFrame['x'].mean()) / joined_dataFrame['x'].std()\n",
    "joined_dataFrame['Ti_Te'] = (joined_dataFrame['Ti_Te'] - joined_dataFrame['Ti_Te'].mean()) / joined_dataFrame['Ti_Te'].std()\n",
    "\n",
    "# Shuffles dataset\n",
    "shuffled_joined_dataFrame = joined_dataFrame.reindex(numpy.random.permutation(\n",
    "                                                joined_dataFrame.index))\n",
    "\n",
    "# Creates a pandas dataframe for the outputs\n",
    "shuffled_clean_output_df = shuffled_joined_dataFrame['efeETG_GB']\n",
    "\n",
    "# Make a copy of shuffled_joined_dataFrame for later use\n",
    "shuffled_joined_dataFrame_base = deepcopy(shuffled_joined_dataFrame)\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************** #\n",
    "# Creates a pandas dataframe for the inputs (7D)\n",
    "shuffled_clean_input_df_7D = shuffled_joined_dataFrame.drop('efeETG_GB', axis=1)\n",
    "\n",
    "# Creates training dataset (90% of total data) for outputs\n",
    "y_train = shuffled_clean_output_df.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9))]\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train = shuffled_clean_input_df_7D.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for outputs\n",
    "y_test = shuffled_clean_output_df.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_output_df)*0.9)):]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test = shuffled_clean_input_df_7D.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_7D)*0.9)):]\n",
    "# *************************************************************************** #\n",
    "\n",
    "\n",
    "# Deletes pandas dataframes that are no longer needed\n",
    "del target_df, input_df\n",
    "\n",
    "# Closes the HDFStore. This is good practice.\n",
    "store.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>Ate</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.411120e-16</td>\n",
       "      <td>2.631464e-16</td>\n",
       "      <td>2.260397e-16</td>\n",
       "      <td>8.714520e-17</td>\n",
       "      <td>-1.731850e-17</td>\n",
       "      <td>-2.588124e-19</td>\n",
       "      <td>5.159578e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632300e+00</td>\n",
       "      <td>-1.639065e+00</td>\n",
       "      <td>-1.901001e+00</td>\n",
       "      <td>-8.370116e-01</td>\n",
       "      <td>-1.574307e+00</td>\n",
       "      <td>-1.405340e+00</td>\n",
       "      <td>-1.235044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.928000e-01</td>\n",
       "      <td>-7.898708e-01</td>\n",
       "      <td>-5.438138e-01</td>\n",
       "      <td>-6.367600e-01</td>\n",
       "      <td>-8.011463e-01</td>\n",
       "      <td>-9.907529e-01</td>\n",
       "      <td>-8.817246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.059360e-01</td>\n",
       "      <td>-9.507533e-02</td>\n",
       "      <td>1.347799e-01</td>\n",
       "      <td>-3.983652e-01</td>\n",
       "      <td>-1.936629e-01</td>\n",
       "      <td>-1.615792e-01</td>\n",
       "      <td>-1.750863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.809279e-01</td>\n",
       "      <td>5.997202e-01</td>\n",
       "      <td>6.437252e-01</td>\n",
       "      <td>1.976217e-01</td>\n",
       "      <td>9.108525e-01</td>\n",
       "      <td>6.675945e-01</td>\n",
       "      <td>7.576761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.641520e+00</td>\n",
       "      <td>2.684107e+00</td>\n",
       "      <td>1.831264e+00</td>\n",
       "      <td>2.581570e+00</td>\n",
       "      <td>1.739239e+00</td>\n",
       "      <td>1.704062e+00</td>\n",
       "      <td>1.944828e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati           Ate            An             q          smag  \\\n",
       "count  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06   \n",
       "mean  -1.411120e-16  2.631464e-16  2.260397e-16  8.714520e-17 -1.731850e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.632300e+00 -1.639065e+00 -1.901001e+00 -8.370116e-01 -1.574307e+00   \n",
       "25%   -7.928000e-01 -7.898708e-01 -5.438138e-01 -6.367600e-01 -8.011463e-01   \n",
       "50%   -1.059360e-01 -9.507533e-02  1.347799e-01 -3.983652e-01 -1.936629e-01   \n",
       "75%    5.809279e-01  5.997202e-01  6.437252e-01  1.976217e-01  9.108525e-01   \n",
       "max    2.641520e+00  2.684107e+00  1.831264e+00  2.581570e+00  1.739239e+00   \n",
       "\n",
       "                  x         Ti_Te  \n",
       "count  6.479137e+06  6.479137e+06  \n",
       "mean  -2.588124e-19  5.159578e-17  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -1.405340e+00 -1.235044e+00  \n",
       "25%   -9.907529e-01 -8.817246e-01  \n",
       "50%   -1.615792e-01 -1.750863e-01  \n",
       "75%    6.675945e-01  7.576761e-01  \n",
       "max    1.704062e+00  1.944828e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_7D.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe for the inputs\n",
    "shuffled_clean_input_df_1 = shuffled_clean_input_df_7D.drop('Ate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ati</th>\n",
       "      <th>An</th>\n",
       "      <th>q</th>\n",
       "      <th>smag</th>\n",
       "      <th>x</th>\n",
       "      <th>Ti_Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.411120e-16</td>\n",
       "      <td>2.260397e-16</td>\n",
       "      <td>8.714520e-17</td>\n",
       "      <td>-1.731850e-17</td>\n",
       "      <td>-2.588124e-19</td>\n",
       "      <td>5.159578e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632300e+00</td>\n",
       "      <td>-1.901001e+00</td>\n",
       "      <td>-8.370116e-01</td>\n",
       "      <td>-1.574307e+00</td>\n",
       "      <td>-1.405340e+00</td>\n",
       "      <td>-1.235044e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.928000e-01</td>\n",
       "      <td>-5.438138e-01</td>\n",
       "      <td>-6.367600e-01</td>\n",
       "      <td>-8.011463e-01</td>\n",
       "      <td>-9.907529e-01</td>\n",
       "      <td>-8.817246e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.059360e-01</td>\n",
       "      <td>1.347799e-01</td>\n",
       "      <td>-3.983652e-01</td>\n",
       "      <td>-1.936629e-01</td>\n",
       "      <td>-1.615792e-01</td>\n",
       "      <td>-1.750863e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.809279e-01</td>\n",
       "      <td>6.437252e-01</td>\n",
       "      <td>1.976217e-01</td>\n",
       "      <td>9.108525e-01</td>\n",
       "      <td>6.675945e-01</td>\n",
       "      <td>7.576761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.641520e+00</td>\n",
       "      <td>1.831264e+00</td>\n",
       "      <td>2.581570e+00</td>\n",
       "      <td>1.739239e+00</td>\n",
       "      <td>1.704062e+00</td>\n",
       "      <td>1.944828e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ati            An             q          smag             x  \\\n",
       "count  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06  6.479137e+06   \n",
       "mean  -1.411120e-16  2.260397e-16  8.714520e-17 -1.731850e-17 -2.588124e-19   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.632300e+00 -1.901001e+00 -8.370116e-01 -1.574307e+00 -1.405340e+00   \n",
       "25%   -7.928000e-01 -5.438138e-01 -6.367600e-01 -8.011463e-01 -9.907529e-01   \n",
       "50%   -1.059360e-01  1.347799e-01 -3.983652e-01 -1.936629e-01 -1.615792e-01   \n",
       "75%    5.809279e-01  6.437252e-01  1.976217e-01  9.108525e-01  6.675945e-01   \n",
       "max    2.641520e+00  1.831264e+00  2.581570e+00  1.739239e+00  1.704062e+00   \n",
       "\n",
       "              Ti_Te  \n",
       "count  6.479137e+06  \n",
       "mean   5.159578e-17  \n",
       "std    1.000000e+00  \n",
       "min   -1.235044e+00  \n",
       "25%   -8.817246e-01  \n",
       "50%   -1.750863e-01  \n",
       "75%    7.576761e-01  \n",
       "max    1.944828e+00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 6)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_7D.drop('Ati', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('An', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('q', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('smag', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('x', axis=1)\n",
    "shuffled_clean_input_df_2 = shuffled_clean_input_df_2.drop('Ti_Te', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.479137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.631464e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.639065e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.898708e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.507533e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.997202e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.684107e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ate\n",
       "count  6.479137e+06\n",
       "mean   2.631464e-16\n",
       "std    1.000000e+00\n",
       "min   -1.639065e+00\n",
       "25%   -7.898708e-01\n",
       "50%   -9.507533e-02\n",
       "75%    5.997202e-01\n",
       "max    2.684107e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_clean_input_df_2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6479137, 1)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_clean_input_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 1\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_1 = shuffled_clean_input_df_1.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_1 = shuffled_clean_input_df_1.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_1)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************** #\n",
    "# Branch 2\n",
    "\n",
    "# Creates training dataset (90% of total data) for inputs\n",
    "x_train_2 = shuffled_clean_input_df_2.iloc[:int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9))]\n",
    "\n",
    "# Creates testing dataset (10% of total data) for inputs\n",
    "x_test_2 = shuffled_clean_input_df_2.iloc[int(\n",
    "    numpy.round(len(shuffled_clean_input_df_2)*0.9)):]\n",
    "# *************************************************************************** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[7].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[3].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer(\"c_3_branch3_feeder\").get_weights()[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[14] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[14].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def power_function(x):\n",
    "    #from keras import backend as K\n",
    "    x = model.get_layer(\"c_3_branch3_feeder\").get_weights()[0]\n",
    "    c_3 = K.cast(x, dtype='float32')\n",
    "    if (c_3 >= 0.0):\n",
    "        return c_3\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    return 1.0 ** c_3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def power_function(x):\n",
    "    #from keras import backend as K\n",
    "    x = model.get_layer(\"c_3_branch3_feeder\").get_weights()[0]\n",
    "    c_3 = K.cast(x, dtype='float32')\n",
    "    #if (c_3 >= 0.0):\n",
    "    #    pass\n",
    "    #else:\n",
    "    #    c_3 = 0.0\n",
    "    #\n",
    "    return 1.0 ** c_3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def power_function(x):\n",
    "    print(\"counter = 0\")\n",
    "    print(\"x: \")\n",
    "    print(x)\n",
    "    print(\"type(x): \")\n",
    "    print(type(x))\n",
    "    counter = 1\n",
    "    if (counter == 0):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"counter = 1\")\n",
    "        print(\"x: \")\n",
    "        print(x)\n",
    "        print(\"type(x): \")\n",
    "        print(type(x))\n",
    "        a = K.cast(x, dtype='float32')\n",
    "        print(\"a: \")\n",
    "        print(a)\n",
    "        try:\n",
    "            print(model.layers[14])\n",
    "            c_3 = model.layers[14].get_weights()[0][0][0]\n",
    "            print(c_3)\n",
    "            print(\"type(c_3): \")\n",
    "            print(type(c_3))\n",
    "            if (c_3 >= 0.0):\n",
    "                pass\n",
    "            else:\n",
    "                c_3 = 0.0\n",
    "            pooling = 1.0 ** c_3\n",
    "            power_pooling_output = K.cast(pooling, dtype='float32')\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "    return power_pooling_output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Lambda(lambda x: 1 ** x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "6D_INPUTS (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch1 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch1 (Dense)         (None, 30)           930         hidden1_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1 (Dense)           (None, 1)            31          hidden2_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Ate_INPUT (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1_branch3 (Dense)         (None, 30)           210         6D_INPUTS[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "theta_branch1_feeder (Dense)    (None, 1)            2           theta_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "visible_branch2_feeder (Dense)  (None, 1)            2           Ate_INPUT[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden2_branch3 (Dense)         (None, 30)           930         hidden1_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Addition_Pooling (Add)          (None, 1)            0           theta_branch1_feeder[0][0]       \n",
      "                                                                 visible_branch2_feeder[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3 (Dense)             (None, 1)            31          hidden2_branch3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "TR (Dense)                      (None, 1)            2           Addition_Pooling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "c_3_branch3_feeder (Dense)      (None, 1)            2           c_3_branch3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           TR[0][0]                         \n",
      "                                                                 c_3_branch3_feeder[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer (Dense)            (None, 1)            2           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,352\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# branch1\n",
    "visible_branch1 = Input(shape=(6, ), name=\"6D_INPUTS\")\n",
    "hidden1_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch1\")(visible_branch1)\n",
    "hidden2_branch1 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch1\")(hidden1_branch1)\n",
    "theta_branch1 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"theta_branch1\")(hidden2_branch1)\n",
    "theta_branch1_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=-1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"theta_branch1_feeder\")(theta_branch1)\n",
    "\n",
    "# branch2 (Ate input)\n",
    "visible_branch2 = Input(shape=(1, ), name=\"Ate_INPUT\")\n",
    "visible_branch2_feeder = Dense(1,\n",
    "                activation='linear',\n",
    "                name=\"visible_branch2_feeder\")(visible_branch2)\n",
    "\n",
    "# addition_pooling (effectively subtraction though...)\n",
    "addition_pooling = keras.layers.Add(name=\"Addition_Pooling\")([theta_branch1_feeder, visible_branch2_feeder])\n",
    "\n",
    "TR = Dense(1, activation='relu',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=False,\n",
    "           name=\"TR\")(addition_pooling)\n",
    "\n",
    "# branch 3 (for c_3)\n",
    "hidden1_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch3\")(visible_branch1)\n",
    "hidden2_branch3 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch3\")(hidden1_branch3)\n",
    "c_3_branch3 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"c_3_branch3\")(hidden2_branch3)\n",
    "c_3_branch3_feeder = Dense(1,\n",
    "        kernel_initializer=Constant(value=+1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"c_3_branch3_feeder\")(c_3_branch3)\n",
    "\n",
    "# Power_Pooling\n",
    "#merge = concatenate([TR, c_3_branch3_feeder], name=\"merge\")\n",
    "#power_pooling = Lambda(power_function, name=\"Power_Pooling\")(merge)\n",
    "#power_pooling = Lambda(lambda x: 1 ** x)(c_3_branch3_feeder)\n",
    "def power_lambda(x):\n",
    "    if x[0] <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x[0] ** x[1]\n",
    "power_layer = Lambda(lambda x: (K.clip(K.abs(x[0]), 1e-32, numpy.inf)) ** (K.clip(K.abs(x[1]), -1., 3.)))\n",
    "#power_layer = Lambda(lambda x: K.tf.where(K.tf.less_equal(x[0], 1e-6), K.tf.fill(tf.shape(x[0]), 0.), K.abs(x[0]) ** K.clip(K.abs(x[1]), 0.5, 3.)))\n",
    "#power_layer = Lambda(lambda x: K.tf.where(K.tf.greater(x[0], 1e-6), K.tf.fill(tf.shape(x[0]), 0.), K.tf.fill(tf.shape(x[0]), 1000000000.)))\n",
    "\n",
    "power_pooling = power_layer([TR, c_3_branch3_feeder])\n",
    "\n",
    "\n",
    "# branch 4 (for the gradient)\n",
    "hidden1_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden1_branch4\")(visible_branch1)\n",
    "hidden2_branch4 = Dense(30,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"hidden2_branch4\")(hidden1_branch4)\n",
    "m_branch4 = Dense(1,\n",
    "        activation='tanh',\n",
    "        kernel_initializer='glorot_normal',\n",
    "        kernel_regularizer=regularizers.l2(0.00005),\n",
    "        use_bias=True, bias_initializer='glorot_normal',\n",
    "        name=\"m_branch4\")(hidden2_branch4)\n",
    "m_branch4_feeder = Dense(1,\n",
    "        activation='linear',\n",
    "        kernel_initializer=Constant(value=+1),\n",
    "        bias_initializer='Zeros',\n",
    "        trainable=False,\n",
    "        name=\"m_branch4_feeder\")(m_branch4)\n",
    "\n",
    "# multiplication pooling\n",
    "multiplication_pooling = keras.layers.Multiply(name=\"Multiplication_Pooling\")([m_branch4_feeder, power_pooling])\n",
    "\n",
    "# interpretation model\n",
    "output = Dense(1, activation='linear',\n",
    "           kernel_initializer='Ones',\n",
    "           bias_initializer='Zeros',\n",
    "           trainable=True,\n",
    "           name=\"Output_Layer\")(power_pooling)\n",
    "\n",
    "model = Model(inputs=[visible_branch1, visible_branch2], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph\n",
    "plot_model(model, 'ModelPlots/' + str(file_name) + '_model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed\n",
    "class NBatchLogger(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Logger that log average performance per `display` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.step += 1\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display\n",
    "                if abs(val) > 1e-3:\n",
    "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            if self.params['steps'] is None:\n",
    "                steps_per_epoch = int(numpy.ceil(self.params['samples'] / self.params['batch_size']))\n",
    "            else:\n",
    "                steps = self.params['steps']\n",
    "            #embed()\n",
    "            epoch = int(numpy.floor((self.step - 1)/ steps_per_epoch))\n",
    "            step_in_epoch = self.step - epoch * steps_per_epoch\n",
    "            print('step: {}/{} epoch {}: ... {}'.format(step_in_epoch,\n",
    "                                          steps_per_epoch,\n",
    "                                          epoch,\n",
    "                                          metrics_log))\n",
    "            self.metric_cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5831223 samples, validate on 647914 samples\n",
      "Epoch 1/100\n",
      "step: 50000/583123 epoch 0: ...  - loss: 0.2539 - mean_absolute_error: 0.1478 - mean_squared_error: 0.2496 - rmse: 0.3394\n",
      "step: 100000/583123 epoch 0: ...  - loss: 0.1394 - mean_absolute_error: 0.1007 - mean_squared_error: 0.1333 - rmse: 0.2381\n",
      "step: 150000/583123 epoch 0: ...  - loss: 0.1329 - mean_absolute_error: 0.0969 - mean_squared_error: 0.1260 - rmse: 0.2293\n",
      "step: 200000/583123 epoch 0: ...  - loss: 0.1311 - mean_absolute_error: 0.0953 - mean_squared_error: 0.1235 - rmse: 0.2275\n",
      "step: 250000/583123 epoch 0: ...  - loss: 0.1334 - mean_absolute_error: 0.0945 - mean_squared_error: 0.1252 - rmse: 0.2268\n",
      "step: 300000/583123 epoch 0: ...  - loss: 0.1251 - mean_absolute_error: 0.0930 - mean_squared_error: 0.1167 - rmse: 0.2196\n",
      "step: 350000/583123 epoch 0: ...  - loss: 0.1318 - mean_absolute_error: 0.0946 - mean_squared_error: 0.1230 - rmse: 0.2239\n",
      "step: 400000/583123 epoch 0: ...  - loss: 0.1232 - mean_absolute_error: 0.0913 - mean_squared_error: 0.1141 - rmse: 0.2165\n",
      "step: 450000/583123 epoch 0: ...  - loss: 0.1195 - mean_absolute_error: 0.0916 - mean_squared_error: 0.1102 - rmse: 0.2151\n",
      "step: 500000/583123 epoch 0: ...  - loss: 0.1199 - mean_absolute_error: 0.0911 - mean_squared_error: 0.1103 - rmse: 0.2145\n",
      "step: 550000/583123 epoch 0: ...  - loss: 0.1262 - mean_absolute_error: 0.0937 - mean_squared_error: 0.1162 - rmse: 0.2206\n",
      " - 382s - loss: 0.1384 - mean_absolute_error: 0.0986 - mean_squared_error: 0.1303 - rmse: 0.2325 - val_loss: 0.1220 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.1121 - val_rmse: 0.2186\n",
      "Epoch 2/100\n",
      "step: 16877/583123 epoch 1: ...  - loss: 0.1168 - mean_absolute_error: 0.0899 - mean_squared_error: 0.1068 - rmse: 0.2119\n",
      "step: 66877/583123 epoch 1: ...  - loss: 0.1302 - mean_absolute_error: 0.0924 - mean_squared_error: 0.1204 - rmse: 0.2221\n",
      "step: 116877/583123 epoch 1: ...  - loss: 0.1200 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1107 - rmse: 0.2141\n",
      "step: 166877/583123 epoch 1: ...  - loss: 0.1351 - mean_absolute_error: 0.0952 - mean_squared_error: 0.1253 - rmse: 0.2259\n",
      "step: 216877/583123 epoch 1: ...  - loss: 0.1279 - mean_absolute_error: 0.0933 - mean_squared_error: 0.1177 - rmse: 0.2193\n",
      "step: 266877/583123 epoch 1: ...  - loss: 0.1388 - mean_absolute_error: 0.0977 - mean_squared_error: 0.1279 - rmse: 0.2307\n",
      "step: 316877/583123 epoch 1: ...  - loss: 0.1169 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1061 - rmse: 0.2105\n",
      "step: 366877/583123 epoch 1: ...  - loss: 0.1283 - mean_absolute_error: 0.0920 - mean_squared_error: 0.1172 - rmse: 0.2192\n",
      "step: 416877/583123 epoch 1: ...  - loss: 0.1448 - mean_absolute_error: 0.1003 - mean_squared_error: 0.1340 - rmse: 0.2346\n",
      "step: 466877/583123 epoch 1: ...  - loss: 0.1543 - mean_absolute_error: 0.0999 - mean_squared_error: 0.1431 - rmse: 0.2423\n",
      "step: 516877/583123 epoch 1: ...  - loss: 0.1183 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1084 - rmse: 0.2119\n",
      "step: 566877/583123 epoch 1: ...  - loss: 0.1197 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1095 - rmse: 0.2125\n",
      " - 384s - loss: 0.1297 - mean_absolute_error: 0.0934 - mean_squared_error: 0.1193 - rmse: 0.2215 - val_loss: 0.1045 - val_mean_absolute_error: 0.0841 - val_mean_squared_error: 0.0940 - val_rmse: 0.1979\n",
      "Epoch 3/100\n",
      "step: 33754/583123 epoch 2: ...  - loss: 0.1212 - mean_absolute_error: 0.0910 - mean_squared_error: 0.1105 - rmse: 0.2135\n",
      "step: 83754/583123 epoch 2: ...  - loss: 0.1211 - mean_absolute_error: 0.0911 - mean_squared_error: 0.1103 - rmse: 0.2145\n",
      "step: 133754/583123 epoch 2: ...  - loss: 0.1159 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1051 - rmse: 0.2093\n",
      "step: 183754/583123 epoch 2: ...  - loss: 0.1135 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1027 - rmse: 0.2071\n",
      "step: 233754/583123 epoch 2: ...  - loss: 0.1334 - mean_absolute_error: 0.0941 - mean_squared_error: 0.1221 - rmse: 0.2225\n",
      "step: 283754/583123 epoch 2: ...  - loss: 0.1134 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1026 - rmse: 0.2072\n",
      "step: 333754/583123 epoch 2: ...  - loss: 0.1222 - mean_absolute_error: 0.0924 - mean_squared_error: 0.1113 - rmse: 0.2154\n",
      "step: 383754/583123 epoch 2: ...  - loss: 0.1288 - mean_absolute_error: 0.0912 - mean_squared_error: 0.1183 - rmse: 0.2193\n",
      "step: 433754/583123 epoch 2: ...  - loss: 0.1176 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1075 - rmse: 0.2111\n",
      "step: 483754/583123 epoch 2: ...  - loss: 0.1736 - mean_absolute_error: 0.1038 - mean_squared_error: 0.1616 - rmse: 0.2528\n",
      "step: 533754/583123 epoch 2: ...  - loss: 0.1391 - mean_absolute_error: 0.0912 - mean_squared_error: 0.1250 - rmse: 0.2240\n",
      " - 385s - loss: 0.1302 - mean_absolute_error: 0.0922 - mean_squared_error: 0.1185 - rmse: 0.2197 - val_loss: 0.1441 - val_mean_absolute_error: 0.0920 - val_mean_squared_error: 0.1253 - val_rmse: 0.2225\n",
      "Epoch 4/100\n",
      "step: 631/583123 epoch 3: ...  - loss: 0.1592 - mean_absolute_error: 0.0981 - mean_squared_error: 0.1419 - rmse: 0.2371\n",
      "step: 50631/583123 epoch 3: ...  - loss: 0.1469 - mean_absolute_error: 0.0927 - mean_squared_error: 0.1299 - rmse: 0.2273\n",
      "step: 100631/583123 epoch 3: ...  - loss: 0.1189 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1089 - rmse: 0.2121\n",
      "step: 150631/583123 epoch 3: ...  - loss: 0.1148 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1049 - rmse: 0.2078\n",
      "step: 200631/583123 epoch 3: ...  - loss: 0.1148 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1048 - rmse: 0.2089\n",
      "step: 250631/583123 epoch 3: ...  - loss: 0.1158 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1057 - rmse: 0.2091\n",
      "step: 300631/583123 epoch 3: ...  - loss: 0.1155 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1054 - rmse: 0.2099\n",
      "step: 350631/583123 epoch 3: ...  - loss: 0.1168 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1067 - rmse: 0.2105\n",
      "step: 400631/583123 epoch 3: ...  - loss: 0.1136 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1034 - rmse: 0.2082\n",
      "step: 450631/583123 epoch 3: ...  - loss: 0.1133 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1030 - rmse: 0.2076\n",
      "step: 500631/583123 epoch 3: ...  - loss: 0.1566 - mean_absolute_error: 0.1015 - mean_squared_error: 0.1458 - rmse: 0.2410\n",
      "step: 550631/583123 epoch 3: ...  - loss: 0.1159 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1053 - rmse: 0.2090\n",
      " - 383s - loss: 0.1242 - mean_absolute_error: 0.0906 - mean_squared_error: 0.1133 - rmse: 0.2154 - val_loss: 0.1321 - val_mean_absolute_error: 0.1083 - val_mean_squared_error: 0.1219 - val_rmse: 0.2462\n",
      "Epoch 5/100\n",
      "step: 17508/583123 epoch 4: ...  - loss: 0.1427 - mean_absolute_error: 0.0946 - mean_squared_error: 0.1319 - rmse: 0.2293\n",
      "step: 67508/583123 epoch 4: ...  - loss: 0.1157 - mean_absolute_error: 0.0895 - mean_squared_error: 0.1053 - rmse: 0.2100\n",
      "step: 117508/583123 epoch 4: ...  - loss: 0.1135 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1028 - rmse: 0.2070\n",
      "step: 167508/583123 epoch 4: ...  - loss: 0.1139 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1030 - rmse: 0.2075\n",
      "step: 217508/583123 epoch 4: ...  - loss: 0.1127 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1018 - rmse: 0.2060\n",
      "step: 267508/583123 epoch 4: ...  - loss: 0.1131 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1020 - rmse: 0.2069\n",
      "step: 317508/583123 epoch 4: ...  - loss: 0.1122 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1011 - rmse: 0.2053\n",
      "step: 367508/583123 epoch 4: ...  - loss: 0.1123 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1012 - rmse: 0.2067\n",
      "step: 417508/583123 epoch 4: ...  - loss: 0.1118 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1007 - rmse: 0.2056\n",
      "step: 467508/583123 epoch 4: ...  - loss: 0.1114 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1003 - rmse: 0.2047\n",
      "step: 517508/583123 epoch 4: ...  - loss: 0.1556 - mean_absolute_error: 0.1012 - mean_squared_error: 0.1441 - rmse: 0.2424\n",
      "step: 567508/583123 epoch 4: ...  - loss: 0.1153 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1039 - rmse: 0.2083\n",
      " - 379s - loss: 0.1168 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1057 - rmse: 0.2098 - val_loss: 0.1145 - val_mean_absolute_error: 0.0896 - val_mean_squared_error: 0.1034 - val_rmse: 0.2127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "step: 34385/583123 epoch 5: ...  - loss: 0.1126 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1015 - rmse: 0.2072\n",
      "step: 84385/583123 epoch 5: ...  - loss: 0.1646 - mean_absolute_error: 0.1016 - mean_squared_error: 0.1527 - rmse: 0.2476\n",
      "step: 134385/583123 epoch 5: ...  - loss: 0.1153 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1051 - rmse: 0.2086\n",
      "step: 184385/583123 epoch 5: ...  - loss: 0.1169 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1066 - rmse: 0.2097\n",
      "step: 234385/583123 epoch 5: ...  - loss: 0.1153 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1049 - rmse: 0.2087\n",
      "step: 284385/583123 epoch 5: ...  - loss: 0.1664 - mean_absolute_error: 0.1037 - mean_squared_error: 0.1550 - rmse: 0.2486\n",
      "step: 334385/583123 epoch 5: ...  - loss: 0.1326 - mean_absolute_error: 0.0909 - mean_squared_error: 0.1209 - rmse: 0.2209\n",
      "step: 384385/583123 epoch 5: ...  - loss: 0.1151 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1050 - rmse: 0.2091\n",
      "step: 434385/583123 epoch 5: ...  - loss: 0.1159 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1055 - rmse: 0.2088\n",
      "step: 484385/583123 epoch 5: ...  - loss: 0.1138 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1032 - rmse: 0.2068\n",
      "step: 534385/583123 epoch 5: ...  - loss: 0.1117 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1012 - rmse: 0.2063\n",
      " - 378s - loss: 0.1252 - mean_absolute_error: 0.0913 - mean_squared_error: 0.1144 - rmse: 0.2163 - val_loss: 0.1233 - val_mean_absolute_error: 0.1102 - val_mean_squared_error: 0.1125 - val_rmse: 0.2345\n",
      "Epoch 7/100\n",
      "step: 1262/583123 epoch 6: ...  - loss: 0.1171 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1063 - rmse: 0.2099\n",
      "step: 51262/583123 epoch 6: ...  - loss: 0.1134 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1025 - rmse: 0.2071\n",
      "step: 101262/583123 epoch 6: ...  - loss: 0.1120 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1012 - rmse: 0.2057\n",
      "step: 151262/583123 epoch 6: ...  - loss: 0.1105 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0997 - rmse: 0.2042\n",
      "step: 201262/583123 epoch 6: ...  - loss: 0.1120 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1012 - rmse: 0.2070\n",
      "step: 251262/583123 epoch 6: ...  - loss: 0.1414 - mean_absolute_error: 0.0967 - mean_squared_error: 0.1301 - rmse: 0.2299\n",
      "step: 301262/583123 epoch 6: ...  - loss: 0.1154 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1044 - rmse: 0.2097\n",
      "step: 351262/583123 epoch 6: ...  - loss: 0.1569 - mean_absolute_error: 0.0990 - mean_squared_error: 0.1448 - rmse: 0.2413\n",
      "step: 401262/583123 epoch 6: ...  - loss: 0.1890 - mean_absolute_error: 0.1112 - mean_squared_error: 0.1729 - rmse: 0.2599\n",
      "step: 451262/583123 epoch 6: ...  - loss: 0.1458 - mean_absolute_error: 0.0948 - mean_squared_error: 0.1304 - rmse: 0.2290\n",
      "step: 501262/583123 epoch 6: ...  - loss: 0.1376 - mean_absolute_error: 0.0902 - mean_squared_error: 0.1218 - rmse: 0.2205\n",
      "step: 551262/583123 epoch 6: ...  - loss: 0.1395 - mean_absolute_error: 0.0914 - mean_squared_error: 0.1236 - rmse: 0.2233\n",
      " - 420s - loss: 0.1340 - mean_absolute_error: 0.0927 - mean_squared_error: 0.1210 - rmse: 0.2214 - val_loss: 0.1877 - val_mean_absolute_error: 0.1096 - val_mean_squared_error: 0.1711 - val_rmse: 0.2689\n",
      "Epoch 8/100\n",
      "step: 18139/583123 epoch 7: ...  - loss: 0.1359 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1191 - rmse: 0.2187\n",
      "step: 68139/583123 epoch 7: ...  - loss: 0.1344 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1166 - rmse: 0.2170\n",
      "step: 118139/583123 epoch 7: ...  - loss: 0.1456 - mean_absolute_error: 0.0930 - mean_squared_error: 0.1273 - rmse: 0.2240\n",
      "step: 168139/583123 epoch 7: ...  - loss: 0.1410 - mean_absolute_error: 0.0909 - mean_squared_error: 0.1218 - rmse: 0.2221\n",
      "step: 218139/583123 epoch 7: ...  - loss: 0.1355 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1150 - rmse: 0.2162\n",
      "step: 268139/583123 epoch 7: ...  - loss: 0.1371 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1166 - rmse: 0.2183\n",
      "step: 318139/583123 epoch 7: ...  - loss: 0.1339 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1128 - rmse: 0.2144\n",
      "step: 368139/583123 epoch 7: ...  - loss: 0.1366 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1156 - rmse: 0.2160\n",
      "step: 418139/583123 epoch 7: ...  - loss: 0.1478 - mean_absolute_error: 0.0907 - mean_squared_error: 0.1255 - rmse: 0.2236\n",
      "step: 468139/583123 epoch 7: ...  - loss: 0.1429 - mean_absolute_error: 0.0904 - mean_squared_error: 0.1247 - rmse: 0.2225\n",
      "step: 518139/583123 epoch 7: ...  - loss: 0.1390 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1218 - rmse: 0.2213\n",
      "step: 568139/583123 epoch 7: ...  - loss: 0.1362 - mean_absolute_error: 0.0904 - mean_squared_error: 0.1190 - rmse: 0.2200\n",
      " - 481s - loss: 0.1388 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1195 - rmse: 0.2195 - val_loss: 0.1228 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.1050 - val_rmse: 0.1975\n",
      "Epoch 9/100\n",
      "step: 35016/583123 epoch 8: ...  - loss: 0.1333 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1156 - rmse: 0.2160\n",
      "step: 85016/583123 epoch 8: ...  - loss: 0.1302 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1161 - rmse: 0.2166\n",
      "step: 135016/583123 epoch 8: ...  - loss: 0.1166 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1069 - rmse: 0.2105\n",
      "step: 185016/583123 epoch 8: ...  - loss: 0.1139 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1040 - rmse: 0.2084\n",
      "step: 235016/583123 epoch 8: ...  - loss: 0.1160 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1062 - rmse: 0.2105\n",
      "step: 285016/583123 epoch 8: ...  - loss: 0.1144 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1044 - rmse: 0.2086\n",
      "step: 335016/583123 epoch 8: ...  - loss: 0.1150 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1049 - rmse: 0.2098\n",
      "step: 385016/583123 epoch 8: ...  - loss: 0.1116 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1014 - rmse: 0.2068\n",
      "step: 435016/583123 epoch 8: ...  - loss: 0.1142 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1039 - rmse: 0.2084\n",
      "step: 485016/583123 epoch 8: ...  - loss: 0.1115 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1011 - rmse: 0.2059\n",
      "step: 535016/583123 epoch 8: ...  - loss: 0.1124 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1020 - rmse: 0.2067\n",
      " - 479s - loss: 0.1165 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1056 - rmse: 0.2096 - val_loss: 0.1039 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.0933 - val_rmse: 0.1966\n",
      "Epoch 10/100\n",
      "step: 1893/583123 epoch 9: ...  - loss: 0.1135 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1030 - rmse: 0.2085\n",
      "step: 51893/583123 epoch 9: ...  - loss: 0.1610 - mean_absolute_error: 0.1020 - mean_squared_error: 0.1493 - rmse: 0.2458\n",
      "step: 101893/583123 epoch 9: ...  - loss: 0.1430 - mean_absolute_error: 0.0963 - mean_squared_error: 0.1316 - rmse: 0.2300\n",
      "step: 151893/583123 epoch 9: ...  - loss: 0.1214 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1103 - rmse: 0.2131\n",
      "step: 201893/583123 epoch 9: ...  - loss: 0.1158 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1048 - rmse: 0.2100\n",
      "step: 251893/583123 epoch 9: ...  - loss: 0.1625 - mean_absolute_error: 0.0994 - mean_squared_error: 0.1503 - rmse: 0.2434\n",
      "step: 301893/583123 epoch 9: ...  - loss: 0.1577 - mean_absolute_error: 0.0973 - mean_squared_error: 0.1436 - rmse: 0.2377\n",
      "step: 351893/583123 epoch 9: ...  - loss: 0.1342 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1208 - rmse: 0.2201\n",
      "step: 401893/583123 epoch 9: ...  - loss: 0.1161 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1064 - rmse: 0.2103\n",
      "step: 451893/583123 epoch 9: ...  - loss: 0.1267 - mean_absolute_error: 0.0922 - mean_squared_error: 0.1167 - rmse: 0.2184\n",
      "step: 501893/583123 epoch 9: ...  - loss: 0.1608 - mean_absolute_error: 0.1034 - mean_squared_error: 0.1496 - rmse: 0.2447\n",
      "step: 551893/583123 epoch 9: ...  - loss: 0.1157 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1050 - rmse: 0.2102\n",
      " - 478s - loss: 0.1401 - mean_absolute_error: 0.0952 - mean_squared_error: 0.1285 - rmse: 0.2276 - val_loss: 0.2059 - val_mean_absolute_error: 0.1157 - val_mean_squared_error: 0.1926 - val_rmse: 0.2793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "step: 18770/583123 epoch 10: ...  - loss: 0.1914 - mean_absolute_error: 0.1115 - mean_squared_error: 0.1785 - rmse: 0.2675\n",
      "step: 68770/583123 epoch 10: ...  - loss: 0.1511 - mean_absolute_error: 0.0948 - mean_squared_error: 0.1341 - rmse: 0.2324\n",
      "step: 118770/583123 epoch 10: ...  - loss: 0.1611 - mean_absolute_error: 0.0992 - mean_squared_error: 0.1433 - rmse: 0.2399\n",
      "step: 168770/583123 epoch 10: ...  - loss: 0.1407 - mean_absolute_error: 0.0919 - mean_squared_error: 0.1237 - rmse: 0.2232\n",
      "step: 218770/583123 epoch 10: ...  - loss: 0.1358 - mean_absolute_error: 0.0895 - mean_squared_error: 0.1186 - rmse: 0.2194\n",
      "step: 268770/583123 epoch 10: ...  - loss: 0.1369 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1184 - rmse: 0.2184\n",
      "step: 318770/583123 epoch 10: ...  - loss: 0.1399 - mean_absolute_error: 0.0915 - mean_squared_error: 0.1211 - rmse: 0.2210\n",
      "step: 368770/583123 epoch 10: ...  - loss: 0.1348 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1160 - rmse: 0.2168\n",
      "step: 418770/583123 epoch 10: ...  - loss: 0.1345 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1151 - rmse: 0.2167\n",
      "step: 468770/583123 epoch 10: ...  - loss: 0.1348 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1149 - rmse: 0.2157\n",
      "step: 518770/583123 epoch 10: ...  - loss: 0.1350 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1148 - rmse: 0.2159\n",
      "step: 568770/583123 epoch 10: ...  - loss: 0.1394 - mean_absolute_error: 0.0908 - mean_squared_error: 0.1192 - rmse: 0.2215\n",
      " - 478s - loss: 0.1423 - mean_absolute_error: 0.0918 - mean_squared_error: 0.1238 - rmse: 0.2236 - val_loss: 0.1332 - val_mean_absolute_error: 0.0845 - val_mean_squared_error: 0.1130 - val_rmse: 0.2089\n",
      "Epoch 12/100\n",
      "step: 35647/583123 epoch 11: ...  - loss: 0.1355 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1152 - rmse: 0.2156\n",
      "step: 85647/583123 epoch 11: ...  - loss: 0.1364 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1157 - rmse: 0.2178\n",
      "step: 135647/583123 epoch 11: ...  - loss: 0.1365 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1162 - rmse: 0.2167\n",
      "step: 185647/583123 epoch 11: ...  - loss: 0.1343 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1142 - rmse: 0.2162\n",
      "step: 235647/583123 epoch 11: ...  - loss: 0.1350 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1145 - rmse: 0.2158\n",
      "step: 285647/583123 epoch 11: ...  - loss: 0.1347 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1140 - rmse: 0.2155\n",
      "step: 335647/583123 epoch 11: ...  - loss: 0.1388 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1180 - rmse: 0.2184\n",
      "step: 385647/583123 epoch 11: ...  - loss: 0.1375 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1161 - rmse: 0.2175\n",
      "step: 435647/583123 epoch 11: ...  - loss: 0.1380 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1167 - rmse: 0.2180\n",
      "step: 485647/583123 epoch 11: ...  - loss: 0.1365 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1151 - rmse: 0.2163\n",
      "step: 535647/583123 epoch 11: ...  - loss: 0.1406 - mean_absolute_error: 0.0899 - mean_squared_error: 0.1189 - rmse: 0.2187\n",
      " - 479s - loss: 0.1369 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1159 - rmse: 0.2170 - val_loss: 0.1251 - val_mean_absolute_error: 0.0844 - val_mean_squared_error: 0.1023 - val_rmse: 0.2037\n",
      "Epoch 13/100\n",
      "step: 2524/583123 epoch 12: ...  - loss: 0.1389 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1162 - rmse: 0.2172\n",
      "step: 52524/583123 epoch 12: ...  - loss: 0.1383 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1158 - rmse: 0.2181\n",
      "step: 102524/583123 epoch 12: ...  - loss: 0.1628 - mean_absolute_error: 0.0984 - mean_squared_error: 0.1398 - rmse: 0.2354\n",
      "step: 152524/583123 epoch 12: ...  - loss: 0.1477 - mean_absolute_error: 0.0908 - mean_squared_error: 0.1235 - rmse: 0.2228\n",
      "step: 202524/583123 epoch 12: ...  - loss: 0.1413 - mean_absolute_error: 0.0895 - mean_squared_error: 0.1166 - rmse: 0.2174\n",
      "step: 252524/583123 epoch 12: ...  - loss: 0.1420 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1176 - rmse: 0.2181\n",
      "step: 302524/583123 epoch 12: ...  - loss: 0.1409 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1172 - rmse: 0.2182\n",
      "step: 352524/583123 epoch 12: ...  - loss: 0.1377 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1131 - rmse: 0.2138\n",
      "step: 402524/583123 epoch 12: ...  - loss: 0.1411 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1152 - rmse: 0.2170\n",
      "step: 452524/583123 epoch 12: ...  - loss: 0.1418 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1154 - rmse: 0.2161\n",
      "step: 502524/583123 epoch 12: ...  - loss: 0.1392 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1123 - rmse: 0.2137\n",
      "step: 552524/583123 epoch 12: ...  - loss: 0.1403 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1126 - rmse: 0.2147\n",
      " - 478s - loss: 0.1430 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1180 - rmse: 0.2185 - val_loss: 0.1427 - val_mean_absolute_error: 0.0829 - val_mean_squared_error: 0.1144 - val_rmse: 0.2030\n",
      "Epoch 14/100\n",
      "step: 19401/583123 epoch 13: ...  - loss: 0.1445 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1163 - rmse: 0.2167\n",
      "step: 69401/583123 epoch 13: ...  - loss: 0.1436 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1143 - rmse: 0.2153\n",
      "step: 119401/583123 epoch 13: ...  - loss: 0.1475 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1173 - rmse: 0.2179\n",
      "step: 169401/583123 epoch 13: ...  - loss: 0.1497 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1183 - rmse: 0.2183\n",
      "step: 219401/583123 epoch 13: ...  - loss: 0.1551 - mean_absolute_error: 0.0907 - mean_squared_error: 0.1239 - rmse: 0.2231\n",
      "step: 269401/583123 epoch 13: ...  - loss: 0.1554 - mean_absolute_error: 0.0925 - mean_squared_error: 0.1236 - rmse: 0.2244\n",
      "step: 319401/583123 epoch 13: ...  - loss: 0.1487 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1166 - rmse: 0.2177\n",
      "step: 369401/583123 epoch 13: ...  - loss: 0.1452 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1137 - rmse: 0.2152\n",
      "step: 419401/583123 epoch 13: ...  - loss: 0.1491 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1171 - rmse: 0.2173\n",
      "step: 469401/583123 epoch 13: ...  - loss: 0.1497 - mean_absolute_error: 0.0895 - mean_squared_error: 0.1171 - rmse: 0.2182\n",
      "step: 519401/583123 epoch 13: ...  - loss: 0.1457 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1125 - rmse: 0.2141\n",
      "step: 569401/583123 epoch 13: ...  - loss: 0.1493 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1178 - rmse: 0.2177\n",
      " - 478s - loss: 0.1488 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1173 - rmse: 0.2180 - val_loss: 0.1330 - val_mean_absolute_error: 0.0827 - val_mean_squared_error: 0.1012 - val_rmse: 0.1988\n",
      "Epoch 15/100\n",
      "step: 36278/583123 epoch 14: ...  - loss: 0.1471 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1157 - rmse: 0.2167\n",
      "step: 86278/583123 epoch 14: ...  - loss: 0.1468 - mean_absolute_error: 0.0895 - mean_squared_error: 0.1168 - rmse: 0.2183\n",
      "step: 136278/583123 epoch 14: ...  - loss: 0.1430 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1137 - rmse: 0.2149\n",
      "step: 186278/583123 epoch 14: ...  - loss: 0.1433 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1151 - rmse: 0.2165\n",
      "step: 236278/583123 epoch 14: ...  - loss: 0.1435 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1143 - rmse: 0.2162\n",
      "step: 286278/583123 epoch 14: ...  - loss: 0.1464 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1158 - rmse: 0.2189\n",
      "step: 336278/583123 epoch 14: ...  - loss: 0.1440 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1128 - rmse: 0.2147\n",
      "step: 386278/583123 epoch 14: ...  - loss: 0.1428 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1138 - rmse: 0.2143\n",
      "step: 436278/583123 epoch 14: ...  - loss: 0.1425 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1137 - rmse: 0.2155\n",
      "step: 486278/583123 epoch 14: ...  - loss: 0.1412 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1136 - rmse: 0.2153\n",
      "step: 536278/583123 epoch 14: ...  - loss: 0.1496 - mean_absolute_error: 0.0908 - mean_squared_error: 0.1222 - rmse: 0.2219\n",
      " - 479s - loss: 0.1454 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1162 - rmse: 0.2174 - val_loss: 0.1451 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.1165 - val_rmse: 0.2148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "step: 3155/583123 epoch 15: ...  - loss: 0.1549 - mean_absolute_error: 0.0912 - mean_squared_error: 0.1270 - rmse: 0.2245\n",
      "step: 53155/583123 epoch 15: ...  - loss: 0.1585 - mean_absolute_error: 0.0927 - mean_squared_error: 0.1292 - rmse: 0.2267\n",
      "step: 103155/583123 epoch 15: ...  - loss: 0.1526 - mean_absolute_error: 0.0905 - mean_squared_error: 0.1221 - rmse: 0.2213\n",
      "step: 153155/583123 epoch 15: ...  - loss: 0.1564 - mean_absolute_error: 0.0919 - mean_squared_error: 0.1252 - rmse: 0.2245\n",
      "step: 203155/583123 epoch 15: ...  - loss: 0.1464 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1167 - rmse: 0.2182\n",
      "step: 253155/583123 epoch 15: ...  - loss: 0.1482 - mean_absolute_error: 0.0899 - mean_squared_error: 0.1187 - rmse: 0.2185\n",
      "step: 303155/583123 epoch 15: ...  - loss: 0.1498 - mean_absolute_error: 0.0902 - mean_squared_error: 0.1203 - rmse: 0.2204\n",
      "step: 353155/583123 epoch 15: ...  - loss: 0.1503 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1204 - rmse: 0.2197\n",
      "step: 403155/583123 epoch 15: ...  - loss: 0.1422 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1125 - rmse: 0.2143\n",
      "step: 453155/583123 epoch 15: ...  - loss: 0.1490 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1182 - rmse: 0.2186\n",
      "step: 503155/583123 epoch 15: ...  - loss: 0.1526 - mean_absolute_error: 0.0907 - mean_squared_error: 0.1200 - rmse: 0.2213\n",
      "step: 553155/583123 epoch 15: ...  - loss: 0.1503 - mean_absolute_error: 0.0899 - mean_squared_error: 0.1186 - rmse: 0.2190\n",
      " - 478s - loss: 0.1505 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1200 - rmse: 0.2201 - val_loss: 0.1467 - val_mean_absolute_error: 0.0819 - val_mean_squared_error: 0.1148 - val_rmse: 0.2089\n",
      "Epoch 17/100\n",
      "step: 20032/583123 epoch 16: ...  - loss: 0.1478 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1159 - rmse: 0.2172\n",
      "step: 70032/583123 epoch 16: ...  - loss: 0.1503 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1191 - rmse: 0.2197\n",
      "step: 120032/583123 epoch 16: ...  - loss: 0.1498 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1188 - rmse: 0.2195\n",
      "step: 170032/583123 epoch 16: ...  - loss: 0.1488 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1179 - rmse: 0.2185\n",
      "step: 220032/583123 epoch 16: ...  - loss: 0.1440 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1128 - rmse: 0.2137\n",
      "step: 270032/583123 epoch 16: ...  - loss: 0.1369 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1125 - rmse: 0.2144\n",
      "step: 320032/583123 epoch 16: ...  - loss: 0.1156 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1063 - rmse: 0.2097\n",
      "step: 370032/583123 epoch 16: ...  - loss: 0.1154 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1058 - rmse: 0.2089\n",
      "step: 420032/583123 epoch 16: ...  - loss: 0.1153 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1057 - rmse: 0.2089\n",
      "step: 470032/583123 epoch 16: ...  - loss: 0.1146 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1048 - rmse: 0.2082\n",
      "step: 520032/583123 epoch 16: ...  - loss: 0.1131 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1034 - rmse: 0.2063\n",
      "step: 570032/583123 epoch 16: ...  - loss: 0.1378 - mean_absolute_error: 0.0965 - mean_squared_error: 0.1278 - rmse: 0.2272\n",
      " - 479s - loss: 0.1312 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1122 - rmse: 0.2141 - val_loss: 0.1076 - val_mean_absolute_error: 0.0922 - val_mean_squared_error: 0.0979 - val_rmse: 0.2084\n",
      "Epoch 18/100\n",
      "step: 36909/583123 epoch 17: ...  - loss: 0.1155 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1057 - rmse: 0.2090\n",
      "step: 86909/583123 epoch 17: ...  - loss: 0.1140 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1041 - rmse: 0.2084\n",
      "step: 136909/583123 epoch 17: ...  - loss: 0.1160 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1059 - rmse: 0.2105\n",
      "step: 186909/583123 epoch 17: ...  - loss: 0.1120 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1018 - rmse: 0.2073\n",
      "step: 236909/583123 epoch 17: ...  - loss: 0.1114 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1011 - rmse: 0.2058\n",
      "step: 286909/583123 epoch 17: ...  - loss: 0.1624 - mean_absolute_error: 0.1057 - mean_squared_error: 0.1516 - rmse: 0.2469\n",
      "step: 336909/583123 epoch 17: ...  - loss: 0.1258 - mean_absolute_error: 0.0917 - mean_squared_error: 0.1151 - rmse: 0.2167\n",
      "step: 386909/583123 epoch 17: ...  - loss: 0.1134 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1033 - rmse: 0.2084\n",
      "step: 436909/583123 epoch 17: ...  - loss: 0.1196 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1099 - rmse: 0.2118\n",
      "step: 486909/583123 epoch 17: ...  - loss: 0.1175 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1085 - rmse: 0.2115\n",
      "step: 536909/583123 epoch 17: ...  - loss: 0.1141 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1049 - rmse: 0.2086\n",
      " - 478s - loss: 0.1197 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1098 - rmse: 0.2128 - val_loss: 0.1064 - val_mean_absolute_error: 0.0836 - val_mean_squared_error: 0.0971 - val_rmse: 0.1972\n",
      "Epoch 19/100\n",
      "step: 3786/583123 epoch 18: ...  - loss: 0.1134 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1041 - rmse: 0.2078\n",
      "step: 53786/583123 epoch 18: ...  - loss: 0.1133 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1039 - rmse: 0.2080\n",
      "step: 103786/583123 epoch 18: ...  - loss: 0.1134 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1038 - rmse: 0.2079\n",
      "step: 153786/583123 epoch 18: ...  - loss: 0.1119 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1021 - rmse: 0.2078\n",
      "step: 203786/583123 epoch 18: ...  - loss: 0.1135 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1035 - rmse: 0.2084\n",
      "step: 253786/583123 epoch 18: ...  - loss: 0.1137 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1036 - rmse: 0.2083\n",
      "step: 303786/583123 epoch 18: ...  - loss: 0.1289 - mean_absolute_error: 0.0925 - mean_squared_error: 0.1186 - rmse: 0.2196\n",
      "step: 353786/583123 epoch 18: ...  - loss: 0.1164 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1069 - rmse: 0.2101\n",
      "step: 403786/583123 epoch 18: ...  - loss: 0.1620 - mean_absolute_error: 0.1032 - mean_squared_error: 0.1518 - rmse: 0.2477\n",
      "step: 453786/583123 epoch 18: ...  - loss: 0.1869 - mean_absolute_error: 0.1097 - mean_squared_error: 0.1750 - rmse: 0.2657\n",
      "step: 503786/583123 epoch 18: ...  - loss: 0.1407 - mean_absolute_error: 0.0946 - mean_squared_error: 0.1292 - rmse: 0.2287\n",
      "step: 553786/583123 epoch 18: ...  - loss: 0.1157 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1066 - rmse: 0.2099\n",
      " - 478s - loss: 0.1280 - mean_absolute_error: 0.0925 - mean_squared_error: 0.1179 - rmse: 0.2196 - val_loss: 0.1021 - val_mean_absolute_error: 0.0792 - val_mean_squared_error: 0.0928 - val_rmse: 0.1931\n",
      "Epoch 20/100\n",
      "step: 20663/583123 epoch 19: ...  - loss: 0.1139 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1046 - rmse: 0.2083\n",
      "step: 70663/583123 epoch 19: ...  - loss: 0.1523 - mean_absolute_error: 0.1012 - mean_squared_error: 0.1427 - rmse: 0.2387\n",
      "step: 120663/583123 epoch 19: ...  - loss: 0.1163 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1067 - rmse: 0.2102\n",
      "step: 170663/583123 epoch 19: ...  - loss: 0.1155 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1058 - rmse: 0.2104\n",
      "step: 220663/583123 epoch 19: ...  - loss: 0.1136 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1040 - rmse: 0.2081\n",
      "step: 270663/583123 epoch 19: ...  - loss: 0.1214 - mean_absolute_error: 0.0916 - mean_squared_error: 0.1116 - rmse: 0.2144\n",
      "step: 320663/583123 epoch 19: ...  - loss: 0.1223 - mean_absolute_error: 0.0923 - mean_squared_error: 0.1122 - rmse: 0.2156\n",
      "step: 370663/583123 epoch 19: ...  - loss: 0.1145 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1046 - rmse: 0.2107\n",
      "step: 420663/583123 epoch 19: ...  - loss: 0.1126 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1026 - rmse: 0.2084\n",
      "step: 470663/583123 epoch 19: ...  - loss: 0.1118 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1017 - rmse: 0.2068\n",
      "step: 520663/583123 epoch 19: ...  - loss: 0.1133 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1032 - rmse: 0.2091\n",
      "step: 570663/583123 epoch 19: ...  - loss: 0.1114 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1012 - rmse: 0.2058\n",
      " - 478s - loss: 0.1182 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1084 - rmse: 0.2122 - val_loss: 0.1014 - val_mean_absolute_error: 0.0852 - val_mean_squared_error: 0.0912 - val_rmse: 0.1954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "step: 37540/583123 epoch 20: ...  - loss: 0.1133 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1031 - rmse: 0.2083\n",
      "step: 87540/583123 epoch 20: ...  - loss: 0.1131 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1028 - rmse: 0.2081\n",
      "step: 137540/583123 epoch 20: ...  - loss: 0.1117 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1015 - rmse: 0.2070\n",
      "step: 187540/583123 epoch 20: ...  - loss: 0.1273 - mean_absolute_error: 0.0927 - mean_squared_error: 0.1169 - rmse: 0.2186\n",
      "step: 237540/583123 epoch 20: ...  - loss: 0.1114 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1011 - rmse: 0.2055\n",
      "step: 287540/583123 epoch 20: ...  - loss: 0.1233 - mean_absolute_error: 0.0913 - mean_squared_error: 0.1130 - rmse: 0.2159\n",
      "step: 337540/583123 epoch 20: ...  - loss: 0.1194 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1098 - rmse: 0.2130\n",
      "step: 387540/583123 epoch 20: ...  - loss: 0.1289 - mean_absolute_error: 0.0929 - mean_squared_error: 0.1196 - rmse: 0.2203\n",
      "step: 437540/583123 epoch 20: ...  - loss: 0.1131 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1036 - rmse: 0.2068\n",
      "step: 487540/583123 epoch 20: ...  - loss: 0.1133 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1037 - rmse: 0.2067\n",
      "step: 537540/583123 epoch 20: ...  - loss: 0.1125 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1027 - rmse: 0.2064\n",
      " - 479s - loss: 0.1168 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1069 - rmse: 0.2104 - val_loss: 0.0979 - val_mean_absolute_error: 0.0828 - val_mean_squared_error: 0.0882 - val_rmse: 0.1923\n",
      "Epoch 22/100\n",
      "step: 4417/583123 epoch 21: ...  - loss: 0.1126 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1027 - rmse: 0.2068\n",
      "step: 54417/583123 epoch 21: ...  - loss: 0.1115 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1017 - rmse: 0.2060\n",
      "step: 104417/583123 epoch 21: ...  - loss: 0.1151 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1052 - rmse: 0.2098\n",
      "step: 154417/583123 epoch 21: ...  - loss: 0.1222 - mean_absolute_error: 0.0908 - mean_squared_error: 0.1124 - rmse: 0.2157\n",
      "step: 204417/583123 epoch 21: ...  - loss: 0.1174 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1077 - rmse: 0.2108\n",
      "step: 254417/583123 epoch 21: ...  - loss: 0.1317 - mean_absolute_error: 0.0940 - mean_squared_error: 0.1219 - rmse: 0.2223\n",
      "step: 304417/583123 epoch 21: ...  - loss: 0.1139 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1039 - rmse: 0.2081\n",
      "step: 354417/583123 epoch 21: ...  - loss: 0.1287 - mean_absolute_error: 0.0927 - mean_squared_error: 0.1185 - rmse: 0.2199\n",
      "step: 404417/583123 epoch 21: ...  - loss: 0.1138 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1035 - rmse: 0.2083\n",
      "step: 454417/583123 epoch 21: ...  - loss: 0.1442 - mean_absolute_error: 0.0956 - mean_squared_error: 0.1338 - rmse: 0.2320\n",
      "step: 504417/583123 epoch 21: ...  - loss: 0.1139 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1046 - rmse: 0.2082\n",
      "step: 554417/583123 epoch 21: ...  - loss: 0.1136 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1042 - rmse: 0.2067\n",
      " - 478s - loss: 0.1203 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1104 - rmse: 0.2133 - val_loss: 0.1101 - val_mean_absolute_error: 0.0807 - val_mean_squared_error: 0.1005 - val_rmse: 0.1989\n",
      "Epoch 23/100\n",
      "step: 21294/583123 epoch 22: ...  - loss: 0.1140 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1044 - rmse: 0.2078\n",
      "step: 71294/583123 epoch 22: ...  - loss: 0.1138 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1041 - rmse: 0.2076\n",
      "step: 121294/583123 epoch 22: ...  - loss: 0.1220 - mean_absolute_error: 0.0909 - mean_squared_error: 0.1120 - rmse: 0.2144\n",
      "step: 171294/583123 epoch 22: ...  - loss: 0.1106 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1006 - rmse: 0.2044\n",
      "step: 221294/583123 epoch 22: ...  - loss: 0.1123 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1022 - rmse: 0.2070\n",
      "step: 271294/583123 epoch 22: ...  - loss: 0.1130 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1026 - rmse: 0.2065\n",
      "step: 321294/583123 epoch 22: ...  - loss: 0.1782 - mean_absolute_error: 0.1100 - mean_squared_error: 0.1677 - rmse: 0.2591\n",
      "step: 371294/583123 epoch 22: ...  - loss: 0.1155 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1063 - rmse: 0.2088\n",
      "step: 421294/583123 epoch 22: ...  - loss: 0.1158 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1065 - rmse: 0.2093\n",
      "step: 471294/583123 epoch 22: ...  - loss: 0.1132 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1039 - rmse: 0.2070\n",
      "step: 521294/583123 epoch 22: ...  - loss: 0.1129 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1033 - rmse: 0.2076\n",
      "step: 571294/583123 epoch 22: ...  - loss: 0.1190 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1093 - rmse: 0.2119\n",
      " - 479s - loss: 0.1202 - mean_absolute_error: 0.0902 - mean_squared_error: 0.1104 - rmse: 0.2127 - val_loss: 0.1225 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.1128 - val_rmse: 0.2036\n",
      "Epoch 24/100\n",
      "step: 38171/583123 epoch 23: ...  - loss: 0.1165 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1069 - rmse: 0.2106\n",
      "step: 88171/583123 epoch 23: ...  - loss: 0.1244 - mean_absolute_error: 0.0921 - mean_squared_error: 0.1145 - rmse: 0.2171\n",
      "step: 138171/583123 epoch 23: ...  - loss: 0.1279 - mean_absolute_error: 0.0922 - mean_squared_error: 0.1179 - rmse: 0.2184\n",
      "step: 188171/583123 epoch 23: ...  - loss: 0.1345 - mean_absolute_error: 0.0934 - mean_squared_error: 0.1242 - rmse: 0.2242\n",
      "step: 238171/583123 epoch 23: ...  - loss: 0.1144 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1050 - rmse: 0.2082\n",
      "step: 288171/583123 epoch 23: ...  - loss: 0.1114 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1018 - rmse: 0.2061\n",
      "step: 338171/583123 epoch 23: ...  - loss: 0.1112 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1014 - rmse: 0.2056\n",
      "step: 388171/583123 epoch 23: ...  - loss: 0.1132 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1032 - rmse: 0.2071\n",
      "step: 438171/583123 epoch 23: ...  - loss: 0.1127 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1027 - rmse: 0.2063\n",
      "step: 488171/583123 epoch 23: ...  - loss: 0.1111 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1011 - rmse: 0.2063\n",
      "step: 538171/583123 epoch 23: ...  - loss: 0.1505 - mean_absolute_error: 0.0996 - mean_squared_error: 0.1402 - rmse: 0.2368\n",
      " - 478s - loss: 0.1208 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1109 - rmse: 0.2134 - val_loss: 0.1105 - val_mean_absolute_error: 0.0890 - val_mean_squared_error: 0.1012 - val_rmse: 0.2043\n",
      "Epoch 25/100\n",
      "step: 5048/583123 epoch 24: ...  - loss: 0.1198 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1100 - rmse: 0.2130\n",
      "step: 55048/583123 epoch 24: ...  - loss: 0.1122 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1028 - rmse: 0.2062\n",
      "step: 105048/583123 epoch 24: ...  - loss: 0.1135 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1039 - rmse: 0.2069\n",
      "step: 155048/583123 epoch 24: ...  - loss: 0.1108 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1013 - rmse: 0.2050\n",
      "step: 205048/583123 epoch 24: ...  - loss: 0.1168 - mean_absolute_error: 0.0906 - mean_squared_error: 0.1070 - rmse: 0.2112\n",
      "step: 255048/583123 epoch 24: ...  - loss: 0.1127 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1029 - rmse: 0.2078\n",
      "step: 305048/583123 epoch 24: ...  - loss: 0.1137 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1038 - rmse: 0.2077\n",
      "step: 355048/583123 epoch 24: ...  - loss: 0.1121 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1020 - rmse: 0.2071\n",
      "step: 405048/583123 epoch 24: ...  - loss: 0.1125 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1023 - rmse: 0.2068\n",
      "step: 455048/583123 epoch 24: ...  - loss: 0.1123 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1020 - rmse: 0.2070\n",
      "step: 505048/583123 epoch 24: ...  - loss: 0.1105 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1003 - rmse: 0.2055\n",
      "step: 555048/583123 epoch 24: ...  - loss: 0.1664 - mean_absolute_error: 0.1033 - mean_squared_error: 0.1553 - rmse: 0.2493\n",
      " - 478s - loss: 0.1173 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1073 - rmse: 0.2107 - val_loss: 0.1116 - val_mean_absolute_error: 0.0813 - val_mean_squared_error: 0.1007 - val_rmse: 0.2066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "step: 21925/583123 epoch 25: ...  - loss: 0.1308 - mean_absolute_error: 0.0922 - mean_squared_error: 0.1197 - rmse: 0.2198\n",
      "step: 71925/583123 epoch 25: ...  - loss: 0.1646 - mean_absolute_error: 0.1010 - mean_squared_error: 0.1525 - rmse: 0.2453\n",
      "step: 121925/583123 epoch 25: ...  - loss: 0.1188 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1084 - rmse: 0.2110\n",
      "step: 171925/583123 epoch 25: ...  - loss: 0.1115 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1018 - rmse: 0.2070\n",
      "step: 221925/583123 epoch 25: ...  - loss: 0.1113 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1016 - rmse: 0.2056\n",
      "step: 271925/583123 epoch 25: ...  - loss: 0.1113 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1016 - rmse: 0.2062\n",
      "step: 321925/583123 epoch 25: ...  - loss: 0.1129 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1030 - rmse: 0.2070\n",
      "step: 371925/583123 epoch 25: ...  - loss: 0.1107 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1008 - rmse: 0.2065\n",
      "step: 421925/583123 epoch 25: ...  - loss: 0.1099 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1000 - rmse: 0.2047\n",
      "step: 471925/583123 epoch 25: ...  - loss: 0.1136 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1035 - rmse: 0.2073\n",
      "step: 521925/583123 epoch 25: ...  - loss: 0.1139 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1037 - rmse: 0.2085\n",
      "step: 571925/583123 epoch 25: ...  - loss: 0.1138 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1035 - rmse: 0.2090\n",
      " - 479s - loss: 0.1188 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1086 - rmse: 0.2117 - val_loss: 0.1012 - val_mean_absolute_error: 0.0791 - val_mean_squared_error: 0.0910 - val_rmse: 0.1937\n",
      "Epoch 27/100\n",
      "step: 38802/583123 epoch 26: ...  - loss: 0.1116 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1013 - rmse: 0.2056\n",
      "step: 88802/583123 epoch 26: ...  - loss: 0.1111 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1008 - rmse: 0.2061\n",
      "step: 138802/583123 epoch 26: ...  - loss: 0.1124 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1020 - rmse: 0.2063\n",
      "step: 188802/583123 epoch 26: ...  - loss: 0.1276 - mean_absolute_error: 0.0930 - mean_squared_error: 0.1170 - rmse: 0.2193\n",
      "step: 238802/583123 epoch 26: ...  - loss: 0.1107 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1002 - rmse: 0.2054\n",
      "step: 288802/583123 epoch 26: ...  - loss: 0.1360 - mean_absolute_error: 0.0941 - mean_squared_error: 0.1253 - rmse: 0.2251\n",
      "step: 338802/583123 epoch 26: ...  - loss: 0.1145 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1050 - rmse: 0.2093\n",
      "step: 388802/583123 epoch 26: ...  - loss: 0.1126 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1031 - rmse: 0.2063\n",
      "step: 438802/583123 epoch 26: ...  - loss: 0.1134 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1037 - rmse: 0.2081\n",
      "step: 488802/583123 epoch 26: ...  - loss: 0.1169 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1070 - rmse: 0.2095\n",
      "step: 538802/583123 epoch 26: ...  - loss: 0.1237 - mean_absolute_error: 0.0922 - mean_squared_error: 0.1135 - rmse: 0.2165\n",
      " - 478s - loss: 0.1185 - mean_absolute_error: 0.0895 - mean_squared_error: 0.1083 - rmse: 0.2115 - val_loss: 0.1068 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0965 - val_rmse: 0.1927\n",
      "Epoch 28/100\n",
      "step: 5679/583123 epoch 27: ...  - loss: 0.1292 - mean_absolute_error: 0.0918 - mean_squared_error: 0.1187 - rmse: 0.2181\n",
      "step: 55679/583123 epoch 27: ...  - loss: 0.1132 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1029 - rmse: 0.2056\n",
      "step: 105679/583123 epoch 27: ...  - loss: 0.1299 - mean_absolute_error: 0.0911 - mean_squared_error: 0.1192 - rmse: 0.2185\n",
      "step: 155679/583123 epoch 27: ...  - loss: 0.1108 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1002 - rmse: 0.2052\n",
      "step: 205679/583123 epoch 27: ...  - loss: 0.1123 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1014 - rmse: 0.2063\n",
      "step: 255679/583123 epoch 27: ...  - loss: 0.1126 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1017 - rmse: 0.2067\n",
      "step: 305679/583123 epoch 27: ...  - loss: 0.1122 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1013 - rmse: 0.2051\n",
      "step: 355679/583123 epoch 27: ...  - loss: 0.1256 - mean_absolute_error: 0.0933 - mean_squared_error: 0.1145 - rmse: 0.2168\n",
      "step: 405679/583123 epoch 27: ...  - loss: 0.1286 - mean_absolute_error: 0.0915 - mean_squared_error: 0.1177 - rmse: 0.2188\n",
      "step: 455679/583123 epoch 27: ...  - loss: 0.1139 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1033 - rmse: 0.2076\n",
      "step: 505679/583123 epoch 27: ...  - loss: 0.1119 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1012 - rmse: 0.2060\n",
      "step: 555679/583123 epoch 27: ...  - loss: 0.1164 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1056 - rmse: 0.2101\n",
      " - 478s - loss: 0.1167 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1060 - rmse: 0.2095 - val_loss: 0.1213 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.1105 - val_rmse: 0.2085\n",
      "Epoch 29/100\n",
      "step: 22556/583123 epoch 28: ...  - loss: 0.1124 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1016 - rmse: 0.2063\n",
      "step: 72556/583123 epoch 28: ...  - loss: 0.1451 - mean_absolute_error: 0.0975 - mean_squared_error: 0.1340 - rmse: 0.2316\n",
      "step: 122556/583123 epoch 28: ...  - loss: 0.1447 - mean_absolute_error: 0.0940 - mean_squared_error: 0.1325 - rmse: 0.2290\n",
      "step: 172556/583123 epoch 28: ...  - loss: 0.1363 - mean_absolute_error: 0.0919 - mean_squared_error: 0.1255 - rmse: 0.2237\n",
      "step: 222556/583123 epoch 28: ...  - loss: 0.1167 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1063 - rmse: 0.2090\n",
      "step: 272556/583123 epoch 28: ...  - loss: 0.1118 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1017 - rmse: 0.2059\n",
      "step: 322556/583123 epoch 28: ...  - loss: 0.1133 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1030 - rmse: 0.2058\n",
      "step: 372556/583123 epoch 28: ...  - loss: 0.1135 - mean_absolute_error: 0.0863 - mean_squared_error: 0.1030 - rmse: 0.2066\n",
      "step: 422556/583123 epoch 28: ...  - loss: 0.1168 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1062 - rmse: 0.2095\n",
      "step: 472556/583123 epoch 28: ...  - loss: 0.1160 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1052 - rmse: 0.2097\n",
      "step: 522556/583123 epoch 28: ...  - loss: 0.1166 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1062 - rmse: 0.2090\n",
      "step: 572556/583123 epoch 28: ...  - loss: 0.1187 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1088 - rmse: 0.2115\n",
      " - 479s - loss: 0.1221 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1115 - rmse: 0.2133 - val_loss: 0.1133 - val_mean_absolute_error: 0.0957 - val_mean_squared_error: 0.1034 - val_rmse: 0.2186\n",
      "Epoch 30/100\n",
      "step: 39433/583123 epoch 29: ...  - loss: 0.1127 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1027 - rmse: 0.2064\n",
      "step: 89433/583123 epoch 29: ...  - loss: 0.1138 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1036 - rmse: 0.2075\n",
      "step: 139433/583123 epoch 29: ...  - loss: 0.1360 - mean_absolute_error: 0.0936 - mean_squared_error: 0.1255 - rmse: 0.2240\n",
      "step: 189433/583123 epoch 29: ...  - loss: 0.1193 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1091 - rmse: 0.2116\n",
      "step: 239433/583123 epoch 29: ...  - loss: 0.1130 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1031 - rmse: 0.2072\n",
      "step: 289433/583123 epoch 29: ...  - loss: 0.1148 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1048 - rmse: 0.2092\n",
      "step: 339433/583123 epoch 29: ...  - loss: 0.1093 - mean_absolute_error: 0.0861 - mean_squared_error: 0.0992 - rmse: 0.2033\n",
      "step: 389433/583123 epoch 29: ...  - loss: 0.1135 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1034 - rmse: 0.2064\n",
      "step: 439433/583123 epoch 29: ...  - loss: 0.1116 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1014 - rmse: 0.2053\n",
      "step: 489433/583123 epoch 29: ...  - loss: 0.1229 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1127 - rmse: 0.2140\n",
      "step: 539433/583123 epoch 29: ...  - loss: 0.1142 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1042 - rmse: 0.2080\n",
      " - 479s - loss: 0.1163 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1062 - rmse: 0.2093 - val_loss: 0.1067 - val_mean_absolute_error: 0.0759 - val_mean_squared_error: 0.0966 - val_rmse: 0.1918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "step: 6310/583123 epoch 30: ...  - loss: 0.1146 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1044 - rmse: 0.2084\n",
      "step: 56310/583123 epoch 30: ...  - loss: 0.1129 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1026 - rmse: 0.2060\n",
      "step: 106310/583123 epoch 30: ...  - loss: 0.1209 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1103 - rmse: 0.2124\n",
      "step: 156310/583123 epoch 30: ...  - loss: 0.1111 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1005 - rmse: 0.2053\n",
      "step: 206310/583123 epoch 30: ...  - loss: 0.1239 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1136 - rmse: 0.2148\n",
      "step: 256310/583123 epoch 30: ...  - loss: 0.1116 - mean_absolute_error: 0.0861 - mean_squared_error: 0.1015 - rmse: 0.2051\n",
      "step: 306310/583123 epoch 30: ...  - loss: 0.1116 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1013 - rmse: 0.2057\n",
      "step: 356310/583123 epoch 30: ...  - loss: 0.1234 - mean_absolute_error: 0.0923 - mean_squared_error: 0.1129 - rmse: 0.2163\n",
      "step: 406310/583123 epoch 30: ...  - loss: 0.1122 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1017 - rmse: 0.2075\n",
      "step: 456310/583123 epoch 30: ...  - loss: 0.1462 - mean_absolute_error: 0.0993 - mean_squared_error: 0.1354 - rmse: 0.2363\n",
      "step: 506310/583123 epoch 30: ...  - loss: 0.1125 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1017 - rmse: 0.2071\n",
      "step: 556310/583123 epoch 30: ...  - loss: 0.1108 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1001 - rmse: 0.2052\n",
      " - 478s - loss: 0.1184 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1079 - rmse: 0.2113 - val_loss: 0.2188 - val_mean_absolute_error: 0.1157 - val_mean_squared_error: 0.2076 - val_rmse: 0.2886\n",
      "Epoch 32/100\n",
      "step: 23187/583123 epoch 31: ...  - loss: 0.1271 - mean_absolute_error: 0.0905 - mean_squared_error: 0.1163 - rmse: 0.2169\n",
      "step: 73187/583123 epoch 31: ...  - loss: 0.1142 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1042 - rmse: 0.2084\n",
      "step: 123187/583123 epoch 31: ...  - loss: 0.1127 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1026 - rmse: 0.2062\n",
      "step: 173187/583123 epoch 31: ...  - loss: 0.1119 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1017 - rmse: 0.2049\n",
      "step: 223187/583123 epoch 31: ...  - loss: 0.1168 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1066 - rmse: 0.2088\n",
      "step: 273187/583123 epoch 31: ...  - loss: 0.1120 - mean_absolute_error: 0.0859 - mean_squared_error: 0.1019 - rmse: 0.2048\n",
      "step: 323187/583123 epoch 31: ...  - loss: 0.1126 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1024 - rmse: 0.2059\n",
      "step: 373187/583123 epoch 31: ...  - loss: 0.1125 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1022 - rmse: 0.2070\n",
      "step: 423187/583123 epoch 31: ...  - loss: 0.1115 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1010 - rmse: 0.2059\n",
      "step: 473187/583123 epoch 31: ...  - loss: 0.1158 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1053 - rmse: 0.2087\n",
      "step: 523187/583123 epoch 31: ...  - loss: 0.1130 - mean_absolute_error: 0.0863 - mean_squared_error: 0.1029 - rmse: 0.2058\n",
      "step: 573187/583123 epoch 31: ...  - loss: 0.1126 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1022 - rmse: 0.2068\n",
      " - 478s - loss: 0.1137 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1034 - rmse: 0.2070 - val_loss: 0.1061 - val_mean_absolute_error: 0.0863 - val_mean_squared_error: 0.0956 - val_rmse: 0.1984\n",
      "Epoch 33/100\n",
      "step: 40064/583123 epoch 32: ...  - loss: 0.1220 - mean_absolute_error: 0.0908 - mean_squared_error: 0.1116 - rmse: 0.2133\n",
      "step: 90064/583123 epoch 32: ...  - loss: 0.1168 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1066 - rmse: 0.2090\n",
      "step: 140064/583123 epoch 32: ...  - loss: 0.1134 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1032 - rmse: 0.2070\n",
      "step: 190064/583123 epoch 32: ...  - loss: 0.1250 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1146 - rmse: 0.2157\n",
      "step: 240064/583123 epoch 32: ...  - loss: 0.1145 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1044 - rmse: 0.2071\n",
      "step: 290064/583123 epoch 32: ...  - loss: 0.1134 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1032 - rmse: 0.2072\n",
      "step: 340064/583123 epoch 32: ...  - loss: 0.1152 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1048 - rmse: 0.2089\n",
      "step: 390064/583123 epoch 32: ...  - loss: 0.1141 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1035 - rmse: 0.2065\n",
      "step: 440064/583123 epoch 32: ...  - loss: 0.1153 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1044 - rmse: 0.2081\n",
      "step: 490064/583123 epoch 32: ...  - loss: 0.1109 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1001 - rmse: 0.2053\n",
      "step: 540064/583123 epoch 32: ...  - loss: 0.1120 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1011 - rmse: 0.2071\n",
      " - 478s - loss: 0.1154 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1049 - rmse: 0.2085 - val_loss: 0.1041 - val_mean_absolute_error: 0.0864 - val_mean_squared_error: 0.0932 - val_rmse: 0.2038\n",
      "Epoch 34/100\n",
      "step: 6941/583123 epoch 33: ...  - loss: 0.1187 - mean_absolute_error: 0.0900 - mean_squared_error: 0.1078 - rmse: 0.2120\n",
      "step: 56941/583123 epoch 33: ...  - loss: 0.1348 - mean_absolute_error: 0.0934 - mean_squared_error: 0.1243 - rmse: 0.2247\n",
      "step: 106941/583123 epoch 33: ...  - loss: 0.1110 - mean_absolute_error: 0.0862 - mean_squared_error: 0.1006 - rmse: 0.2045\n",
      "step: 156941/583123 epoch 33: ...  - loss: 0.1137 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1032 - rmse: 0.2076\n",
      "step: 206941/583123 epoch 33: ...  - loss: 0.1104 - mean_absolute_error: 0.0871 - mean_squared_error: 0.0999 - rmse: 0.2051\n",
      "step: 256941/583123 epoch 33: ...  - loss: 0.1108 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1001 - rmse: 0.2043\n",
      "step: 306941/583123 epoch 33: ...  - loss: 0.1350 - mean_absolute_error: 0.0934 - mean_squared_error: 0.1242 - rmse: 0.2249\n",
      "step: 356941/583123 epoch 33: ...  - loss: 0.1280 - mean_absolute_error: 0.0915 - mean_squared_error: 0.1176 - rmse: 0.2179\n",
      "step: 406941/583123 epoch 33: ...  - loss: 0.1115 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1013 - rmse: 0.2055\n",
      "step: 456941/583123 epoch 33: ...  - loss: 0.1171 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1068 - rmse: 0.2117\n",
      "step: 506941/583123 epoch 33: ...  - loss: 0.1154 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1051 - rmse: 0.2107\n",
      "step: 556941/583123 epoch 33: ...  - loss: 0.1115 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1010 - rmse: 0.2062\n",
      " - 478s - loss: 0.1183 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1078 - rmse: 0.2113 - val_loss: 0.1184 - val_mean_absolute_error: 0.0905 - val_mean_squared_error: 0.1077 - val_rmse: 0.2046\n",
      "Epoch 35/100\n",
      "step: 23818/583123 epoch 34: ...  - loss: 0.1114 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1007 - rmse: 0.2045\n",
      "step: 73818/583123 epoch 34: ...  - loss: 0.1213 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1107 - rmse: 0.2128\n",
      "step: 123818/583123 epoch 34: ...  - loss: 0.1131 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1025 - rmse: 0.2073\n",
      "step: 173818/583123 epoch 34: ...  - loss: 0.1152 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1044 - rmse: 0.2088\n",
      "step: 223818/583123 epoch 34: ...  - loss: 0.1097 - mean_absolute_error: 0.0862 - mean_squared_error: 0.0988 - rmse: 0.2032\n",
      "step: 273818/583123 epoch 34: ...  - loss: 0.1089 - mean_absolute_error: 0.0859 - mean_squared_error: 0.0981 - rmse: 0.2029\n",
      "step: 323818/583123 epoch 34: ...  - loss: 0.1131 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1023 - rmse: 0.2074\n",
      "step: 373818/583123 epoch 34: ...  - loss: 0.1109 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1001 - rmse: 0.2054\n",
      "step: 423818/583123 epoch 34: ...  - loss: 0.1123 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1015 - rmse: 0.2072\n",
      "step: 473818/583123 epoch 34: ...  - loss: 0.1129 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1020 - rmse: 0.2068\n",
      "step: 523818/583123 epoch 34: ...  - loss: 0.1108 - mean_absolute_error: 0.0860 - mean_squared_error: 0.0999 - rmse: 0.2048\n",
      "step: 573818/583123 epoch 34: ...  - loss: 0.1167 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1058 - rmse: 0.2080\n",
      " - 479s - loss: 0.1132 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1024 - rmse: 0.2068 - val_loss: 0.1093 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0998 - val_rmse: 0.2036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "step: 40695/583123 epoch 35: ...  - loss: 0.1138 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1040 - rmse: 0.2077\n",
      "step: 90695/583123 epoch 35: ...  - loss: 0.1105 - mean_absolute_error: 0.0856 - mean_squared_error: 0.1005 - rmse: 0.2036\n",
      "step: 140695/583123 epoch 35: ...  - loss: 0.1121 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1020 - rmse: 0.2063\n",
      "step: 190695/583123 epoch 35: ...  - loss: 0.1119 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1018 - rmse: 0.2060\n",
      "step: 240695/583123 epoch 35: ...  - loss: 0.1130 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1027 - rmse: 0.2072\n",
      "step: 290695/583123 epoch 35: ...  - loss: 0.1111 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1007 - rmse: 0.2055\n",
      "step: 340695/583123 epoch 35: ...  - loss: 0.1182 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1076 - rmse: 0.2106\n",
      "step: 390695/583123 epoch 35: ...  - loss: 0.1126 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1022 - rmse: 0.2058\n",
      "step: 440695/583123 epoch 35: ...  - loss: 0.1200 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1098 - rmse: 0.2112\n",
      "step: 490695/583123 epoch 35: ...  - loss: 0.1127 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1026 - rmse: 0.2073\n",
      "step: 540695/583123 epoch 35: ...  - loss: 0.1166 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1063 - rmse: 0.2098\n",
      " - 477s - loss: 0.1141 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1039 - rmse: 0.2076 - val_loss: 0.1135 - val_mean_absolute_error: 0.0882 - val_mean_squared_error: 0.1035 - val_rmse: 0.2057\n",
      "Epoch 37/100\n",
      "step: 7572/583123 epoch 36: ...  - loss: 0.1246 - mean_absolute_error: 0.0910 - mean_squared_error: 0.1145 - rmse: 0.2170\n",
      "step: 57572/583123 epoch 36: ...  - loss: 0.1170 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1070 - rmse: 0.2090\n",
      "step: 107572/583123 epoch 36: ...  - loss: 0.1138 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1038 - rmse: 0.2082\n",
      "step: 157572/583123 epoch 36: ...  - loss: 0.1115 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1014 - rmse: 0.2051\n",
      "step: 207572/583123 epoch 36: ...  - loss: 0.1121 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1018 - rmse: 0.2061\n",
      "step: 257572/583123 epoch 36: ...  - loss: 0.1188 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1083 - rmse: 0.2100\n",
      "step: 307572/583123 epoch 36: ...  - loss: 0.1158 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1052 - rmse: 0.2092\n",
      "step: 357572/583123 epoch 36: ...  - loss: 0.1111 - mean_absolute_error: 0.0856 - mean_squared_error: 0.1006 - rmse: 0.2048\n",
      "step: 407572/583123 epoch 36: ...  - loss: 0.1129 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1022 - rmse: 0.2072\n",
      "step: 457572/583123 epoch 36: ...  - loss: 0.1216 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1111 - rmse: 0.2124\n",
      "step: 507572/583123 epoch 36: ...  - loss: 0.1128 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1028 - rmse: 0.2060\n",
      "step: 557572/583123 epoch 36: ...  - loss: 0.1115 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1013 - rmse: 0.2061\n",
      " - 376s - loss: 0.1150 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1047 - rmse: 0.2081 - val_loss: 0.1285 - val_mean_absolute_error: 0.0908 - val_mean_squared_error: 0.1181 - val_rmse: 0.2192\n",
      "Epoch 38/100\n",
      "step: 24449/583123 epoch 37: ...  - loss: 0.1113 - mean_absolute_error: 0.0859 - mean_squared_error: 0.1009 - rmse: 0.2042\n",
      "step: 74449/583123 epoch 37: ...  - loss: 0.1103 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0998 - rmse: 0.2042\n",
      "step: 124449/583123 epoch 37: ...  - loss: 0.1262 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1158 - rmse: 0.2156\n",
      "step: 174449/583123 epoch 37: ...  - loss: 0.1144 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1045 - rmse: 0.2088\n",
      "step: 224449/583123 epoch 37: ...  - loss: 0.1136 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1035 - rmse: 0.2069\n",
      "step: 274449/583123 epoch 37: ...  - loss: 0.1178 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1076 - rmse: 0.2103\n",
      "step: 324449/583123 epoch 37: ...  - loss: 0.1153 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1053 - rmse: 0.2080\n",
      "step: 374449/583123 epoch 37: ...  - loss: 0.1110 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1009 - rmse: 0.2043\n",
      "step: 424449/583123 epoch 37: ...  - loss: 0.1129 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1028 - rmse: 0.2069\n",
      "step: 474449/583123 epoch 37: ...  - loss: 0.1543 - mean_absolute_error: 0.1025 - mean_squared_error: 0.1441 - rmse: 0.2360\n",
      "step: 524449/583123 epoch 37: ...  - loss: 0.1144 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1043 - rmse: 0.2072\n",
      "step: 574449/583123 epoch 37: ...  - loss: 0.1321 - mean_absolute_error: 0.0927 - mean_squared_error: 0.1218 - rmse: 0.2211\n",
      " - 376s - loss: 0.1197 - mean_absolute_error: 0.0892 - mean_squared_error: 0.1096 - rmse: 0.2114 - val_loss: 0.1109 - val_mean_absolute_error: 0.0830 - val_mean_squared_error: 0.1006 - val_rmse: 0.1985\n",
      "Epoch 39/100\n",
      "step: 41326/583123 epoch 38: ...  - loss: 0.1132 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1030 - rmse: 0.2066\n",
      "step: 91326/583123 epoch 38: ...  - loss: 0.1117 - mean_absolute_error: 0.0861 - mean_squared_error: 0.1015 - rmse: 0.2043\n",
      "step: 141326/583123 epoch 38: ...  - loss: 0.1375 - mean_absolute_error: 0.0954 - mean_squared_error: 0.1271 - rmse: 0.2278\n",
      "step: 191326/583123 epoch 38: ...  - loss: 0.1171 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1067 - rmse: 0.2094\n",
      "step: 241326/583123 epoch 38: ...  - loss: 0.1118 - mean_absolute_error: 0.0862 - mean_squared_error: 0.1015 - rmse: 0.2054\n",
      "step: 291326/583123 epoch 38: ...  - loss: 0.1131 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1027 - rmse: 0.2068\n",
      "step: 341326/583123 epoch 38: ...  - loss: 0.1169 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1064 - rmse: 0.2090\n",
      "step: 391326/583123 epoch 38: ...  - loss: 0.1135 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1031 - rmse: 0.2077\n",
      "step: 441326/583123 epoch 38: ...  - loss: 0.1116 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1010 - rmse: 0.2058\n",
      "step: 491326/583123 epoch 38: ...  - loss: 0.1131 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1025 - rmse: 0.2074\n",
      "step: 541326/583123 epoch 38: ...  - loss: 0.1177 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1073 - rmse: 0.2091\n",
      " - 377s - loss: 0.1159 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1054 - rmse: 0.2089 - val_loss: 0.1061 - val_mean_absolute_error: 0.0854 - val_mean_squared_error: 0.0956 - val_rmse: 0.2017\n",
      "Epoch 40/100\n",
      "step: 8203/583123 epoch 39: ...  - loss: 0.1137 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1033 - rmse: 0.2073\n",
      "step: 58203/583123 epoch 39: ...  - loss: 0.1163 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1060 - rmse: 0.2085\n",
      "step: 108203/583123 epoch 39: ...  - loss: 0.1127 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1026 - rmse: 0.2061\n",
      "step: 158203/583123 epoch 39: ...  - loss: 0.1131 - mean_absolute_error: 0.0861 - mean_squared_error: 0.1030 - rmse: 0.2060\n",
      "step: 208203/583123 epoch 39: ...  - loss: 0.1109 - mean_absolute_error: 0.0857 - mean_squared_error: 0.1006 - rmse: 0.2037\n",
      "step: 258203/583123 epoch 39: ...  - loss: 0.1115 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1011 - rmse: 0.2055\n",
      "step: 308203/583123 epoch 39: ...  - loss: 0.1119 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1015 - rmse: 0.2073\n",
      "step: 358203/583123 epoch 39: ...  - loss: 0.1348 - mean_absolute_error: 0.0952 - mean_squared_error: 0.1244 - rmse: 0.2247\n",
      "step: 408203/583123 epoch 39: ...  - loss: 0.1152 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1045 - rmse: 0.2092\n",
      "step: 458203/583123 epoch 39: ...  - loss: 0.1126 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1019 - rmse: 0.2073\n",
      "step: 508203/583123 epoch 39: ...  - loss: 0.1116 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1008 - rmse: 0.2050\n",
      "step: 558203/583123 epoch 39: ...  - loss: 0.1108 - mean_absolute_error: 0.0867 - mean_squared_error: 0.0999 - rmse: 0.2043\n",
      " - 377s - loss: 0.1145 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1040 - rmse: 0.2078 - val_loss: 0.1341 - val_mean_absolute_error: 0.1081 - val_mean_squared_error: 0.1233 - val_rmse: 0.2457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "step: 25080/583123 epoch 40: ...  - loss: 0.1391 - mean_absolute_error: 0.0970 - mean_squared_error: 0.1282 - rmse: 0.2275\n",
      "step: 75080/583123 epoch 40: ...  - loss: 0.1115 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1006 - rmse: 0.2047\n",
      "step: 125080/583123 epoch 40: ...  - loss: 0.1219 - mean_absolute_error: 0.0918 - mean_squared_error: 0.1110 - rmse: 0.2157\n",
      "step: 175080/583123 epoch 40: ...  - loss: 0.1097 - mean_absolute_error: 0.0860 - mean_squared_error: 0.0988 - rmse: 0.2036\n",
      "step: 225080/583123 epoch 40: ...  - loss: 0.1143 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1034 - rmse: 0.2083\n",
      "step: 275080/583123 epoch 40: ...  - loss: 0.1139 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1031 - rmse: 0.2065\n",
      "step: 325080/583123 epoch 40: ...  - loss: 0.1148 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1040 - rmse: 0.2084\n",
      "step: 375080/583123 epoch 40: ...  - loss: 0.1111 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1003 - rmse: 0.2049\n",
      "step: 425080/583123 epoch 40: ...  - loss: 0.1166 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1058 - rmse: 0.2107\n",
      "step: 475080/583123 epoch 40: ...  - loss: 0.1130 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1021 - rmse: 0.2070\n",
      "step: 525080/583123 epoch 40: ...  - loss: 0.1115 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1007 - rmse: 0.2062\n",
      "step: 575080/583123 epoch 40: ...  - loss: 0.1114 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1005 - rmse: 0.2054\n",
      " - 376s - loss: 0.1159 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1050 - rmse: 0.2092 - val_loss: 0.0987 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.0879 - val_rmse: 0.1871\n",
      "Epoch 42/100\n",
      "step: 41957/583123 epoch 41: ...  - loss: 0.1093 - mean_absolute_error: 0.0858 - mean_squared_error: 0.0985 - rmse: 0.2030\n",
      "step: 91957/583123 epoch 41: ...  - loss: 0.1089 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0981 - rmse: 0.2038\n",
      "step: 141957/583123 epoch 41: ...  - loss: 0.1712 - mean_absolute_error: 0.1075 - mean_squared_error: 0.1597 - rmse: 0.2522\n",
      "step: 191957/583123 epoch 41: ...  - loss: 0.1370 - mean_absolute_error: 0.0923 - mean_squared_error: 0.1249 - rmse: 0.2247\n",
      "step: 241957/583123 epoch 41: ...  - loss: 0.1280 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1158 - rmse: 0.2170\n",
      "step: 291957/583123 epoch 41: ...  - loss: 0.1418 - mean_absolute_error: 0.0938 - mean_squared_error: 0.1304 - rmse: 0.2283\n",
      "step: 341957/583123 epoch 41: ...  - loss: 0.1334 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1204 - rmse: 0.2202\n",
      "step: 391957/583123 epoch 41: ...  - loss: 0.1368 - mean_absolute_error: 0.0920 - mean_squared_error: 0.1235 - rmse: 0.2226\n",
      "step: 441957/583123 epoch 41: ...  - loss: 0.1331 - mean_absolute_error: 0.0908 - mean_squared_error: 0.1196 - rmse: 0.2198\n",
      "step: 491957/583123 epoch 41: ...  - loss: 0.1173 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1069 - rmse: 0.2105\n",
      "step: 541957/583123 epoch 41: ...  - loss: 0.1144 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1042 - rmse: 0.2079\n",
      " - 377s - loss: 0.1291 - mean_absolute_error: 0.0911 - mean_squared_error: 0.1174 - rmse: 0.2183 - val_loss: 0.1012 - val_mean_absolute_error: 0.0819 - val_mean_squared_error: 0.0908 - val_rmse: 0.1916\n",
      "Epoch 43/100\n",
      "step: 8834/583123 epoch 42: ...  - loss: 0.1115 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1011 - rmse: 0.2051\n",
      "step: 58834/583123 epoch 42: ...  - loss: 0.1115 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1010 - rmse: 0.2055\n",
      "step: 108834/583123 epoch 42: ...  - loss: 0.1096 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0991 - rmse: 0.2041\n",
      "step: 158834/583123 epoch 42: ...  - loss: 0.1105 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0999 - rmse: 0.2050\n",
      "step: 208834/583123 epoch 42: ...  - loss: 0.1154 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1048 - rmse: 0.2083\n",
      "step: 258834/583123 epoch 42: ...  - loss: 0.1173 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1075 - rmse: 0.2103\n",
      "step: 308834/583123 epoch 42: ...  - loss: 0.1123 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1026 - rmse: 0.2059\n",
      "step: 358834/583123 epoch 42: ...  - loss: 0.1148 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1052 - rmse: 0.2083\n",
      "step: 408834/583123 epoch 42: ...  - loss: 0.1132 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1035 - rmse: 0.2064\n",
      "step: 458834/583123 epoch 42: ...  - loss: 0.1201 - mean_absolute_error: 0.0889 - mean_squared_error: 0.1102 - rmse: 0.2118\n",
      "step: 508834/583123 epoch 42: ...  - loss: 0.1133 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1034 - rmse: 0.2077\n",
      "step: 558834/583123 epoch 42: ...  - loss: 0.1098 - mean_absolute_error: 0.0857 - mean_squared_error: 0.0998 - rmse: 0.2036\n",
      " - 376s - loss: 0.1134 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1033 - rmse: 0.2070 - val_loss: 0.1101 - val_mean_absolute_error: 0.0889 - val_mean_squared_error: 0.0999 - val_rmse: 0.2102\n",
      "Epoch 44/100\n",
      "step: 25711/583123 epoch 43: ...  - loss: 0.1146 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1044 - rmse: 0.2091\n",
      "step: 75711/583123 epoch 43: ...  - loss: 0.1154 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1053 - rmse: 0.2077\n",
      "step: 125711/583123 epoch 43: ...  - loss: 0.1447 - mean_absolute_error: 0.0981 - mean_squared_error: 0.1346 - rmse: 0.2326\n",
      "step: 175711/583123 epoch 43: ...  - loss: 0.1134 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1035 - rmse: 0.2069\n",
      "step: 225711/583123 epoch 43: ...  - loss: 0.1386 - mean_absolute_error: 0.0947 - mean_squared_error: 0.1283 - rmse: 0.2265\n",
      "step: 275711/583123 epoch 43: ...  - loss: 0.1131 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1033 - rmse: 0.2066\n",
      "step: 325711/583123 epoch 43: ...  - loss: 0.1156 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1056 - rmse: 0.2083\n",
      "step: 375711/583123 epoch 43: ...  - loss: 0.1179 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1077 - rmse: 0.2106\n",
      "step: 425711/583123 epoch 43: ...  - loss: 0.1110 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1009 - rmse: 0.2061\n",
      "step: 475711/583123 epoch 43: ...  - loss: 0.1159 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1059 - rmse: 0.2090\n",
      "step: 525711/583123 epoch 43: ...  - loss: 0.1406 - mean_absolute_error: 0.0964 - mean_squared_error: 0.1302 - rmse: 0.2297\n",
      "step: 575711/583123 epoch 43: ...  - loss: 0.1140 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1037 - rmse: 0.2086\n",
      " - 376s - loss: 0.1215 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1113 - rmse: 0.2136 - val_loss: 0.1006 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0903 - val_rmse: 0.1935\n",
      "Epoch 45/100\n",
      "step: 42588/583123 epoch 44: ...  - loss: 0.1148 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1044 - rmse: 0.2087\n",
      "step: 92588/583123 epoch 44: ...  - loss: 0.1107 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1002 - rmse: 0.2054\n",
      "step: 142588/583123 epoch 44: ...  - loss: 0.1124 - mean_absolute_error: 0.0883 - mean_squared_error: 0.1019 - rmse: 0.2068\n",
      "step: 192588/583123 epoch 44: ...  - loss: 0.1137 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1031 - rmse: 0.2071\n",
      "step: 242588/583123 epoch 44: ...  - loss: 0.1243 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1141 - rmse: 0.2156\n",
      "step: 292588/583123 epoch 44: ...  - loss: 0.1121 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1023 - rmse: 0.2065\n",
      "step: 342588/583123 epoch 44: ...  - loss: 0.1125 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1027 - rmse: 0.2069\n",
      "step: 392588/583123 epoch 44: ...  - loss: 0.1118 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1019 - rmse: 0.2057\n",
      "step: 442588/583123 epoch 44: ...  - loss: 0.1118 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1018 - rmse: 0.2066\n",
      "step: 492588/583123 epoch 44: ...  - loss: 0.1251 - mean_absolute_error: 0.0924 - mean_squared_error: 0.1149 - rmse: 0.2177\n",
      "step: 542588/583123 epoch 44: ...  - loss: 0.1125 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1021 - rmse: 0.2066\n",
      " - 376s - loss: 0.1158 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1055 - rmse: 0.2094 - val_loss: 0.1263 - val_mean_absolute_error: 0.0883 - val_mean_squared_error: 0.1156 - val_rmse: 0.2184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "step: 9465/583123 epoch 45: ...  - loss: 0.1280 - mean_absolute_error: 0.0930 - mean_squared_error: 0.1175 - rmse: 0.2202\n",
      "step: 59465/583123 epoch 45: ...  - loss: 0.1166 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1062 - rmse: 0.2094\n",
      "step: 109465/583123 epoch 45: ...  - loss: 0.1131 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1035 - rmse: 0.2060\n",
      "step: 159465/583123 epoch 45: ...  - loss: 0.1138 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1040 - rmse: 0.2078\n",
      "step: 209465/583123 epoch 45: ...  - loss: 0.1133 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1034 - rmse: 0.2079\n",
      "step: 259465/583123 epoch 45: ...  - loss: 0.1269 - mean_absolute_error: 0.0934 - mean_squared_error: 0.1166 - rmse: 0.2193\n",
      "step: 309465/583123 epoch 45: ...  - loss: 0.1374 - mean_absolute_error: 0.0949 - mean_squared_error: 0.1270 - rmse: 0.2257\n",
      "step: 359465/583123 epoch 45: ...  - loss: 0.1114 - mean_absolute_error: 0.0857 - mean_squared_error: 0.1015 - rmse: 0.2047\n",
      "step: 409465/583123 epoch 45: ...  - loss: 0.1126 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1027 - rmse: 0.2059\n",
      "step: 459465/583123 epoch 45: ...  - loss: 0.1141 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1041 - rmse: 0.2070\n",
      "step: 509465/583123 epoch 45: ...  - loss: 0.1112 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1012 - rmse: 0.2055\n",
      "step: 559465/583123 epoch 45: ...  - loss: 0.1102 - mean_absolute_error: 0.0862 - mean_squared_error: 0.1000 - rmse: 0.2037\n",
      " - 376s - loss: 0.1162 - mean_absolute_error: 0.0884 - mean_squared_error: 0.1061 - rmse: 0.2092 - val_loss: 0.1135 - val_mean_absolute_error: 0.0887 - val_mean_squared_error: 0.1032 - val_rmse: 0.2075\n",
      "Epoch 47/100\n",
      "step: 26342/583123 epoch 46: ...  - loss: 0.1110 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1007 - rmse: 0.2059\n",
      "step: 76342/583123 epoch 46: ...  - loss: 0.1186 - mean_absolute_error: 0.0912 - mean_squared_error: 0.1081 - rmse: 0.2127\n",
      "step: 126342/583123 epoch 46: ...  - loss: 0.1114 - mean_absolute_error: 0.0860 - mean_squared_error: 0.1008 - rmse: 0.2048\n",
      "step: 176342/583123 epoch 46: ...  - loss: 0.1121 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1015 - rmse: 0.2056\n",
      "step: 226342/583123 epoch 46: ...  - loss: 0.1106 - mean_absolute_error: 0.0871 - mean_squared_error: 0.0999 - rmse: 0.2048\n",
      "step: 276342/583123 epoch 46: ...  - loss: 0.1144 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1036 - rmse: 0.2084\n",
      "step: 326342/583123 epoch 46: ...  - loss: 0.1130 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1022 - rmse: 0.2071\n",
      "step: 376342/583123 epoch 46: ...  - loss: 0.1165 - mean_absolute_error: 0.0896 - mean_squared_error: 0.1058 - rmse: 0.2098\n",
      "step: 426342/583123 epoch 46: ...  - loss: 0.1257 - mean_absolute_error: 0.0905 - mean_squared_error: 0.1149 - rmse: 0.2157\n",
      "step: 476342/583123 epoch 46: ...  - loss: 0.1136 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1039 - rmse: 0.2064\n",
      "step: 526342/583123 epoch 46: ...  - loss: 0.1120 - mean_absolute_error: 0.0862 - mean_squared_error: 0.1022 - rmse: 0.2047\n",
      "step: 576342/583123 epoch 46: ...  - loss: 0.1163 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1065 - rmse: 0.2093\n",
      " - 376s - loss: 0.1148 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1044 - rmse: 0.2081 - val_loss: 0.1037 - val_mean_absolute_error: 0.0840 - val_mean_squared_error: 0.0940 - val_rmse: 0.1938\n",
      "Epoch 48/100\n",
      "step: 43219/583123 epoch 47: ...  - loss: 0.1132 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1033 - rmse: 0.2064\n",
      "step: 93219/583123 epoch 47: ...  - loss: 0.1134 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1033 - rmse: 0.2072\n",
      "step: 143219/583123 epoch 47: ...  - loss: 0.1115 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1015 - rmse: 0.2055\n",
      "step: 193219/583123 epoch 47: ...  - loss: 0.1190 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1090 - rmse: 0.2108\n",
      "step: 243219/583123 epoch 47: ...  - loss: 0.1125 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1025 - rmse: 0.2051\n",
      "step: 293219/583123 epoch 47: ...  - loss: 0.1108 - mean_absolute_error: 0.0853 - mean_squared_error: 0.1006 - rmse: 0.2041\n",
      "step: 343219/583123 epoch 47: ...  - loss: 0.1168 - mean_absolute_error: 0.0877 - mean_squared_error: 0.1065 - rmse: 0.2092\n",
      "step: 393219/583123 epoch 47: ...  - loss: 0.1145 - mean_absolute_error: 0.0863 - mean_squared_error: 0.1045 - rmse: 0.2072\n",
      "step: 443219/583123 epoch 47: ...  - loss: 0.1278 - mean_absolute_error: 0.0916 - mean_squared_error: 0.1178 - rmse: 0.2180\n",
      "step: 493219/583123 epoch 47: ...  - loss: 0.1137 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1036 - rmse: 0.2073\n",
      "step: 543219/583123 epoch 47: ...  - loss: 0.1142 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1040 - rmse: 0.2080\n",
      " - 377s - loss: 0.1150 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1049 - rmse: 0.2079 - val_loss: 0.1004 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0901 - val_rmse: 0.1950\n",
      "Epoch 49/100\n",
      "step: 10096/583123 epoch 48: ...  - loss: 0.1120 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1017 - rmse: 0.2059\n",
      "step: 60096/583123 epoch 48: ...  - loss: 0.1129 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1024 - rmse: 0.2066\n",
      "step: 110096/583123 epoch 48: ...  - loss: 0.1114 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1008 - rmse: 0.2058\n",
      "step: 160096/583123 epoch 48: ...  - loss: 0.1540 - mean_absolute_error: 0.1004 - mean_squared_error: 0.1435 - rmse: 0.2380\n",
      "step: 210096/583123 epoch 48: ...  - loss: 0.1186 - mean_absolute_error: 0.0893 - mean_squared_error: 0.1084 - rmse: 0.2110\n",
      "step: 260096/583123 epoch 48: ...  - loss: 0.1228 - mean_absolute_error: 0.0903 - mean_squared_error: 0.1125 - rmse: 0.2144\n",
      "step: 310096/583123 epoch 48: ...  - loss: 0.1113 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1009 - rmse: 0.2049\n",
      "step: 360096/583123 epoch 48: ...  - loss: 0.1123 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1019 - rmse: 0.2066\n",
      "step: 410096/583123 epoch 48: ...  - loss: 0.1121 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1015 - rmse: 0.2054\n",
      "step: 460096/583123 epoch 48: ...  - loss: 0.1113 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1006 - rmse: 0.2048\n",
      "step: 510096/583123 epoch 48: ...  - loss: 0.1130 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1022 - rmse: 0.2065\n",
      "step: 560096/583123 epoch 48: ...  - loss: 0.1179 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1077 - rmse: 0.2105\n",
      " - 376s - loss: 0.1178 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1073 - rmse: 0.2103 - val_loss: 0.1196 - val_mean_absolute_error: 0.0821 - val_mean_squared_error: 0.1094 - val_rmse: 0.2071\n",
      "Epoch 50/100\n",
      "step: 26973/583123 epoch 49: ...  - loss: 0.1148 - mean_absolute_error: 0.0880 - mean_squared_error: 0.1045 - rmse: 0.2089\n",
      "step: 76973/583123 epoch 49: ...  - loss: 0.1105 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1000 - rmse: 0.2047\n",
      "step: 126973/583123 epoch 49: ...  - loss: 0.1260 - mean_absolute_error: 0.0928 - mean_squared_error: 0.1152 - rmse: 0.2163\n",
      "step: 176973/583123 epoch 49: ...  - loss: 0.1127 - mean_absolute_error: 0.0882 - mean_squared_error: 0.1019 - rmse: 0.2071\n",
      "step: 226973/583123 epoch 49: ...  - loss: 0.1120 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1011 - rmse: 0.2056\n",
      "step: 276973/583123 epoch 49: ...  - loss: 0.1105 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0995 - rmse: 0.2044\n",
      "step: 326973/583123 epoch 49: ...  - loss: 0.1104 - mean_absolute_error: 0.0868 - mean_squared_error: 0.0996 - rmse: 0.2044\n",
      "step: 376973/583123 epoch 49: ...  - loss: 0.1109 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1000 - rmse: 0.2049\n",
      "step: 426973/583123 epoch 49: ...  - loss: 0.1123 - mean_absolute_error: 0.0871 - mean_squared_error: 0.1014 - rmse: 0.2061\n",
      "step: 476973/583123 epoch 49: ...  - loss: 0.1098 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0990 - rmse: 0.2043\n",
      "step: 526973/583123 epoch 49: ...  - loss: 0.1134 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1025 - rmse: 0.2071\n",
      "step: 576973/583123 epoch 49: ...  - loss: 0.1217 - mean_absolute_error: 0.0905 - mean_squared_error: 0.1105 - rmse: 0.2136\n",
      " - 377s - loss: 0.1136 - mean_absolute_error: 0.0878 - mean_squared_error: 0.1028 - rmse: 0.2071 - val_loss: 0.1105 - val_mean_absolute_error: 0.0851 - val_mean_squared_error: 0.0995 - val_rmse: 0.2068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "step: 43850/583123 epoch 50: ...  - loss: 0.1327 - mean_absolute_error: 0.0929 - mean_squared_error: 0.1217 - rmse: 0.2216\n",
      "step: 93850/583123 epoch 50: ...  - loss: 0.1221 - mean_absolute_error: 0.0905 - mean_squared_error: 0.1107 - rmse: 0.2140\n",
      "step: 143850/583123 epoch 50: ...  - loss: 0.1524 - mean_absolute_error: 0.0979 - mean_squared_error: 0.1411 - rmse: 0.2367\n",
      "step: 193850/583123 epoch 50: ...  - loss: 0.1142 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1042 - rmse: 0.2086\n",
      "step: 243850/583123 epoch 50: ...  - loss: 0.1136 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1035 - rmse: 0.2063\n",
      "step: 293850/583123 epoch 50: ...  - loss: 0.1160 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1058 - rmse: 0.2082\n",
      "step: 343850/583123 epoch 50: ...  - loss: 0.1137 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1036 - rmse: 0.2066\n",
      "step: 393850/583123 epoch 50: ...  - loss: 0.1122 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1022 - rmse: 0.2062\n",
      "step: 443850/583123 epoch 50: ...  - loss: 0.1123 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1022 - rmse: 0.2057\n",
      "step: 493850/583123 epoch 50: ...  - loss: 0.1249 - mean_absolute_error: 0.0901 - mean_squared_error: 0.1145 - rmse: 0.2156\n",
      "step: 543850/583123 epoch 50: ...  - loss: 0.1118 - mean_absolute_error: 0.0859 - mean_squared_error: 0.1014 - rmse: 0.2053\n",
      " - 376s - loss: 0.1201 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1096 - rmse: 0.2119 - val_loss: 0.1047 - val_mean_absolute_error: 0.0801 - val_mean_squared_error: 0.0939 - val_rmse: 0.1937\n",
      "Epoch 52/100\n",
      "step: 10727/583123 epoch 51: ...  - loss: 0.1119 - mean_absolute_error: 0.0862 - mean_squared_error: 0.1012 - rmse: 0.2044\n",
      "step: 60727/583123 epoch 51: ...  - loss: 0.1118 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1009 - rmse: 0.2060\n",
      "step: 110727/583123 epoch 51: ...  - loss: 0.1100 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0991 - rmse: 0.2042\n",
      "step: 160727/583123 epoch 51: ...  - loss: 0.1085 - mean_absolute_error: 0.0870 - mean_squared_error: 0.0977 - rmse: 0.2029\n",
      "step: 210727/583123 epoch 51: ...  - loss: 0.1094 - mean_absolute_error: 0.0866 - mean_squared_error: 0.0985 - rmse: 0.2038\n",
      "step: 260727/583123 epoch 51: ...  - loss: 0.1104 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0994 - rmse: 0.2049\n",
      "step: 310727/583123 epoch 51: ...  - loss: 0.1149 - mean_absolute_error: 0.0888 - mean_squared_error: 0.1038 - rmse: 0.2088\n",
      "step: 360727/583123 epoch 51: ...  - loss: 0.1188 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1076 - rmse: 0.2114\n",
      "step: 410727/583123 epoch 51: ...  - loss: 0.1091 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0981 - rmse: 0.2032\n",
      "step: 460727/583123 epoch 51: ...  - loss: 0.1118 - mean_absolute_error: 0.0885 - mean_squared_error: 0.1008 - rmse: 0.2072\n",
      "step: 510727/583123 epoch 51: ...  - loss: 0.1100 - mean_absolute_error: 0.0863 - mean_squared_error: 0.0990 - rmse: 0.2040\n",
      "step: 560727/583123 epoch 51: ...  - loss: 0.1093 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0983 - rmse: 0.2044\n",
      " - 376s - loss: 0.1113 - mean_absolute_error: 0.0876 - mean_squared_error: 0.1004 - rmse: 0.2055 - val_loss: 0.1074 - val_mean_absolute_error: 0.0850 - val_mean_squared_error: 0.0963 - val_rmse: 0.2021\n",
      "Epoch 53/100\n",
      "step: 27604/583123 epoch 52: ...  - loss: 0.1115 - mean_absolute_error: 0.0879 - mean_squared_error: 0.1004 - rmse: 0.2063\n",
      "step: 77604/583123 epoch 52: ...  - loss: 0.1087 - mean_absolute_error: 0.0861 - mean_squared_error: 0.0977 - rmse: 0.2035\n",
      "step: 127604/583123 epoch 52: ...  - loss: 0.1108 - mean_absolute_error: 0.0875 - mean_squared_error: 0.0999 - rmse: 0.2052\n",
      "step: 177604/583123 epoch 52: ...  - loss: 0.1091 - mean_absolute_error: 0.0867 - mean_squared_error: 0.0982 - rmse: 0.2038\n",
      "step: 227604/583123 epoch 52: ...  - loss: 0.1100 - mean_absolute_error: 0.0875 - mean_squared_error: 0.0992 - rmse: 0.2046\n",
      "step: 277604/583123 epoch 52: ...  - loss: 0.1147 - mean_absolute_error: 0.0886 - mean_squared_error: 0.1036 - rmse: 0.2087\n",
      "step: 327604/583123 epoch 52: ...  - loss: 0.1103 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0993 - rmse: 0.2047\n",
      "step: 377604/583123 epoch 52: ...  - loss: 0.1090 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0979 - rmse: 0.2037\n",
      "step: 427604/583123 epoch 52: ...  - loss: 0.1067 - mean_absolute_error: 0.0858 - mean_squared_error: 0.0956 - rmse: 0.2007\n",
      "step: 477604/583123 epoch 52: ...  - loss: 0.1062 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0952 - rmse: 0.2005\n",
      "step: 527604/583123 epoch 52: ...  - loss: 0.1083 - mean_absolute_error: 0.0863 - mean_squared_error: 0.0974 - rmse: 0.2018\n",
      "step: 577604/583123 epoch 52: ...  - loss: 0.1180 - mean_absolute_error: 0.0891 - mean_squared_error: 0.1071 - rmse: 0.2099\n",
      " - 376s - loss: 0.1110 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1000 - rmse: 0.2050 - val_loss: 0.1963 - val_mean_absolute_error: 0.1094 - val_mean_squared_error: 0.1842 - val_rmse: 0.2702\n",
      "Epoch 54/100\n",
      "step: 44481/583123 epoch 53: ...  - loss: 0.1728 - mean_absolute_error: 0.1020 - mean_squared_error: 0.1602 - rmse: 0.2519\n",
      "step: 94481/583123 epoch 53: ...  - loss: 0.1193 - mean_absolute_error: 0.0866 - mean_squared_error: 0.1073 - rmse: 0.2100\n",
      "step: 144481/583123 epoch 53: ...  - loss: 0.1406 - mean_absolute_error: 0.0938 - mean_squared_error: 0.1290 - rmse: 0.2275\n",
      "step: 194481/583123 epoch 53: ...  - loss: 0.1463 - mean_absolute_error: 0.0931 - mean_squared_error: 0.1328 - rmse: 0.2289\n",
      "step: 244481/583123 epoch 53: ...  - loss: 0.1380 - mean_absolute_error: 0.0894 - mean_squared_error: 0.1229 - rmse: 0.2205\n",
      "step: 294481/583123 epoch 53: ...  - loss: 0.1366 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1208 - rmse: 0.2191\n",
      "step: 344481/583123 epoch 53: ...  - loss: 0.1345 - mean_absolute_error: 0.0887 - mean_squared_error: 0.1183 - rmse: 0.2165\n",
      "step: 394481/583123 epoch 53: ...  - loss: 0.1302 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1125 - rmse: 0.2122\n",
      "step: 444481/583123 epoch 53: ...  - loss: 0.1314 - mean_absolute_error: 0.0872 - mean_squared_error: 0.1131 - rmse: 0.2135\n",
      "step: 494481/583123 epoch 53: ...  - loss: 0.1343 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1147 - rmse: 0.2145\n",
      "step: 544481/583123 epoch 53: ...  - loss: 0.1322 - mean_absolute_error: 0.0870 - mean_squared_error: 0.1117 - rmse: 0.2131\n",
      " - 376s - loss: 0.1370 - mean_absolute_error: 0.0898 - mean_squared_error: 0.1208 - rmse: 0.2197 - val_loss: 0.1241 - val_mean_absolute_error: 0.0796 - val_mean_squared_error: 0.1030 - val_rmse: 0.1987\n",
      "Epoch 55/100\n",
      "step: 11358/583123 epoch 54: ...  - loss: 0.1337 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1124 - rmse: 0.2135\n",
      "step: 61358/583123 epoch 54: ...  - loss: 0.1336 - mean_absolute_error: 0.0863 - mean_squared_error: 0.1113 - rmse: 0.2112\n",
      "step: 111358/583123 epoch 54: ...  - loss: 0.1351 - mean_absolute_error: 0.0863 - mean_squared_error: 0.1108 - rmse: 0.2120\n",
      "step: 161358/583123 epoch 54: ...  - loss: 0.1386 - mean_absolute_error: 0.0874 - mean_squared_error: 0.1128 - rmse: 0.2134\n",
      "step: 211358/583123 epoch 54: ...  - loss: 0.1361 - mean_absolute_error: 0.0864 - mean_squared_error: 0.1110 - rmse: 0.2116\n",
      "step: 261358/583123 epoch 54: ...  - loss: 0.1363 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1119 - rmse: 0.2122\n",
      "step: 311358/583123 epoch 54: ...  - loss: 0.1342 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1111 - rmse: 0.2125\n",
      "step: 361358/583123 epoch 54: ...  - loss: 0.1348 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1103 - rmse: 0.2118\n",
      "step: 411358/583123 epoch 54: ...  - loss: 0.1369 - mean_absolute_error: 0.0875 - mean_squared_error: 0.1141 - rmse: 0.2144\n",
      "step: 461358/583123 epoch 54: ...  - loss: 0.1322 - mean_absolute_error: 0.0890 - mean_squared_error: 0.1161 - rmse: 0.2172\n",
      "step: 511358/583123 epoch 54: ...  - loss: 0.1331 - mean_absolute_error: 0.0881 - mean_squared_error: 0.1166 - rmse: 0.2163\n",
      "step: 561358/583123 epoch 54: ...  - loss: 0.1286 - mean_absolute_error: 0.0862 - mean_squared_error: 0.1112 - rmse: 0.2120\n",
      " - 376s - loss: 0.1341 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1123 - rmse: 0.2130 - val_loss: 0.1203 - val_mean_absolute_error: 0.0753 - val_mean_squared_error: 0.1034 - val_rmse: 0.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "step: 28235/583123 epoch 55: ...  - loss: 0.1259 - mean_absolute_error: 0.0858 - mean_squared_error: 0.1090 - rmse: 0.2098\n",
      "step: 78235/583123 epoch 55: ...  - loss: 0.1309 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1182 - rmse: 0.2178\n",
      "step: 128235/583123 epoch 55: ...  - loss: 0.1197 - mean_absolute_error: 0.0873 - mean_squared_error: 0.1091 - rmse: 0.2105\n",
      "step: 178235/583123 epoch 55: ...  - loss: 0.1131 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1028 - rmse: 0.2067\n",
      "step: 228235/583123 epoch 55: ...  - loss: 0.1112 - mean_absolute_error: 0.0867 - mean_squared_error: 0.1009 - rmse: 0.2052\n",
      "step: 278235/583123 epoch 55: ...  - loss: 0.1119 - mean_absolute_error: 0.0865 - mean_squared_error: 0.1014 - rmse: 0.2051\n",
      "step: 328235/583123 epoch 55: ...  - loss: 0.1091 - mean_absolute_error: 0.0853 - mean_squared_error: 0.0986 - rmse: 0.2029\n",
      "step: 378235/583123 epoch 55: ...  - loss: 0.1547 - mean_absolute_error: 0.1014 - mean_squared_error: 0.1437 - rmse: 0.2405\n",
      "step: 428235/583123 epoch 55: ...  - loss: 0.1563 - mean_absolute_error: 0.0991 - mean_squared_error: 0.1433 - rmse: 0.2401\n",
      "step: 478235/583123 epoch 55: ...  - loss: 0.1410 - mean_absolute_error: 0.0919 - mean_squared_error: 0.1268 - rmse: 0.2257\n",
      "step: 528235/583123 epoch 55: ...  - loss: 0.1148 - mean_absolute_error: 0.0869 - mean_squared_error: 0.1041 - rmse: 0.2072\n",
      "step: 578235/583123 epoch 55: ...  - loss: 0.1132 - mean_absolute_error: 0.0868 - mean_squared_error: 0.1028 - rmse: 0.2054\n",
      " - 376s - loss: 0.1251 - mean_absolute_error: 0.0897 - mean_squared_error: 0.1135 - rmse: 0.2149 - val_loss: 0.1010 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0905 - val_rmse: 0.1925\n",
      "Test loss: 0.10099731821635598\n",
      "val_mean_absolute_error: 0.08098343505193668\n",
      "score\n",
      "[0.10099731821635598, 0.08098343505193668, 0.09047769850857806, 0.2520294939860216]\n",
      "model.metrics_names\n",
      "['loss', 'mean_absolute_error', 'mean_squared_error', 'rmse']\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',   #categorical_crossentropy\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"mae\", \"mean_squared_error\", rmse])\n",
    "\n",
    "# Add CallBacks (including TensorBoard)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "        log_dir='TensorBoard_logs/' + str(file_name), write_graph = False, write_images=False, write_grads=False)\n",
    "EarlyStoppingCallBack = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_rmse', min_delta=0, patience=15, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit([x_train_1, x_train_2],\n",
    "                    y = y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=2,\n",
    "                    # validation_data=(x_test, y_test),\n",
    "                    validation_data=([x_test_1, x_test_2], y_test),\n",
    "                    callbacks=[tbCallBack, EarlyStoppingCallBack, NBatchLogger(5e4)])\n",
    "#5e4\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = model.evaluate([x_test_1, x_test_2], y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('val_mean_absolute_error:', score[1])\n",
    "\n",
    "print(\"score\")\n",
    "print(score)\n",
    "\n",
    "print(\"model.metrics_names\")\n",
    "print(model.metrics_names)\n",
    "\n",
    "# creates a HDF5 file 'my_model.h5'\n",
    "model.save(\"./Saved-Networks/\" + str(file_name) +\".h5\")\n",
    "\n",
    "# Create output file\n",
    "OutputFile = open(\"./Loss-Values/\" +str(file_name) +\".txt\", \"w+\")\n",
    "OutputFile.write(\"Test loss: \" + str(score[0]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_absolute_error: \" +str(score[1]) + \"\\n\")\n",
    "OutputFile.write(\"val_mean_squared_error: \" +str(score[2]) + \"\\n\")\n",
    "OutputFile.write(\"RMSE: \" +str(score[3]) + \"\\n\")\n",
    "OutputFile.close()\n",
    "\n",
    "del history\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0**1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session = K.get_session()\n",
    "with tf_session.as_default():\n",
    "    display(((K.abs(0.)) ** (K.clip(K.abs(.5), 0.5, 3))).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
